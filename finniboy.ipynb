{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = baseline.baselineXy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import QuantileTransformer, KBinsDiscretizer, Normalizer, PowerTransformer, RobustScaler, SplineTransformer, StandardScaler, MinMaxScaler\n",
    "td = {\n",
    " 'sdoif_mean_id': QuantileTransformer,\n",
    " 'sdoif_mean_sq': RobustScaler,\n",
    " 'elevation_mean_sqrt': QuantileTransformer,\n",
    " 'procurv_mean_id': StandardScaler,\n",
    " 'placurv_mean_id': Normalizer,\n",
    " 'lsfactor_mean_id': Normalizer,\n",
    " 'slope_mean_id': RobustScaler,\n",
    " 'twi_mean_id': Normalizer,\n",
    " 'twi_mean_sqrt': QuantileTransformer,\n",
    " 'aspect_mean_id': QuantileTransformer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, t in td.items():\n",
    "    X[key] = t().fit_transform(X[[key]])\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\n",
    "    [1, 2, 6, 7],\n",
    "    [3, 8],\n",
    "    [4, 5, 9, 10],\n",
    "    [11, 12],\n",
    "    [13],\n",
    "    [14, 15],\n",
    "    [16, 17, 21, 22],\n",
    "    [18, 23],\n",
    "    [19, 20, 24, 25],\n",
    "    list(range(1, 26))\n",
    "]\n",
    "\n",
    "def get_group_mean(df, col, group):\n",
    "    cols = [f\"{i}_{col}\" for i in group]\n",
    "    return df[cols].to_numpy().mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37.73571  , 31.7261425, 49.1132025, ..., 39.9281625, 35.24104  ,\n",
       "       20.02481  ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import baseline\n",
    "X, y = baseline.originalXy()\n",
    "get_group_mean(X, \"slope\", groups[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[cat] = X[cat].map({\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(X):\n",
    "    grid_groups = pd.DataFrame()\n",
    "\n",
    "    def normalize(x):\n",
    "        return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "    def special_normalize(x):\n",
    "        return ((x - x.min()) / (x.max() - x.min()) + 0.01) / 1.01\n",
    "\n",
    "    fns = [(np.array, 'id'), (np.sqrt, 'sqrt'), (np.square, 'sq'), (np.log, 'log')]\n",
    "    print(len(baseline.continuous) * len(groups) * len(fns))\n",
    "    for col in baseline.continuous:\n",
    "        for i, group in enumerate(groups):\n",
    "            for fn, name in fns:\n",
    "                this = f\"{col}_g{i}_{name}\"\n",
    "                if name == 'log':\n",
    "                    grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
    "                else:\n",
    "                    grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
    "\n",
    "    import dfcols\n",
    "    def most_freq(df, col):\n",
    "        matrix = df[dfcols.all_square_cols(col)].to_numpy()\n",
    "        return np.array(list(map(np.argmax, map(np.bincount, matrix))))\n",
    "\n",
    "    cat = \"geology\"\n",
    "    # get most freq category\n",
    "    X[cat] = most_freq(X, cat)\n",
    "    grid_groups[cat] = X[cat].map({\n",
    "        1: \"Weathered Cretaceous granitic rocks\",\n",
    "        2: \"Weathered Jurassic granite rocks\",\n",
    "        3: \"Weathered Jurassic tuff and lava\",\n",
    "        4: \"Weathered Cretaceous tuff and lava\",\n",
    "        5: \"Quaternary deposits\",\n",
    "        6: \"Fill\",\n",
    "        7: \"Weathered Jurassic sandstone, siltstone and mudstone\"\n",
    "    })\n",
    "    return grid_groups\n",
    "grid_groups = preprocess(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sdoif_g0_id</th>\n",
       "      <th>sdoif_g0_sqrt</th>\n",
       "      <th>sdoif_g0_sq</th>\n",
       "      <th>sdoif_g0_log</th>\n",
       "      <th>sdoif_g1_id</th>\n",
       "      <th>sdoif_g1_sqrt</th>\n",
       "      <th>sdoif_g1_sq</th>\n",
       "      <th>sdoif_g1_log</th>\n",
       "      <th>sdoif_g2_id</th>\n",
       "      <th>sdoif_g2_sqrt</th>\n",
       "      <th>...</th>\n",
       "      <th>aspect_g7_log</th>\n",
       "      <th>aspect_g8_id</th>\n",
       "      <th>aspect_g8_sqrt</th>\n",
       "      <th>aspect_g8_sq</th>\n",
       "      <th>aspect_g8_log</th>\n",
       "      <th>aspect_g9_id</th>\n",
       "      <th>aspect_g9_sqrt</th>\n",
       "      <th>aspect_g9_sq</th>\n",
       "      <th>aspect_g9_log</th>\n",
       "      <th>geology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680410</td>\n",
       "      <td>0.824870</td>\n",
       "      <td>0.462958</td>\n",
       "      <td>-0.380419</td>\n",
       "      <td>0.680235</td>\n",
       "      <td>0.824763</td>\n",
       "      <td>0.462719</td>\n",
       "      <td>-0.380674</td>\n",
       "      <td>0.680087</td>\n",
       "      <td>0.824674</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.118586</td>\n",
       "      <td>0.323977</td>\n",
       "      <td>0.569190</td>\n",
       "      <td>0.104961</td>\n",
       "      <td>-1.106634</td>\n",
       "      <td>0.303978</td>\n",
       "      <td>0.551342</td>\n",
       "      <td>0.092402</td>\n",
       "      <td>-1.168384</td>\n",
       "      <td>Weathered Jurassic tuff and lava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960227</td>\n",
       "      <td>0.979912</td>\n",
       "      <td>0.922036</td>\n",
       "      <td>-0.040175</td>\n",
       "      <td>0.960051</td>\n",
       "      <td>0.979822</td>\n",
       "      <td>0.921698</td>\n",
       "      <td>-0.040357</td>\n",
       "      <td>0.959901</td>\n",
       "      <td>0.979745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675332</td>\n",
       "      <td>0.481153</td>\n",
       "      <td>0.693652</td>\n",
       "      <td>0.231508</td>\n",
       "      <td>-0.720950</td>\n",
       "      <td>0.500208</td>\n",
       "      <td>0.707254</td>\n",
       "      <td>0.250208</td>\n",
       "      <td>-0.682887</td>\n",
       "      <td>Weathered Jurassic tuff and lava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979967</td>\n",
       "      <td>0.989933</td>\n",
       "      <td>0.960336</td>\n",
       "      <td>-0.020034</td>\n",
       "      <td>0.980065</td>\n",
       "      <td>0.989982</td>\n",
       "      <td>0.960528</td>\n",
       "      <td>-0.019935</td>\n",
       "      <td>0.980189</td>\n",
       "      <td>0.990045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326154</td>\n",
       "      <td>0.722408</td>\n",
       "      <td>0.849946</td>\n",
       "      <td>0.521873</td>\n",
       "      <td>-0.321368</td>\n",
       "      <td>0.790661</td>\n",
       "      <td>0.889191</td>\n",
       "      <td>0.625145</td>\n",
       "      <td>-0.232268</td>\n",
       "      <td>Weathered Jurassic granite rocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.173158</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>-3.229237</td>\n",
       "      <td>0.030168</td>\n",
       "      <td>0.173691</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>-3.224625</td>\n",
       "      <td>0.030344</td>\n",
       "      <td>0.174196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.846976</td>\n",
       "      <td>0.410311</td>\n",
       "      <td>0.640555</td>\n",
       "      <td>0.168355</td>\n",
       "      <td>-0.876712</td>\n",
       "      <td>0.466744</td>\n",
       "      <td>0.683187</td>\n",
       "      <td>0.217850</td>\n",
       "      <td>-0.750726</td>\n",
       "      <td>Weathered Jurassic granite rocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.690175</td>\n",
       "      <td>0.830768</td>\n",
       "      <td>0.476342</td>\n",
       "      <td>-0.366375</td>\n",
       "      <td>0.689855</td>\n",
       "      <td>0.830575</td>\n",
       "      <td>0.475900</td>\n",
       "      <td>-0.366832</td>\n",
       "      <td>0.689496</td>\n",
       "      <td>0.830359</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.019687</td>\n",
       "      <td>0.329545</td>\n",
       "      <td>0.574060</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>-1.090100</td>\n",
       "      <td>0.329019</td>\n",
       "      <td>0.573602</td>\n",
       "      <td>0.108253</td>\n",
       "      <td>-1.091650</td>\n",
       "      <td>Quaternary deposits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10859</th>\n",
       "      <td>0.646353</td>\n",
       "      <td>0.803961</td>\n",
       "      <td>0.417773</td>\n",
       "      <td>-0.431006</td>\n",
       "      <td>0.646819</td>\n",
       "      <td>0.804251</td>\n",
       "      <td>0.418375</td>\n",
       "      <td>-0.430297</td>\n",
       "      <td>0.647233</td>\n",
       "      <td>0.804508</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.088610</td>\n",
       "      <td>0.294239</td>\n",
       "      <td>0.542438</td>\n",
       "      <td>0.086576</td>\n",
       "      <td>-1.199894</td>\n",
       "      <td>0.308574</td>\n",
       "      <td>0.555495</td>\n",
       "      <td>0.095218</td>\n",
       "      <td>-1.153850</td>\n",
       "      <td>Weathered Jurassic granite rocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10860</th>\n",
       "      <td>0.857721</td>\n",
       "      <td>0.926132</td>\n",
       "      <td>0.735685</td>\n",
       "      <td>-0.151835</td>\n",
       "      <td>0.857601</td>\n",
       "      <td>0.926067</td>\n",
       "      <td>0.735479</td>\n",
       "      <td>-0.151974</td>\n",
       "      <td>0.857472</td>\n",
       "      <td>0.925998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.905288</td>\n",
       "      <td>0.481153</td>\n",
       "      <td>0.693652</td>\n",
       "      <td>0.231508</td>\n",
       "      <td>-0.720950</td>\n",
       "      <td>0.401679</td>\n",
       "      <td>0.633782</td>\n",
       "      <td>0.161346</td>\n",
       "      <td>-0.897461</td>\n",
       "      <td>Weathered Jurassic tuff and lava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10861</th>\n",
       "      <td>0.739961</td>\n",
       "      <td>0.860210</td>\n",
       "      <td>0.547543</td>\n",
       "      <td>-0.297684</td>\n",
       "      <td>0.739836</td>\n",
       "      <td>0.860137</td>\n",
       "      <td>0.547358</td>\n",
       "      <td>-0.297851</td>\n",
       "      <td>0.739731</td>\n",
       "      <td>0.860076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.920145</td>\n",
       "      <td>0.364499</td>\n",
       "      <td>0.603738</td>\n",
       "      <td>0.132860</td>\n",
       "      <td>-0.992116</td>\n",
       "      <td>0.360548</td>\n",
       "      <td>0.600456</td>\n",
       "      <td>0.129995</td>\n",
       "      <td>-1.002723</td>\n",
       "      <td>Weathered Jurassic tuff and lava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10862</th>\n",
       "      <td>0.944510</td>\n",
       "      <td>0.971859</td>\n",
       "      <td>0.892099</td>\n",
       "      <td>-0.056508</td>\n",
       "      <td>0.944649</td>\n",
       "      <td>0.971930</td>\n",
       "      <td>0.892361</td>\n",
       "      <td>-0.056362</td>\n",
       "      <td>0.944817</td>\n",
       "      <td>0.972017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320025</td>\n",
       "      <td>0.709069</td>\n",
       "      <td>0.842063</td>\n",
       "      <td>0.502780</td>\n",
       "      <td>-0.339748</td>\n",
       "      <td>0.698702</td>\n",
       "      <td>0.835884</td>\n",
       "      <td>0.488185</td>\n",
       "      <td>-0.354270</td>\n",
       "      <td>Weathered Jurassic granite rocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10863</th>\n",
       "      <td>0.856016</td>\n",
       "      <td>0.925211</td>\n",
       "      <td>0.732763</td>\n",
       "      <td>-0.153803</td>\n",
       "      <td>0.855844</td>\n",
       "      <td>0.925119</td>\n",
       "      <td>0.732469</td>\n",
       "      <td>-0.154001</td>\n",
       "      <td>0.855657</td>\n",
       "      <td>0.925017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208728</td>\n",
       "      <td>0.839855</td>\n",
       "      <td>0.916436</td>\n",
       "      <td>0.705356</td>\n",
       "      <td>-0.172640</td>\n",
       "      <td>0.839641</td>\n",
       "      <td>0.916319</td>\n",
       "      <td>0.704997</td>\n",
       "      <td>-0.172892</td>\n",
       "      <td>Weathered Jurassic tuff and lava</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10864 rows × 321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sdoif_g0_id  sdoif_g0_sqrt  sdoif_g0_sq  sdoif_g0_log  sdoif_g1_id  \\\n",
       "0         0.680410       0.824870     0.462958     -0.380419     0.680235   \n",
       "1         0.960227       0.979912     0.922036     -0.040175     0.960051   \n",
       "2         0.979967       0.989933     0.960336     -0.020034     0.980065   \n",
       "3         0.029984       0.173158     0.000899     -3.229237     0.030168   \n",
       "4         0.690175       0.830768     0.476342     -0.366375     0.689855   \n",
       "...            ...            ...          ...           ...          ...   \n",
       "10859     0.646353       0.803961     0.417773     -0.431006     0.646819   \n",
       "10860     0.857721       0.926132     0.735685     -0.151835     0.857601   \n",
       "10861     0.739961       0.860210     0.547543     -0.297684     0.739836   \n",
       "10862     0.944510       0.971859     0.892099     -0.056508     0.944649   \n",
       "10863     0.856016       0.925211     0.732763     -0.153803     0.855844   \n",
       "\n",
       "       sdoif_g1_sqrt  sdoif_g1_sq  sdoif_g1_log  sdoif_g2_id  sdoif_g2_sqrt  \\\n",
       "0           0.824763     0.462719     -0.380674     0.680087       0.824674   \n",
       "1           0.979822     0.921698     -0.040357     0.959901       0.979745   \n",
       "2           0.989982     0.960528     -0.019935     0.980189       0.990045   \n",
       "3           0.173691     0.000910     -3.224625     0.030344       0.174196   \n",
       "4           0.830575     0.475900     -0.366832     0.689496       0.830359   \n",
       "...              ...          ...           ...          ...            ...   \n",
       "10859       0.804251     0.418375     -0.430297     0.647233       0.804508   \n",
       "10860       0.926067     0.735479     -0.151974     0.857472       0.925998   \n",
       "10861       0.860137     0.547358     -0.297851     0.739731       0.860076   \n",
       "10862       0.971930     0.892361     -0.056362     0.944817       0.972017   \n",
       "10863       0.925119     0.732469     -0.154001     0.855657       0.925017   \n",
       "\n",
       "       ...  aspect_g7_log  aspect_g8_id  aspect_g8_sqrt  aspect_g8_sq  \\\n",
       "0      ...      -1.118586      0.323977        0.569190      0.104961   \n",
       "1      ...      -0.675332      0.481153        0.693652      0.231508   \n",
       "2      ...      -0.326154      0.722408        0.849946      0.521873   \n",
       "3      ...      -0.846976      0.410311        0.640555      0.168355   \n",
       "4      ...      -1.019687      0.329545        0.574060      0.108600   \n",
       "...    ...            ...           ...             ...           ...   \n",
       "10859  ...      -1.088610      0.294239        0.542438      0.086576   \n",
       "10860  ...      -0.905288      0.481153        0.693652      0.231508   \n",
       "10861  ...      -0.920145      0.364499        0.603738      0.132860   \n",
       "10862  ...      -0.320025      0.709069        0.842063      0.502780   \n",
       "10863  ...      -0.208728      0.839855        0.916436      0.705356   \n",
       "\n",
       "       aspect_g8_log  aspect_g9_id  aspect_g9_sqrt  aspect_g9_sq  \\\n",
       "0          -1.106634      0.303978        0.551342      0.092402   \n",
       "1          -0.720950      0.500208        0.707254      0.250208   \n",
       "2          -0.321368      0.790661        0.889191      0.625145   \n",
       "3          -0.876712      0.466744        0.683187      0.217850   \n",
       "4          -1.090100      0.329019        0.573602      0.108253   \n",
       "...              ...           ...             ...           ...   \n",
       "10859      -1.199894      0.308574        0.555495      0.095218   \n",
       "10860      -0.720950      0.401679        0.633782      0.161346   \n",
       "10861      -0.992116      0.360548        0.600456      0.129995   \n",
       "10862      -0.339748      0.698702        0.835884      0.488185   \n",
       "10863      -0.172640      0.839641        0.916319      0.704997   \n",
       "\n",
       "       aspect_g9_log                           geology  \n",
       "0          -1.168384  Weathered Jurassic tuff and lava  \n",
       "1          -0.682887  Weathered Jurassic tuff and lava  \n",
       "2          -0.232268  Weathered Jurassic granite rocks  \n",
       "3          -0.750726  Weathered Jurassic granite rocks  \n",
       "4          -1.091650               Quaternary deposits  \n",
       "...              ...                               ...  \n",
       "10859      -1.153850  Weathered Jurassic granite rocks  \n",
       "10860      -0.897461  Weathered Jurassic tuff and lava  \n",
       "10861      -1.002723  Weathered Jurassic tuff and lava  \n",
       "10862      -0.354270  Weathered Jurassic granite rocks  \n",
       "10863      -0.172892  Weathered Jurassic tuff and lava  \n",
       "\n",
       "[10864 rows x 321 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nk = 3\\nkf = KFold(n_splits=k)\\nfor m in models:\\n    f1m = 0\\n    for train_ind, test_ind in kf.split(grid_groups.to_numpy()):\\n        X_train, X_test = grid_groups.to_numpy()[train_ind], grid_groups.to_numpy()[test_ind]\\n        y_train, y_test = y[train_ind], y[test_ind]\\n        X_train, y_train = SMOTE().fit_resample(X_train, y_train)\\n        mym = m().fit(X_train, y_train)\\n        probs = mym.predict_proba(X_test)[:, 1]\\n        y_pred = np.array(probs > 0.4, dtype=int)\\n        #print(y_pred)\\n        f1 = f1_score(y_test, y_pred)\\n        print(f1)\\n        f1m += f1 / k\\n    print(m.__name__, f1m)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.feat_trans import test_feats\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# estimators = [\n",
    "#     ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "#     ('svr', make_pipeline(StandardScaler(),\n",
    "#                           LinearSVC(random_state=42)))\n",
    "# ]\n",
    "models = [LogisticRegression, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, CatBoostClassifier]\n",
    "\n",
    "\"\"\"\n",
    "k = 3\n",
    "kf = KFold(n_splits=k)\n",
    "for m in models:\n",
    "    f1m = 0\n",
    "    for train_ind, test_ind in kf.split(grid_groups.to_numpy()):\n",
    "        X_train, X_test = grid_groups.to_numpy()[train_ind], grid_groups.to_numpy()[test_ind]\n",
    "        y_train, y_test = y[train_ind], y[test_ind]\n",
    "        X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "        mym = m().fit(X_train, y_train)\n",
    "        probs = mym.predict_proba(X_test)[:, 1]\n",
    "        y_pred = np.array(probs > 0.4, dtype=int)\n",
    "        #print(y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        print(f1)\n",
    "        f1m += f1 / k\n",
    "    print(m.__name__, f1m)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "def tree_features(X, n):\n",
    "    clf = ExtraTreesClassifier(n_estimators=50)\n",
    "    clf = clf.fit(X, y)\n",
    "    model = SelectFromModel(clf, prefit=True, max_features=n)\n",
    "\n",
    "    X_clf = model.transform(X)\n",
    "    return test_feats(ExtraTreesClassifier(n_estimators=50), X_clf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def something():\n",
    "    for sc in [StandardScaler, MinMaxScaler, QuantileTransformer, PowerTransformer]:\n",
    "        hX = sc().fit_transform(gg)\n",
    "        clf = ExtraTreesClassifier()\n",
    "        clf = clf.fit(hX, y)\n",
    "        model = SelectFromModel(clf, prefit=True)\n",
    "        X_clf = model.transform(hX)\n",
    "        print(sc.__name__, test_feats(ExtraTreesClassifier(n_estimators=50), X_clf, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_test(x, y):\n",
    "    kf = KFold(n_splits=3)\n",
    "    f1m = 0\n",
    "    for train_ind, test_ind in kf.split(x):\n",
    "        X_train, X_test = x[train_ind], x[test_ind]\n",
    "        y_train, y_test = y[train_ind], y[test_ind]\n",
    "        X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "        X_train, X_test = StandardScaler().fit_transform(X_train), StandardScaler().fit_transform(X_test)\n",
    "        ds = lgb.Dataset(X_train, label=y_train)\n",
    "        bst = lgb.train({'num_leaves': 30, 'objective': 'binary', 'metric': 'auc', 'n_jobs': 2}, ds)\n",
    "        y_pred = bst.predict(X_test)\n",
    "        y_pred = np.array(y_pred > 0.5, dtype=int)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1m += f1 / 3\n",
    "    return f1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5456, number of negative: 5456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81600\n",
      "[LightGBM] [Info] Number of data points in the train set: 10912, number of used features: 320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 5418, number of negative: 5418\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81600\n",
      "[LightGBM] [Info] Number of data points in the train set: 10836, number of used features: 320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 5422, number of negative: 5422\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81600\n",
      "[LightGBM] [Info] Number of data points in the train set: 10844, number of used features: 320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6025762321404486"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_test(grid_groups.drop([\"geology\"], axis=1, inplace=False).to_numpy(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: gridgroups\n",
       "  DataFrames:\n",
       "    gg [Rows: 10864, Columns: 322]\n",
       "    2nd [Rows: 7, Columns: 1]\n",
       "  Relationships:\n",
       "    gg.geology -> 2nd.geology"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = ft.EntitySet(id = 'gridgroups')\n",
    "grid_groups['id'] = grid_groups.index\n",
    "es = ft.EntitySet(id = 'gridgroups')\n",
    "es = es.add_dataframe(dataframe_name='gg', dataframe =grid_groups, index='id')\n",
    "es.normalize_dataframe(base_dataframe_name='gg', new_dataframe_name='2nd', index='geology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2242"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix, feature_names = ft.dfs(\n",
    "    entityset=es, \n",
    "    target_dataframe_name = 'gg',\n",
    "    max_depth=2\n",
    ")\n",
    "\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.37303177, -0.20639589, -0.60936445, ..., -0.86115675,\n",
       "         0.83649743,  0.85975046],\n",
       "       [ 1.12698306,  0.88288997,  1.47308477, ..., -0.86115675,\n",
       "         0.83649743,  0.85975046],\n",
       "       [ 1.23280512,  0.95329685,  1.64681993, ...,  0.90482352,\n",
       "        -1.12893699, -0.98071659],\n",
       "       ...,\n",
       "       [-0.05379693,  0.04189499, -0.2256762 , ..., -0.86115675,\n",
       "         0.83649743,  0.85975046],\n",
       "       [ 1.04272735,  0.82631275,  1.3372845 , ...,  0.90482352,\n",
       "        -1.12893699, -0.98071659],\n",
       "       [ 0.56833535,  0.49857612,  0.61450997, ..., -0.86115675,\n",
       "         0.83649743,  0.85975046]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = StandardScaler().fit_transform(feature_matrix.drop([\"geology\"], axis=1, inplace=False))\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5456, number of negative: 5456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.185232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 96644\n",
      "[LightGBM] [Info] Number of data points in the train set: 10912, number of used features: 2233\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 5418, number of negative: 5418\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.471047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96644\n",
      "[LightGBM] [Info] Number of data points in the train set: 10836, number of used features: 2233\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 5422, number of negative: 5422\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.411877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96725\n",
      "[LightGBM] [Info] Number of data points in the train set: 10844, number of used features: 2233\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6157702746422324"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_test(feats, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t2241\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t2241\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t2241\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t2241\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t2241\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t2241\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t2241\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 10\n",
      "Confirmed: \t248\n",
      "Tentative: \t284\n",
      "Rejected: \t1709\n",
      "Iteration: \t9 / 10\n",
      "Confirmed: \t248\n",
      "Tentative: \t284\n",
      "Rejected: \t1709\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t10 / 10\n",
      "Confirmed: \t248\n",
      "Tentative: \t71\n",
      "Rejected: \t1709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=ExtraTreesClassifier(n_estimators=326,\n",
       "                                        random_state=RandomState(MT19937) at 0x2B64F3EEDD40),\n",
       "         max_iter=10, n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x2B64F3EEDD40, verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "feat_selector = BorutaPy(\n",
    "    verbose=2,\n",
    "    estimator=ExtraTreesClassifier(),\n",
    "    n_estimators='auto',\n",
    "    max_iter=10  # number of iterations to perform\n",
    ")\n",
    "feat_selector.fit(feats, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10864, 248)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_selector.transform(feats).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5456, number of negative: 5456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 63237\n",
      "[LightGBM] [Info] Number of data points in the train set: 10912, number of used features: 248\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 5418, number of negative: 5418\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 63238\n",
      "[LightGBM] [Info] Number of data points in the train set: 10836, number of used features: 248\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 5422, number of negative: 5422\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 63236\n",
      "[LightGBM] [Info] Number of data points in the train set: 10844, number of used features: 248\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5136524826262826"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_test(feat_selector.transform(feats), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5833996\ttotal: 181ms\tremaining: 1m 12s\n",
      "1:\tlearn: 0.5113672\ttotal: 226ms\tremaining: 45s\n",
      "2:\tlearn: 0.4737487\ttotal: 271ms\tremaining: 35.9s\n",
      "3:\tlearn: 0.4495428\ttotal: 322ms\tremaining: 31.9s\n",
      "4:\tlearn: 0.4260257\ttotal: 372ms\tremaining: 29.4s\n",
      "5:\tlearn: 0.4089173\ttotal: 428ms\tremaining: 28.1s\n",
      "6:\tlearn: 0.4006509\ttotal: 474ms\tremaining: 26.6s\n",
      "7:\tlearn: 0.3889901\ttotal: 526ms\tremaining: 25.8s\n",
      "8:\tlearn: 0.3808598\ttotal: 600ms\tremaining: 26.1s\n",
      "9:\tlearn: 0.3737514\ttotal: 658ms\tremaining: 25.7s\n",
      "10:\tlearn: 0.3680432\ttotal: 702ms\tremaining: 24.8s\n",
      "11:\tlearn: 0.3636558\ttotal: 746ms\tremaining: 24.1s\n",
      "12:\tlearn: 0.3585111\ttotal: 815ms\tremaining: 24.3s\n",
      "13:\tlearn: 0.3539373\ttotal: 864ms\tremaining: 23.8s\n",
      "14:\tlearn: 0.3505214\ttotal: 919ms\tremaining: 23.6s\n",
      "15:\tlearn: 0.3474621\ttotal: 982ms\tremaining: 23.6s\n",
      "16:\tlearn: 0.3441163\ttotal: 1.05s\tremaining: 23.8s\n",
      "17:\tlearn: 0.3407552\ttotal: 1.1s\tremaining: 23.4s\n",
      "18:\tlearn: 0.3376195\ttotal: 1.15s\tremaining: 23s\n",
      "19:\tlearn: 0.3341574\ttotal: 1.21s\tremaining: 23s\n",
      "20:\tlearn: 0.3318644\ttotal: 1.27s\tremaining: 22.9s\n",
      "21:\tlearn: 0.3293415\ttotal: 1.31s\tremaining: 22.6s\n",
      "22:\tlearn: 0.3268892\ttotal: 1.35s\tremaining: 22.2s\n",
      "23:\tlearn: 0.3243159\ttotal: 1.4s\tremaining: 22s\n",
      "24:\tlearn: 0.3227316\ttotal: 1.45s\tremaining: 21.7s\n",
      "25:\tlearn: 0.3202115\ttotal: 1.49s\tremaining: 21.4s\n",
      "26:\tlearn: 0.3181174\ttotal: 1.53s\tremaining: 21.2s\n",
      "27:\tlearn: 0.3160253\ttotal: 1.57s\tremaining: 20.9s\n",
      "28:\tlearn: 0.3132193\ttotal: 1.61s\tremaining: 20.6s\n",
      "29:\tlearn: 0.3119304\ttotal: 1.66s\tremaining: 20.4s\n",
      "30:\tlearn: 0.3100238\ttotal: 1.69s\tremaining: 20.2s\n",
      "31:\tlearn: 0.3076471\ttotal: 1.73s\tremaining: 19.9s\n",
      "32:\tlearn: 0.3059226\ttotal: 1.78s\tremaining: 19.8s\n",
      "33:\tlearn: 0.3042168\ttotal: 1.84s\tremaining: 19.8s\n",
      "34:\tlearn: 0.3018941\ttotal: 1.9s\tremaining: 19.9s\n",
      "35:\tlearn: 0.3000503\ttotal: 1.95s\tremaining: 19.7s\n",
      "36:\tlearn: 0.2981203\ttotal: 2s\tremaining: 19.6s\n",
      "37:\tlearn: 0.2962417\ttotal: 2.04s\tremaining: 19.4s\n",
      "38:\tlearn: 0.2941891\ttotal: 2.08s\tremaining: 19.3s\n",
      "39:\tlearn: 0.2922083\ttotal: 2.12s\tremaining: 19.1s\n",
      "40:\tlearn: 0.2908082\ttotal: 2.16s\tremaining: 18.9s\n",
      "41:\tlearn: 0.2885513\ttotal: 2.2s\tremaining: 18.7s\n",
      "42:\tlearn: 0.2871091\ttotal: 2.26s\tremaining: 18.8s\n",
      "43:\tlearn: 0.2852201\ttotal: 2.32s\tremaining: 18.8s\n",
      "44:\tlearn: 0.2837894\ttotal: 2.36s\tremaining: 18.6s\n",
      "45:\tlearn: 0.2812734\ttotal: 2.41s\tremaining: 18.5s\n",
      "46:\tlearn: 0.2788126\ttotal: 2.54s\tremaining: 19.1s\n",
      "47:\tlearn: 0.2776135\ttotal: 2.58s\tremaining: 18.9s\n",
      "48:\tlearn: 0.2751781\ttotal: 2.63s\tremaining: 18.8s\n",
      "49:\tlearn: 0.2739017\ttotal: 2.66s\tremaining: 18.6s\n",
      "50:\tlearn: 0.2718638\ttotal: 2.71s\tremaining: 18.5s\n",
      "51:\tlearn: 0.2706675\ttotal: 2.76s\tremaining: 18.5s\n",
      "52:\tlearn: 0.2683720\ttotal: 2.79s\tremaining: 18.3s\n",
      "53:\tlearn: 0.2674673\ttotal: 2.83s\tremaining: 18.2s\n",
      "54:\tlearn: 0.2656936\ttotal: 2.91s\tremaining: 18.2s\n",
      "55:\tlearn: 0.2642670\ttotal: 2.97s\tremaining: 18.2s\n",
      "56:\tlearn: 0.2628282\ttotal: 3.01s\tremaining: 18.1s\n",
      "57:\tlearn: 0.2599150\ttotal: 3.07s\tremaining: 18.1s\n",
      "58:\tlearn: 0.2582880\ttotal: 3.15s\tremaining: 18.2s\n",
      "59:\tlearn: 0.2559853\ttotal: 3.19s\tremaining: 18.1s\n",
      "60:\tlearn: 0.2545445\ttotal: 3.24s\tremaining: 18s\n",
      "61:\tlearn: 0.2529544\ttotal: 3.27s\tremaining: 17.9s\n",
      "62:\tlearn: 0.2505302\ttotal: 3.31s\tremaining: 17.7s\n",
      "63:\tlearn: 0.2483386\ttotal: 3.35s\tremaining: 17.6s\n",
      "64:\tlearn: 0.2462135\ttotal: 3.39s\tremaining: 17.5s\n",
      "65:\tlearn: 0.2441452\ttotal: 3.43s\tremaining: 17.3s\n",
      "66:\tlearn: 0.2426589\ttotal: 3.47s\tremaining: 17.2s\n",
      "67:\tlearn: 0.2408256\ttotal: 3.5s\tremaining: 17.1s\n",
      "68:\tlearn: 0.2390266\ttotal: 3.55s\tremaining: 17.1s\n",
      "69:\tlearn: 0.2366602\ttotal: 3.59s\tremaining: 16.9s\n",
      "70:\tlearn: 0.2353176\ttotal: 3.66s\tremaining: 17s\n",
      "71:\tlearn: 0.2330429\ttotal: 3.71s\tremaining: 16.9s\n",
      "72:\tlearn: 0.2312737\ttotal: 3.75s\tremaining: 16.8s\n",
      "73:\tlearn: 0.2299475\ttotal: 3.79s\tremaining: 16.7s\n",
      "74:\tlearn: 0.2293231\ttotal: 3.84s\tremaining: 16.6s\n",
      "75:\tlearn: 0.2277877\ttotal: 3.9s\tremaining: 16.6s\n",
      "76:\tlearn: 0.2264055\ttotal: 3.94s\tremaining: 16.5s\n",
      "77:\tlearn: 0.2247729\ttotal: 3.99s\tremaining: 16.5s\n",
      "78:\tlearn: 0.2239370\ttotal: 4.04s\tremaining: 16.4s\n",
      "79:\tlearn: 0.2221762\ttotal: 4.08s\tremaining: 16.3s\n",
      "80:\tlearn: 0.2198299\ttotal: 4.12s\tremaining: 16.2s\n",
      "81:\tlearn: 0.2185562\ttotal: 4.16s\tremaining: 16.1s\n",
      "82:\tlearn: 0.2175192\ttotal: 4.25s\tremaining: 16.2s\n",
      "83:\tlearn: 0.2162341\ttotal: 4.3s\tremaining: 16.2s\n",
      "84:\tlearn: 0.2143268\ttotal: 4.35s\tremaining: 16.1s\n",
      "85:\tlearn: 0.2128304\ttotal: 4.4s\tremaining: 16.1s\n",
      "86:\tlearn: 0.2111875\ttotal: 4.44s\tremaining: 16s\n",
      "87:\tlearn: 0.2098421\ttotal: 4.48s\tremaining: 15.9s\n",
      "88:\tlearn: 0.2080330\ttotal: 4.53s\tremaining: 15.8s\n",
      "89:\tlearn: 0.2061210\ttotal: 4.58s\tremaining: 15.8s\n",
      "90:\tlearn: 0.2048624\ttotal: 4.61s\tremaining: 15.7s\n",
      "91:\tlearn: 0.2034323\ttotal: 4.65s\tremaining: 15.6s\n",
      "92:\tlearn: 0.2018376\ttotal: 4.71s\tremaining: 15.5s\n",
      "93:\tlearn: 0.2005968\ttotal: 4.75s\tremaining: 15.5s\n",
      "94:\tlearn: 0.1989724\ttotal: 4.79s\tremaining: 15.4s\n",
      "95:\tlearn: 0.1977595\ttotal: 4.83s\tremaining: 15.3s\n",
      "96:\tlearn: 0.1965790\ttotal: 4.88s\tremaining: 15.3s\n",
      "97:\tlearn: 0.1955803\ttotal: 4.93s\tremaining: 15.2s\n",
      "98:\tlearn: 0.1944532\ttotal: 4.97s\tremaining: 15.1s\n",
      "99:\tlearn: 0.1930689\ttotal: 5.01s\tremaining: 15s\n",
      "100:\tlearn: 0.1916371\ttotal: 5.05s\tremaining: 14.9s\n",
      "101:\tlearn: 0.1903872\ttotal: 5.09s\tremaining: 14.9s\n",
      "102:\tlearn: 0.1890841\ttotal: 5.13s\tremaining: 14.8s\n",
      "103:\tlearn: 0.1879310\ttotal: 5.18s\tremaining: 14.7s\n",
      "104:\tlearn: 0.1867935\ttotal: 5.24s\tremaining: 14.7s\n",
      "105:\tlearn: 0.1859667\ttotal: 5.35s\tremaining: 14.8s\n",
      "106:\tlearn: 0.1845105\ttotal: 5.39s\tremaining: 14.8s\n",
      "107:\tlearn: 0.1828853\ttotal: 5.44s\tremaining: 14.7s\n",
      "108:\tlearn: 0.1815747\ttotal: 5.48s\tremaining: 14.6s\n",
      "109:\tlearn: 0.1803594\ttotal: 5.53s\tremaining: 14.6s\n",
      "110:\tlearn: 0.1795574\ttotal: 5.6s\tremaining: 14.6s\n",
      "111:\tlearn: 0.1788431\ttotal: 5.67s\tremaining: 14.6s\n",
      "112:\tlearn: 0.1777512\ttotal: 5.72s\tremaining: 14.5s\n",
      "113:\tlearn: 0.1763705\ttotal: 5.79s\tremaining: 14.5s\n",
      "114:\tlearn: 0.1746235\ttotal: 5.84s\tremaining: 14.5s\n",
      "115:\tlearn: 0.1737598\ttotal: 5.89s\tremaining: 14.4s\n",
      "116:\tlearn: 0.1727437\ttotal: 5.95s\tremaining: 14.4s\n",
      "117:\tlearn: 0.1708280\ttotal: 6.01s\tremaining: 14.4s\n",
      "118:\tlearn: 0.1703452\ttotal: 6.08s\tremaining: 14.4s\n",
      "119:\tlearn: 0.1694508\ttotal: 6.13s\tremaining: 14.3s\n",
      "120:\tlearn: 0.1685470\ttotal: 6.19s\tremaining: 14.3s\n",
      "121:\tlearn: 0.1678346\ttotal: 6.25s\tremaining: 14.2s\n",
      "122:\tlearn: 0.1669690\ttotal: 6.3s\tremaining: 14.2s\n",
      "123:\tlearn: 0.1661336\ttotal: 6.36s\tremaining: 14.1s\n",
      "124:\tlearn: 0.1652252\ttotal: 6.45s\tremaining: 14.2s\n",
      "125:\tlearn: 0.1643228\ttotal: 6.5s\tremaining: 14.1s\n",
      "126:\tlearn: 0.1631128\ttotal: 6.57s\tremaining: 14.1s\n",
      "127:\tlearn: 0.1622257\ttotal: 6.64s\tremaining: 14.1s\n",
      "128:\tlearn: 0.1611042\ttotal: 6.71s\tremaining: 14.1s\n",
      "129:\tlearn: 0.1600609\ttotal: 6.75s\tremaining: 14s\n",
      "130:\tlearn: 0.1593966\ttotal: 6.79s\tremaining: 13.9s\n",
      "131:\tlearn: 0.1583889\ttotal: 6.86s\tremaining: 13.9s\n",
      "132:\tlearn: 0.1578932\ttotal: 6.93s\tremaining: 13.9s\n",
      "133:\tlearn: 0.1571827\ttotal: 6.98s\tremaining: 13.8s\n",
      "134:\tlearn: 0.1555217\ttotal: 7.1s\tremaining: 13.9s\n",
      "135:\tlearn: 0.1546740\ttotal: 7.16s\tremaining: 13.9s\n",
      "136:\tlearn: 0.1533088\ttotal: 7.22s\tremaining: 13.9s\n",
      "137:\tlearn: 0.1524034\ttotal: 7.26s\tremaining: 13.8s\n",
      "138:\tlearn: 0.1515562\ttotal: 7.31s\tremaining: 13.7s\n",
      "139:\tlearn: 0.1511051\ttotal: 7.35s\tremaining: 13.7s\n",
      "140:\tlearn: 0.1503093\ttotal: 7.41s\tremaining: 13.6s\n",
      "141:\tlearn: 0.1490736\ttotal: 7.47s\tremaining: 13.6s\n",
      "142:\tlearn: 0.1482687\ttotal: 7.54s\tremaining: 13.5s\n",
      "143:\tlearn: 0.1471977\ttotal: 7.59s\tremaining: 13.5s\n",
      "144:\tlearn: 0.1461344\ttotal: 7.66s\tremaining: 13.5s\n",
      "145:\tlearn: 0.1453149\ttotal: 7.75s\tremaining: 13.5s\n",
      "146:\tlearn: 0.1446997\ttotal: 7.83s\tremaining: 13.5s\n",
      "147:\tlearn: 0.1436348\ttotal: 7.87s\tremaining: 13.4s\n",
      "148:\tlearn: 0.1428798\ttotal: 7.91s\tremaining: 13.3s\n",
      "149:\tlearn: 0.1417114\ttotal: 7.96s\tremaining: 13.3s\n",
      "150:\tlearn: 0.1407085\ttotal: 8.04s\tremaining: 13.3s\n",
      "151:\tlearn: 0.1399032\ttotal: 8.09s\tremaining: 13.2s\n",
      "152:\tlearn: 0.1395025\ttotal: 8.18s\tremaining: 13.2s\n",
      "153:\tlearn: 0.1384115\ttotal: 8.24s\tremaining: 13.2s\n",
      "154:\tlearn: 0.1378931\ttotal: 8.29s\tremaining: 13.1s\n",
      "155:\tlearn: 0.1366850\ttotal: 8.37s\tremaining: 13.1s\n",
      "156:\tlearn: 0.1362989\ttotal: 8.45s\tremaining: 13.1s\n",
      "157:\tlearn: 0.1356513\ttotal: 8.53s\tremaining: 13.1s\n",
      "158:\tlearn: 0.1347133\ttotal: 8.6s\tremaining: 13s\n",
      "159:\tlearn: 0.1342453\ttotal: 8.64s\tremaining: 13s\n",
      "160:\tlearn: 0.1330337\ttotal: 8.68s\tremaining: 12.9s\n",
      "161:\tlearn: 0.1320901\ttotal: 8.72s\tremaining: 12.8s\n",
      "162:\tlearn: 0.1311649\ttotal: 8.79s\tremaining: 12.8s\n",
      "163:\tlearn: 0.1302388\ttotal: 8.87s\tremaining: 12.8s\n",
      "164:\tlearn: 0.1295155\ttotal: 8.91s\tremaining: 12.7s\n",
      "165:\tlearn: 0.1292329\ttotal: 8.96s\tremaining: 12.6s\n",
      "166:\tlearn: 0.1280898\ttotal: 9.01s\tremaining: 12.6s\n",
      "167:\tlearn: 0.1267873\ttotal: 9.05s\tremaining: 12.5s\n",
      "168:\tlearn: 0.1257144\ttotal: 9.13s\tremaining: 12.5s\n",
      "169:\tlearn: 0.1252506\ttotal: 9.18s\tremaining: 12.4s\n",
      "170:\tlearn: 0.1244654\ttotal: 9.25s\tremaining: 12.4s\n",
      "171:\tlearn: 0.1238285\ttotal: 9.32s\tremaining: 12.3s\n",
      "172:\tlearn: 0.1236197\ttotal: 9.35s\tremaining: 12.3s\n",
      "173:\tlearn: 0.1224125\ttotal: 9.44s\tremaining: 12.3s\n",
      "174:\tlearn: 0.1219024\ttotal: 9.49s\tremaining: 12.2s\n",
      "175:\tlearn: 0.1213168\ttotal: 9.54s\tremaining: 12.1s\n",
      "176:\tlearn: 0.1208462\ttotal: 9.64s\tremaining: 12.1s\n",
      "177:\tlearn: 0.1200465\ttotal: 9.71s\tremaining: 12.1s\n",
      "178:\tlearn: 0.1193778\ttotal: 9.79s\tremaining: 12.1s\n",
      "179:\tlearn: 0.1184845\ttotal: 9.84s\tremaining: 12s\n",
      "180:\tlearn: 0.1176056\ttotal: 9.89s\tremaining: 12s\n",
      "181:\tlearn: 0.1171578\ttotal: 9.97s\tremaining: 11.9s\n",
      "182:\tlearn: 0.1163139\ttotal: 10s\tremaining: 11.9s\n",
      "183:\tlearn: 0.1157679\ttotal: 10.1s\tremaining: 11.9s\n",
      "184:\tlearn: 0.1150389\ttotal: 10.2s\tremaining: 11.8s\n",
      "185:\tlearn: 0.1144561\ttotal: 10.3s\tremaining: 11.8s\n",
      "186:\tlearn: 0.1137780\ttotal: 10.3s\tremaining: 11.7s\n",
      "187:\tlearn: 0.1131989\ttotal: 10.4s\tremaining: 11.7s\n",
      "188:\tlearn: 0.1122672\ttotal: 10.4s\tremaining: 11.6s\n",
      "189:\tlearn: 0.1116431\ttotal: 10.6s\tremaining: 11.7s\n",
      "190:\tlearn: 0.1109163\ttotal: 10.6s\tremaining: 11.6s\n",
      "191:\tlearn: 0.1102857\ttotal: 10.7s\tremaining: 11.6s\n",
      "192:\tlearn: 0.1096385\ttotal: 10.7s\tremaining: 11.5s\n",
      "193:\tlearn: 0.1090771\ttotal: 10.8s\tremaining: 11.4s\n",
      "194:\tlearn: 0.1080574\ttotal: 10.9s\tremaining: 11.4s\n",
      "195:\tlearn: 0.1075277\ttotal: 11s\tremaining: 11.4s\n",
      "196:\tlearn: 0.1068756\ttotal: 11s\tremaining: 11.4s\n",
      "197:\tlearn: 0.1066869\ttotal: 11.1s\tremaining: 11.4s\n",
      "198:\tlearn: 0.1064055\ttotal: 11.2s\tremaining: 11.3s\n",
      "199:\tlearn: 0.1057371\ttotal: 11.3s\tremaining: 11.3s\n",
      "200:\tlearn: 0.1051413\ttotal: 11.4s\tremaining: 11.3s\n",
      "201:\tlearn: 0.1045198\ttotal: 11.5s\tremaining: 11.3s\n",
      "202:\tlearn: 0.1038754\ttotal: 11.6s\tremaining: 11.2s\n",
      "203:\tlearn: 0.1035248\ttotal: 11.6s\tremaining: 11.2s\n",
      "204:\tlearn: 0.1031742\ttotal: 11.7s\tremaining: 11.1s\n",
      "205:\tlearn: 0.1022845\ttotal: 11.7s\tremaining: 11.1s\n",
      "206:\tlearn: 0.1015073\ttotal: 11.8s\tremaining: 11s\n",
      "207:\tlearn: 0.1008692\ttotal: 11.9s\tremaining: 11s\n",
      "208:\tlearn: 0.1005243\ttotal: 11.9s\tremaining: 10.9s\n",
      "209:\tlearn: 0.0998846\ttotal: 12.1s\tremaining: 10.9s\n",
      "210:\tlearn: 0.0988604\ttotal: 12.2s\tremaining: 10.9s\n",
      "211:\tlearn: 0.0982774\ttotal: 12.3s\tremaining: 10.9s\n",
      "212:\tlearn: 0.0977782\ttotal: 12.3s\tremaining: 10.8s\n",
      "213:\tlearn: 0.0975009\ttotal: 12.4s\tremaining: 10.8s\n",
      "214:\tlearn: 0.0968217\ttotal: 12.5s\tremaining: 10.7s\n",
      "215:\tlearn: 0.0962848\ttotal: 12.5s\tremaining: 10.7s\n",
      "216:\tlearn: 0.0958930\ttotal: 12.6s\tremaining: 10.6s\n",
      "217:\tlearn: 0.0954834\ttotal: 12.6s\tremaining: 10.5s\n",
      "218:\tlearn: 0.0947213\ttotal: 12.7s\tremaining: 10.5s\n",
      "219:\tlearn: 0.0940259\ttotal: 12.7s\tremaining: 10.4s\n",
      "220:\tlearn: 0.0934181\ttotal: 12.7s\tremaining: 10.3s\n",
      "221:\tlearn: 0.0928300\ttotal: 12.8s\tremaining: 10.3s\n",
      "222:\tlearn: 0.0925661\ttotal: 12.8s\tremaining: 10.2s\n",
      "223:\tlearn: 0.0918272\ttotal: 12.9s\tremaining: 10.1s\n",
      "224:\tlearn: 0.0913375\ttotal: 12.9s\tremaining: 10.1s\n",
      "225:\tlearn: 0.0908253\ttotal: 13s\tremaining: 10s\n",
      "226:\tlearn: 0.0902734\ttotal: 13.1s\tremaining: 9.95s\n",
      "227:\tlearn: 0.0899290\ttotal: 13.1s\tremaining: 9.89s\n",
      "228:\tlearn: 0.0893099\ttotal: 13.2s\tremaining: 9.83s\n",
      "229:\tlearn: 0.0888888\ttotal: 13.2s\tremaining: 9.78s\n",
      "230:\tlearn: 0.0883775\ttotal: 13.3s\tremaining: 9.71s\n",
      "231:\tlearn: 0.0876170\ttotal: 13.3s\tremaining: 9.65s\n",
      "232:\tlearn: 0.0869775\ttotal: 13.4s\tremaining: 9.58s\n",
      "233:\tlearn: 0.0863402\ttotal: 13.4s\tremaining: 9.52s\n",
      "234:\tlearn: 0.0858894\ttotal: 13.5s\tremaining: 9.45s\n",
      "235:\tlearn: 0.0855974\ttotal: 13.5s\tremaining: 9.39s\n",
      "236:\tlearn: 0.0853028\ttotal: 13.6s\tremaining: 9.32s\n",
      "237:\tlearn: 0.0849725\ttotal: 13.6s\tremaining: 9.25s\n",
      "238:\tlearn: 0.0844739\ttotal: 13.6s\tremaining: 9.19s\n",
      "239:\tlearn: 0.0840580\ttotal: 13.7s\tremaining: 9.12s\n",
      "240:\tlearn: 0.0838567\ttotal: 13.8s\tremaining: 9.08s\n",
      "241:\tlearn: 0.0834278\ttotal: 13.8s\tremaining: 9.01s\n",
      "242:\tlearn: 0.0829280\ttotal: 13.9s\tremaining: 8.97s\n",
      "243:\tlearn: 0.0822920\ttotal: 13.9s\tremaining: 8.91s\n",
      "244:\tlearn: 0.0820172\ttotal: 14s\tremaining: 8.84s\n",
      "245:\tlearn: 0.0813056\ttotal: 14.1s\tremaining: 8.8s\n",
      "246:\tlearn: 0.0809736\ttotal: 14.1s\tremaining: 8.74s\n",
      "247:\tlearn: 0.0805183\ttotal: 14.2s\tremaining: 8.68s\n",
      "248:\tlearn: 0.0803688\ttotal: 14.2s\tremaining: 8.62s\n",
      "249:\tlearn: 0.0798215\ttotal: 14.3s\tremaining: 8.55s\n",
      "250:\tlearn: 0.0793922\ttotal: 14.3s\tremaining: 8.52s\n",
      "251:\tlearn: 0.0788591\ttotal: 14.4s\tremaining: 8.46s\n",
      "252:\tlearn: 0.0783478\ttotal: 14.5s\tremaining: 8.4s\n",
      "253:\tlearn: 0.0780304\ttotal: 14.5s\tremaining: 8.34s\n",
      "254:\tlearn: 0.0774193\ttotal: 14.6s\tremaining: 8.28s\n",
      "255:\tlearn: 0.0767552\ttotal: 14.6s\tremaining: 8.22s\n",
      "256:\tlearn: 0.0761799\ttotal: 14.7s\tremaining: 8.15s\n",
      "257:\tlearn: 0.0760084\ttotal: 14.7s\tremaining: 8.09s\n",
      "258:\tlearn: 0.0756437\ttotal: 14.7s\tremaining: 8.03s\n",
      "259:\tlearn: 0.0753693\ttotal: 14.8s\tremaining: 7.96s\n",
      "260:\tlearn: 0.0751573\ttotal: 14.8s\tremaining: 7.9s\n",
      "261:\tlearn: 0.0747561\ttotal: 14.9s\tremaining: 7.83s\n",
      "262:\tlearn: 0.0744045\ttotal: 14.9s\tremaining: 7.76s\n",
      "263:\tlearn: 0.0740911\ttotal: 15s\tremaining: 7.71s\n",
      "264:\tlearn: 0.0734342\ttotal: 15s\tremaining: 7.64s\n",
      "265:\tlearn: 0.0732680\ttotal: 15.1s\tremaining: 7.58s\n",
      "266:\tlearn: 0.0728941\ttotal: 15.1s\tremaining: 7.53s\n",
      "267:\tlearn: 0.0725928\ttotal: 15.2s\tremaining: 7.47s\n",
      "268:\tlearn: 0.0720645\ttotal: 15.2s\tremaining: 7.41s\n",
      "269:\tlearn: 0.0718426\ttotal: 15.2s\tremaining: 7.34s\n",
      "270:\tlearn: 0.0715412\ttotal: 15.3s\tremaining: 7.28s\n",
      "271:\tlearn: 0.0711150\ttotal: 15.3s\tremaining: 7.21s\n",
      "272:\tlearn: 0.0706517\ttotal: 15.4s\tremaining: 7.15s\n",
      "273:\tlearn: 0.0701328\ttotal: 15.4s\tremaining: 7.09s\n",
      "274:\tlearn: 0.0698164\ttotal: 15.5s\tremaining: 7.02s\n",
      "275:\tlearn: 0.0694819\ttotal: 15.5s\tremaining: 6.96s\n",
      "276:\tlearn: 0.0692878\ttotal: 15.5s\tremaining: 6.9s\n",
      "277:\tlearn: 0.0688179\ttotal: 15.6s\tremaining: 6.84s\n",
      "278:\tlearn: 0.0681767\ttotal: 15.6s\tremaining: 6.78s\n",
      "279:\tlearn: 0.0678208\ttotal: 15.7s\tremaining: 6.72s\n",
      "280:\tlearn: 0.0674907\ttotal: 15.7s\tremaining: 6.66s\n",
      "281:\tlearn: 0.0672157\ttotal: 15.8s\tremaining: 6.6s\n",
      "282:\tlearn: 0.0670059\ttotal: 15.8s\tremaining: 6.55s\n",
      "283:\tlearn: 0.0667894\ttotal: 15.9s\tremaining: 6.49s\n",
      "284:\tlearn: 0.0662576\ttotal: 15.9s\tremaining: 6.43s\n",
      "285:\tlearn: 0.0659653\ttotal: 16s\tremaining: 6.37s\n",
      "286:\tlearn: 0.0656461\ttotal: 16s\tremaining: 6.31s\n",
      "287:\tlearn: 0.0653500\ttotal: 16.1s\tremaining: 6.25s\n",
      "288:\tlearn: 0.0650419\ttotal: 16.1s\tremaining: 6.19s\n",
      "289:\tlearn: 0.0647815\ttotal: 16.2s\tremaining: 6.13s\n",
      "290:\tlearn: 0.0644682\ttotal: 16.2s\tremaining: 6.07s\n",
      "291:\tlearn: 0.0642545\ttotal: 16.2s\tremaining: 6s\n",
      "292:\tlearn: 0.0639049\ttotal: 16.3s\tremaining: 5.95s\n",
      "293:\tlearn: 0.0636102\ttotal: 16.3s\tremaining: 5.88s\n",
      "294:\tlearn: 0.0633622\ttotal: 16.4s\tremaining: 5.83s\n",
      "295:\tlearn: 0.0629257\ttotal: 16.4s\tremaining: 5.77s\n",
      "296:\tlearn: 0.0624412\ttotal: 16.5s\tremaining: 5.71s\n",
      "297:\tlearn: 0.0620620\ttotal: 16.5s\tremaining: 5.66s\n",
      "298:\tlearn: 0.0614489\ttotal: 16.6s\tremaining: 5.6s\n",
      "299:\tlearn: 0.0613010\ttotal: 16.6s\tremaining: 5.54s\n",
      "300:\tlearn: 0.0609799\ttotal: 16.7s\tremaining: 5.48s\n",
      "301:\tlearn: 0.0606253\ttotal: 16.7s\tremaining: 5.42s\n",
      "302:\tlearn: 0.0602601\ttotal: 16.8s\tremaining: 5.37s\n",
      "303:\tlearn: 0.0599280\ttotal: 16.8s\tremaining: 5.31s\n",
      "304:\tlearn: 0.0595967\ttotal: 16.9s\tremaining: 5.25s\n",
      "305:\tlearn: 0.0591956\ttotal: 16.9s\tremaining: 5.19s\n",
      "306:\tlearn: 0.0587361\ttotal: 16.9s\tremaining: 5.13s\n",
      "307:\tlearn: 0.0585123\ttotal: 17s\tremaining: 5.07s\n",
      "308:\tlearn: 0.0583242\ttotal: 17s\tremaining: 5.02s\n",
      "309:\tlearn: 0.0581415\ttotal: 17.1s\tremaining: 4.96s\n",
      "310:\tlearn: 0.0575893\ttotal: 17.1s\tremaining: 4.91s\n",
      "311:\tlearn: 0.0573479\ttotal: 17.2s\tremaining: 4.84s\n",
      "312:\tlearn: 0.0569426\ttotal: 17.2s\tremaining: 4.79s\n",
      "313:\tlearn: 0.0567493\ttotal: 17.3s\tremaining: 4.74s\n",
      "314:\tlearn: 0.0566260\ttotal: 17.4s\tremaining: 4.68s\n",
      "315:\tlearn: 0.0564516\ttotal: 17.4s\tremaining: 4.62s\n",
      "316:\tlearn: 0.0561476\ttotal: 17.5s\tremaining: 4.57s\n",
      "317:\tlearn: 0.0560646\ttotal: 17.5s\tremaining: 4.52s\n",
      "318:\tlearn: 0.0558256\ttotal: 17.6s\tremaining: 4.46s\n",
      "319:\tlearn: 0.0556305\ttotal: 17.6s\tremaining: 4.41s\n",
      "320:\tlearn: 0.0552341\ttotal: 17.7s\tremaining: 4.35s\n",
      "321:\tlearn: 0.0549617\ttotal: 17.7s\tremaining: 4.29s\n",
      "322:\tlearn: 0.0549265\ttotal: 17.8s\tremaining: 4.23s\n",
      "323:\tlearn: 0.0546846\ttotal: 17.8s\tremaining: 4.17s\n",
      "324:\tlearn: 0.0545146\ttotal: 17.8s\tremaining: 4.12s\n",
      "325:\tlearn: 0.0542750\ttotal: 17.9s\tremaining: 4.06s\n",
      "326:\tlearn: 0.0540164\ttotal: 18s\tremaining: 4.01s\n",
      "327:\tlearn: 0.0536864\ttotal: 18s\tremaining: 3.95s\n",
      "328:\tlearn: 0.0532985\ttotal: 18.1s\tremaining: 3.9s\n",
      "329:\tlearn: 0.0529252\ttotal: 18.1s\tremaining: 3.84s\n",
      "330:\tlearn: 0.0526969\ttotal: 18.2s\tremaining: 3.79s\n",
      "331:\tlearn: 0.0522837\ttotal: 18.2s\tremaining: 3.73s\n",
      "332:\tlearn: 0.0521571\ttotal: 18.3s\tremaining: 3.67s\n",
      "333:\tlearn: 0.0517798\ttotal: 18.3s\tremaining: 3.61s\n",
      "334:\tlearn: 0.0515081\ttotal: 18.3s\tremaining: 3.56s\n",
      "335:\tlearn: 0.0510888\ttotal: 18.4s\tremaining: 3.51s\n",
      "336:\tlearn: 0.0509228\ttotal: 18.5s\tremaining: 3.45s\n",
      "337:\tlearn: 0.0506271\ttotal: 18.5s\tremaining: 3.4s\n",
      "338:\tlearn: 0.0503841\ttotal: 18.6s\tremaining: 3.34s\n",
      "339:\tlearn: 0.0499954\ttotal: 18.6s\tremaining: 3.28s\n",
      "340:\tlearn: 0.0497610\ttotal: 18.7s\tremaining: 3.23s\n",
      "341:\tlearn: 0.0494592\ttotal: 18.7s\tremaining: 3.17s\n",
      "342:\tlearn: 0.0491005\ttotal: 18.8s\tremaining: 3.12s\n",
      "343:\tlearn: 0.0487826\ttotal: 18.8s\tremaining: 3.06s\n",
      "344:\tlearn: 0.0485689\ttotal: 18.9s\tremaining: 3.01s\n",
      "345:\tlearn: 0.0483222\ttotal: 18.9s\tremaining: 2.95s\n",
      "346:\tlearn: 0.0479822\ttotal: 19s\tremaining: 2.89s\n",
      "347:\tlearn: 0.0477017\ttotal: 19s\tremaining: 2.84s\n",
      "348:\tlearn: 0.0475461\ttotal: 19s\tremaining: 2.78s\n",
      "349:\tlearn: 0.0471551\ttotal: 19.1s\tremaining: 2.72s\n",
      "350:\tlearn: 0.0469493\ttotal: 19.1s\tremaining: 2.67s\n",
      "351:\tlearn: 0.0466353\ttotal: 19.1s\tremaining: 2.61s\n",
      "352:\tlearn: 0.0464485\ttotal: 19.2s\tremaining: 2.56s\n",
      "353:\tlearn: 0.0462101\ttotal: 19.2s\tremaining: 2.5s\n",
      "354:\tlearn: 0.0460460\ttotal: 19.3s\tremaining: 2.44s\n",
      "355:\tlearn: 0.0458335\ttotal: 19.3s\tremaining: 2.39s\n",
      "356:\tlearn: 0.0455374\ttotal: 19.3s\tremaining: 2.33s\n",
      "357:\tlearn: 0.0453704\ttotal: 19.4s\tremaining: 2.27s\n",
      "358:\tlearn: 0.0451906\ttotal: 19.4s\tremaining: 2.22s\n",
      "359:\tlearn: 0.0449556\ttotal: 19.5s\tremaining: 2.17s\n",
      "360:\tlearn: 0.0447553\ttotal: 19.5s\tremaining: 2.11s\n",
      "361:\tlearn: 0.0444248\ttotal: 19.6s\tremaining: 2.06s\n",
      "362:\tlearn: 0.0441968\ttotal: 19.6s\tremaining: 2s\n",
      "363:\tlearn: 0.0439954\ttotal: 19.7s\tremaining: 1.95s\n",
      "364:\tlearn: 0.0439214\ttotal: 19.7s\tremaining: 1.89s\n",
      "365:\tlearn: 0.0436093\ttotal: 19.8s\tremaining: 1.83s\n",
      "366:\tlearn: 0.0433061\ttotal: 19.8s\tremaining: 1.78s\n",
      "367:\tlearn: 0.0430147\ttotal: 19.8s\tremaining: 1.73s\n",
      "368:\tlearn: 0.0428207\ttotal: 19.9s\tremaining: 1.67s\n",
      "369:\tlearn: 0.0426452\ttotal: 19.9s\tremaining: 1.62s\n",
      "370:\tlearn: 0.0423671\ttotal: 20s\tremaining: 1.56s\n",
      "371:\tlearn: 0.0420632\ttotal: 20.1s\tremaining: 1.51s\n",
      "372:\tlearn: 0.0418800\ttotal: 20.2s\tremaining: 1.46s\n",
      "373:\tlearn: 0.0417501\ttotal: 20.2s\tremaining: 1.4s\n",
      "374:\tlearn: 0.0415717\ttotal: 20.3s\tremaining: 1.35s\n",
      "375:\tlearn: 0.0414048\ttotal: 20.3s\tremaining: 1.3s\n",
      "376:\tlearn: 0.0411833\ttotal: 20.3s\tremaining: 1.24s\n",
      "377:\tlearn: 0.0409927\ttotal: 20.4s\tremaining: 1.19s\n",
      "378:\tlearn: 0.0408303\ttotal: 20.4s\tremaining: 1.13s\n",
      "379:\tlearn: 0.0406928\ttotal: 20.5s\tremaining: 1.08s\n",
      "380:\tlearn: 0.0405023\ttotal: 20.5s\tremaining: 1.02s\n",
      "381:\tlearn: 0.0402990\ttotal: 20.5s\tremaining: 968ms\n",
      "382:\tlearn: 0.0400747\ttotal: 20.6s\tremaining: 914ms\n",
      "383:\tlearn: 0.0398707\ttotal: 20.6s\tremaining: 860ms\n",
      "384:\tlearn: 0.0397385\ttotal: 20.7s\tremaining: 806ms\n",
      "385:\tlearn: 0.0395336\ttotal: 20.7s\tremaining: 752ms\n",
      "386:\tlearn: 0.0393502\ttotal: 20.8s\tremaining: 697ms\n",
      "387:\tlearn: 0.0391974\ttotal: 20.8s\tremaining: 643ms\n",
      "388:\tlearn: 0.0391128\ttotal: 20.8s\tremaining: 589ms\n",
      "389:\tlearn: 0.0389757\ttotal: 20.9s\tremaining: 536ms\n",
      "390:\tlearn: 0.0388848\ttotal: 21s\tremaining: 483ms\n",
      "391:\tlearn: 0.0387821\ttotal: 21s\tremaining: 429ms\n",
      "392:\tlearn: 0.0385752\ttotal: 21.1s\tremaining: 375ms\n",
      "393:\tlearn: 0.0385187\ttotal: 21.1s\tremaining: 322ms\n",
      "394:\tlearn: 0.0384130\ttotal: 21.2s\tremaining: 268ms\n",
      "395:\tlearn: 0.0383370\ttotal: 21.2s\tremaining: 214ms\n",
      "396:\tlearn: 0.0381189\ttotal: 21.2s\tremaining: 161ms\n",
      "397:\tlearn: 0.0380110\ttotal: 21.3s\tremaining: 107ms\n",
      "398:\tlearn: 0.0378764\ttotal: 21.3s\tremaining: 53.5ms\n",
      "399:\tlearn: 0.0378092\ttotal: 21.4s\tremaining: 0us\n",
      "0:\tlearn: 0.5776135\ttotal: 60.9ms\tremaining: 24.3s\n",
      "1:\tlearn: 0.5179939\ttotal: 114ms\tremaining: 22.7s\n",
      "2:\tlearn: 0.4750864\ttotal: 164ms\tremaining: 21.6s\n",
      "3:\tlearn: 0.4471523\ttotal: 200ms\tremaining: 19.8s\n",
      "4:\tlearn: 0.4248454\ttotal: 234ms\tremaining: 18.5s\n",
      "5:\tlearn: 0.4102516\ttotal: 275ms\tremaining: 18.1s\n",
      "6:\tlearn: 0.4010267\ttotal: 315ms\tremaining: 17.7s\n",
      "7:\tlearn: 0.3925331\ttotal: 358ms\tremaining: 17.5s\n",
      "8:\tlearn: 0.3849767\ttotal: 393ms\tremaining: 17.1s\n",
      "9:\tlearn: 0.3786416\ttotal: 434ms\tremaining: 16.9s\n",
      "10:\tlearn: 0.3727744\ttotal: 471ms\tremaining: 16.6s\n",
      "11:\tlearn: 0.3684133\ttotal: 512ms\tremaining: 16.6s\n",
      "12:\tlearn: 0.3635720\ttotal: 555ms\tremaining: 16.5s\n",
      "13:\tlearn: 0.3587587\ttotal: 592ms\tremaining: 16.3s\n",
      "14:\tlearn: 0.3553635\ttotal: 634ms\tremaining: 16.3s\n",
      "15:\tlearn: 0.3508611\ttotal: 670ms\tremaining: 16.1s\n",
      "16:\tlearn: 0.3466138\ttotal: 707ms\tremaining: 15.9s\n",
      "17:\tlearn: 0.3428932\ttotal: 749ms\tremaining: 15.9s\n",
      "18:\tlearn: 0.3395068\ttotal: 842ms\tremaining: 16.9s\n",
      "19:\tlearn: 0.3369082\ttotal: 903ms\tremaining: 17.1s\n",
      "20:\tlearn: 0.3336249\ttotal: 949ms\tremaining: 17.1s\n",
      "21:\tlearn: 0.3300848\ttotal: 1.02s\tremaining: 17.5s\n",
      "22:\tlearn: 0.3273076\ttotal: 1.07s\tremaining: 17.6s\n",
      "23:\tlearn: 0.3247560\ttotal: 1.11s\tremaining: 17.4s\n",
      "24:\tlearn: 0.3220361\ttotal: 1.18s\tremaining: 17.7s\n",
      "25:\tlearn: 0.3198435\ttotal: 1.23s\tremaining: 17.7s\n",
      "26:\tlearn: 0.3175801\ttotal: 1.29s\tremaining: 17.8s\n",
      "27:\tlearn: 0.3159143\ttotal: 1.35s\tremaining: 18s\n",
      "28:\tlearn: 0.3134396\ttotal: 1.44s\tremaining: 18.4s\n",
      "29:\tlearn: 0.3113391\ttotal: 1.48s\tremaining: 18.3s\n",
      "30:\tlearn: 0.3088170\ttotal: 1.53s\tremaining: 18.2s\n",
      "31:\tlearn: 0.3071129\ttotal: 1.59s\tremaining: 18.2s\n",
      "32:\tlearn: 0.3047467\ttotal: 1.64s\tremaining: 18.2s\n",
      "33:\tlearn: 0.3029495\ttotal: 1.69s\tremaining: 18.2s\n",
      "34:\tlearn: 0.3009245\ttotal: 1.74s\tremaining: 18.1s\n",
      "35:\tlearn: 0.2992368\ttotal: 1.79s\tremaining: 18.1s\n",
      "36:\tlearn: 0.2971345\ttotal: 1.84s\tremaining: 18.1s\n",
      "37:\tlearn: 0.2959424\ttotal: 1.89s\tremaining: 18s\n",
      "38:\tlearn: 0.2943435\ttotal: 1.94s\tremaining: 18s\n",
      "39:\tlearn: 0.2929804\ttotal: 1.99s\tremaining: 17.9s\n",
      "40:\tlearn: 0.2914080\ttotal: 2.04s\tremaining: 17.9s\n",
      "41:\tlearn: 0.2891037\ttotal: 2.09s\tremaining: 17.9s\n",
      "42:\tlearn: 0.2878102\ttotal: 2.14s\tremaining: 17.8s\n",
      "43:\tlearn: 0.2855167\ttotal: 2.21s\tremaining: 17.9s\n",
      "44:\tlearn: 0.2831698\ttotal: 2.26s\tremaining: 17.9s\n",
      "45:\tlearn: 0.2806693\ttotal: 2.31s\tremaining: 17.8s\n",
      "46:\tlearn: 0.2792207\ttotal: 2.37s\tremaining: 17.8s\n",
      "47:\tlearn: 0.2776630\ttotal: 2.41s\tremaining: 17.7s\n",
      "48:\tlearn: 0.2762029\ttotal: 2.46s\tremaining: 17.6s\n",
      "49:\tlearn: 0.2747153\ttotal: 2.51s\tremaining: 17.6s\n",
      "50:\tlearn: 0.2732290\ttotal: 2.6s\tremaining: 17.8s\n",
      "51:\tlearn: 0.2706130\ttotal: 2.67s\tremaining: 17.8s\n",
      "52:\tlearn: 0.2689386\ttotal: 2.72s\tremaining: 17.8s\n",
      "53:\tlearn: 0.2673826\ttotal: 2.77s\tremaining: 17.8s\n",
      "54:\tlearn: 0.2653245\ttotal: 2.83s\tremaining: 17.8s\n",
      "55:\tlearn: 0.2633262\ttotal: 2.92s\tremaining: 18s\n",
      "56:\tlearn: 0.2608189\ttotal: 3s\tremaining: 18.1s\n",
      "57:\tlearn: 0.2588667\ttotal: 3.12s\tremaining: 18.4s\n",
      "58:\tlearn: 0.2572561\ttotal: 3.25s\tremaining: 18.8s\n",
      "59:\tlearn: 0.2555349\ttotal: 3.33s\tremaining: 18.9s\n",
      "60:\tlearn: 0.2535013\ttotal: 3.43s\tremaining: 19.1s\n",
      "61:\tlearn: 0.2520462\ttotal: 3.6s\tremaining: 19.6s\n",
      "62:\tlearn: 0.2503111\ttotal: 3.68s\tremaining: 19.7s\n",
      "63:\tlearn: 0.2476276\ttotal: 3.77s\tremaining: 19.8s\n",
      "64:\tlearn: 0.2461265\ttotal: 3.85s\tremaining: 19.8s\n",
      "65:\tlearn: 0.2449589\ttotal: 3.92s\tremaining: 19.8s\n",
      "66:\tlearn: 0.2433818\ttotal: 3.99s\tremaining: 19.8s\n",
      "67:\tlearn: 0.2421071\ttotal: 4.07s\tremaining: 19.9s\n",
      "68:\tlearn: 0.2409573\ttotal: 4.15s\tremaining: 19.9s\n",
      "69:\tlearn: 0.2396907\ttotal: 4.23s\tremaining: 19.9s\n",
      "70:\tlearn: 0.2382249\ttotal: 4.31s\tremaining: 20s\n",
      "71:\tlearn: 0.2361336\ttotal: 4.38s\tremaining: 20s\n",
      "72:\tlearn: 0.2345156\ttotal: 4.47s\tremaining: 20s\n",
      "73:\tlearn: 0.2327463\ttotal: 4.56s\tremaining: 20.1s\n",
      "74:\tlearn: 0.2306469\ttotal: 4.66s\tremaining: 20.2s\n",
      "75:\tlearn: 0.2290128\ttotal: 4.73s\tremaining: 20.2s\n",
      "76:\tlearn: 0.2277805\ttotal: 4.8s\tremaining: 20.1s\n",
      "77:\tlearn: 0.2256863\ttotal: 4.84s\tremaining: 20s\n",
      "78:\tlearn: 0.2245059\ttotal: 4.89s\tremaining: 19.9s\n",
      "79:\tlearn: 0.2225371\ttotal: 4.96s\tremaining: 19.8s\n",
      "80:\tlearn: 0.2204837\ttotal: 5s\tremaining: 19.7s\n",
      "81:\tlearn: 0.2188758\ttotal: 5.04s\tremaining: 19.5s\n",
      "82:\tlearn: 0.2167710\ttotal: 5.07s\tremaining: 19.4s\n",
      "83:\tlearn: 0.2155837\ttotal: 5.11s\tremaining: 19.2s\n",
      "84:\tlearn: 0.2142126\ttotal: 5.18s\tremaining: 19.2s\n",
      "85:\tlearn: 0.2127159\ttotal: 5.26s\tremaining: 19.2s\n",
      "86:\tlearn: 0.2113191\ttotal: 5.31s\tremaining: 19.1s\n",
      "87:\tlearn: 0.2092924\ttotal: 5.35s\tremaining: 19s\n",
      "88:\tlearn: 0.2078081\ttotal: 5.39s\tremaining: 18.8s\n",
      "89:\tlearn: 0.2066790\ttotal: 5.43s\tremaining: 18.7s\n",
      "90:\tlearn: 0.2045464\ttotal: 5.46s\tremaining: 18.5s\n",
      "91:\tlearn: 0.2035671\ttotal: 5.5s\tremaining: 18.4s\n",
      "92:\tlearn: 0.2018684\ttotal: 5.54s\tremaining: 18.3s\n",
      "93:\tlearn: 0.2010771\ttotal: 5.58s\tremaining: 18.2s\n",
      "94:\tlearn: 0.1994493\ttotal: 5.62s\tremaining: 18.1s\n",
      "95:\tlearn: 0.1979049\ttotal: 5.66s\tremaining: 17.9s\n",
      "96:\tlearn: 0.1969198\ttotal: 5.7s\tremaining: 17.8s\n",
      "97:\tlearn: 0.1955703\ttotal: 5.78s\tremaining: 17.8s\n",
      "98:\tlearn: 0.1946291\ttotal: 5.83s\tremaining: 17.7s\n",
      "99:\tlearn: 0.1930210\ttotal: 5.88s\tremaining: 17.6s\n",
      "100:\tlearn: 0.1909180\ttotal: 5.92s\tremaining: 17.5s\n",
      "101:\tlearn: 0.1896225\ttotal: 5.98s\tremaining: 17.5s\n",
      "102:\tlearn: 0.1885405\ttotal: 6.03s\tremaining: 17.4s\n",
      "103:\tlearn: 0.1874967\ttotal: 6.08s\tremaining: 17.3s\n",
      "104:\tlearn: 0.1860903\ttotal: 6.12s\tremaining: 17.2s\n",
      "105:\tlearn: 0.1847458\ttotal: 6.16s\tremaining: 17.1s\n",
      "106:\tlearn: 0.1835471\ttotal: 6.23s\tremaining: 17s\n",
      "107:\tlearn: 0.1823994\ttotal: 6.29s\tremaining: 17s\n",
      "108:\tlearn: 0.1808685\ttotal: 6.34s\tremaining: 16.9s\n",
      "109:\tlearn: 0.1798904\ttotal: 6.38s\tremaining: 16.8s\n",
      "110:\tlearn: 0.1790053\ttotal: 6.43s\tremaining: 16.7s\n",
      "111:\tlearn: 0.1770225\ttotal: 6.47s\tremaining: 16.6s\n",
      "112:\tlearn: 0.1761370\ttotal: 6.51s\tremaining: 16.5s\n",
      "113:\tlearn: 0.1751145\ttotal: 6.61s\tremaining: 16.6s\n",
      "114:\tlearn: 0.1738319\ttotal: 6.65s\tremaining: 16.5s\n",
      "115:\tlearn: 0.1732834\ttotal: 6.69s\tremaining: 16.4s\n",
      "116:\tlearn: 0.1717745\ttotal: 6.79s\tremaining: 16.4s\n",
      "117:\tlearn: 0.1706198\ttotal: 6.84s\tremaining: 16.3s\n",
      "118:\tlearn: 0.1693927\ttotal: 6.88s\tremaining: 16.3s\n",
      "119:\tlearn: 0.1685186\ttotal: 6.92s\tremaining: 16.2s\n",
      "120:\tlearn: 0.1676018\ttotal: 6.97s\tremaining: 16.1s\n",
      "121:\tlearn: 0.1673571\ttotal: 7.04s\tremaining: 16s\n",
      "122:\tlearn: 0.1663467\ttotal: 7.13s\tremaining: 16.1s\n",
      "123:\tlearn: 0.1650671\ttotal: 7.2s\tremaining: 16s\n",
      "124:\tlearn: 0.1647235\ttotal: 7.25s\tremaining: 15.9s\n",
      "125:\tlearn: 0.1631989\ttotal: 7.34s\tremaining: 16s\n",
      "126:\tlearn: 0.1621204\ttotal: 7.41s\tremaining: 15.9s\n",
      "127:\tlearn: 0.1610343\ttotal: 7.46s\tremaining: 15.9s\n",
      "128:\tlearn: 0.1601031\ttotal: 7.52s\tremaining: 15.8s\n",
      "129:\tlearn: 0.1586631\ttotal: 7.59s\tremaining: 15.8s\n",
      "130:\tlearn: 0.1575455\ttotal: 7.64s\tremaining: 15.7s\n",
      "131:\tlearn: 0.1567554\ttotal: 7.72s\tremaining: 15.7s\n",
      "132:\tlearn: 0.1554991\ttotal: 7.82s\tremaining: 15.7s\n",
      "133:\tlearn: 0.1543285\ttotal: 7.92s\tremaining: 15.7s\n",
      "134:\tlearn: 0.1538306\ttotal: 8.03s\tremaining: 15.8s\n",
      "135:\tlearn: 0.1528613\ttotal: 8.12s\tremaining: 15.8s\n",
      "136:\tlearn: 0.1514802\ttotal: 8.24s\tremaining: 15.8s\n",
      "137:\tlearn: 0.1510315\ttotal: 8.32s\tremaining: 15.8s\n",
      "138:\tlearn: 0.1502875\ttotal: 8.42s\tremaining: 15.8s\n",
      "139:\tlearn: 0.1494188\ttotal: 8.52s\tremaining: 15.8s\n",
      "140:\tlearn: 0.1485520\ttotal: 8.6s\tremaining: 15.8s\n",
      "141:\tlearn: 0.1474944\ttotal: 8.75s\tremaining: 15.9s\n",
      "142:\tlearn: 0.1461753\ttotal: 8.84s\tremaining: 15.9s\n",
      "143:\tlearn: 0.1449982\ttotal: 8.93s\tremaining: 15.9s\n",
      "144:\tlearn: 0.1442222\ttotal: 9.02s\tremaining: 15.9s\n",
      "145:\tlearn: 0.1431893\ttotal: 9.11s\tremaining: 15.9s\n",
      "146:\tlearn: 0.1425308\ttotal: 9.24s\tremaining: 15.9s\n",
      "147:\tlearn: 0.1415860\ttotal: 9.34s\tremaining: 15.9s\n",
      "148:\tlearn: 0.1404791\ttotal: 9.46s\tremaining: 15.9s\n",
      "149:\tlearn: 0.1394732\ttotal: 9.54s\tremaining: 15.9s\n",
      "150:\tlearn: 0.1386321\ttotal: 9.62s\tremaining: 15.9s\n",
      "151:\tlearn: 0.1377130\ttotal: 9.74s\tremaining: 15.9s\n",
      "152:\tlearn: 0.1369831\ttotal: 9.82s\tremaining: 15.8s\n",
      "153:\tlearn: 0.1363535\ttotal: 9.89s\tremaining: 15.8s\n",
      "154:\tlearn: 0.1357061\ttotal: 10s\tremaining: 15.8s\n",
      "155:\tlearn: 0.1351302\ttotal: 10.1s\tremaining: 15.9s\n",
      "156:\tlearn: 0.1343912\ttotal: 10.2s\tremaining: 15.8s\n",
      "157:\tlearn: 0.1333110\ttotal: 10.3s\tremaining: 15.8s\n",
      "158:\tlearn: 0.1322589\ttotal: 10.4s\tremaining: 15.8s\n",
      "159:\tlearn: 0.1313705\ttotal: 10.5s\tremaining: 15.8s\n",
      "160:\tlearn: 0.1303653\ttotal: 10.6s\tremaining: 15.8s\n",
      "161:\tlearn: 0.1298101\ttotal: 10.7s\tremaining: 15.8s\n",
      "162:\tlearn: 0.1291144\ttotal: 10.8s\tremaining: 15.7s\n",
      "163:\tlearn: 0.1278115\ttotal: 10.9s\tremaining: 15.7s\n",
      "164:\tlearn: 0.1269249\ttotal: 11s\tremaining: 15.7s\n",
      "165:\tlearn: 0.1263364\ttotal: 11.1s\tremaining: 15.6s\n",
      "166:\tlearn: 0.1252677\ttotal: 11.2s\tremaining: 15.6s\n",
      "167:\tlearn: 0.1246237\ttotal: 11.2s\tremaining: 15.5s\n",
      "168:\tlearn: 0.1235903\ttotal: 11.4s\tremaining: 15.5s\n",
      "169:\tlearn: 0.1229914\ttotal: 11.5s\tremaining: 15.5s\n",
      "170:\tlearn: 0.1217976\ttotal: 11.6s\tremaining: 15.5s\n",
      "171:\tlearn: 0.1213608\ttotal: 11.7s\tremaining: 15.5s\n",
      "172:\tlearn: 0.1207034\ttotal: 11.7s\tremaining: 15.4s\n",
      "173:\tlearn: 0.1197206\ttotal: 11.9s\tremaining: 15.4s\n",
      "174:\tlearn: 0.1191919\ttotal: 12s\tremaining: 15.4s\n",
      "175:\tlearn: 0.1181445\ttotal: 12.1s\tremaining: 15.4s\n",
      "176:\tlearn: 0.1178845\ttotal: 12.2s\tremaining: 15.4s\n",
      "177:\tlearn: 0.1174233\ttotal: 12.3s\tremaining: 15.4s\n",
      "178:\tlearn: 0.1166751\ttotal: 12.4s\tremaining: 15.3s\n",
      "179:\tlearn: 0.1162574\ttotal: 12.5s\tremaining: 15.3s\n",
      "180:\tlearn: 0.1153788\ttotal: 12.6s\tremaining: 15.2s\n",
      "181:\tlearn: 0.1143659\ttotal: 12.6s\tremaining: 15.1s\n",
      "182:\tlearn: 0.1134893\ttotal: 12.7s\tremaining: 15.1s\n",
      "183:\tlearn: 0.1128012\ttotal: 12.8s\tremaining: 15s\n",
      "184:\tlearn: 0.1124539\ttotal: 12.9s\tremaining: 15s\n",
      "185:\tlearn: 0.1114155\ttotal: 13s\tremaining: 15s\n",
      "186:\tlearn: 0.1108982\ttotal: 13.1s\tremaining: 14.9s\n",
      "187:\tlearn: 0.1102200\ttotal: 13.2s\tremaining: 14.9s\n",
      "188:\tlearn: 0.1095311\ttotal: 13.2s\tremaining: 14.8s\n",
      "189:\tlearn: 0.1087117\ttotal: 13.4s\tremaining: 14.8s\n",
      "190:\tlearn: 0.1083031\ttotal: 13.5s\tremaining: 14.7s\n",
      "191:\tlearn: 0.1078064\ttotal: 13.5s\tremaining: 14.7s\n",
      "192:\tlearn: 0.1068282\ttotal: 13.6s\tremaining: 14.6s\n",
      "193:\tlearn: 0.1063688\ttotal: 13.7s\tremaining: 14.6s\n",
      "194:\tlearn: 0.1053894\ttotal: 13.8s\tremaining: 14.5s\n",
      "195:\tlearn: 0.1050692\ttotal: 13.9s\tremaining: 14.5s\n",
      "196:\tlearn: 0.1044866\ttotal: 14.1s\tremaining: 14.5s\n",
      "197:\tlearn: 0.1039051\ttotal: 14.2s\tremaining: 14.4s\n",
      "198:\tlearn: 0.1031646\ttotal: 14.2s\tremaining: 14.4s\n",
      "199:\tlearn: 0.1027453\ttotal: 14.3s\tremaining: 14.3s\n",
      "200:\tlearn: 0.1020501\ttotal: 14.4s\tremaining: 14.2s\n",
      "201:\tlearn: 0.1011492\ttotal: 14.5s\tremaining: 14.2s\n",
      "202:\tlearn: 0.1005594\ttotal: 14.6s\tremaining: 14.2s\n",
      "203:\tlearn: 0.1001679\ttotal: 14.7s\tremaining: 14.2s\n",
      "204:\tlearn: 0.0996000\ttotal: 14.8s\tremaining: 14.1s\n",
      "205:\tlearn: 0.0990891\ttotal: 14.9s\tremaining: 14.1s\n",
      "206:\tlearn: 0.0985282\ttotal: 15s\tremaining: 14s\n",
      "207:\tlearn: 0.0979915\ttotal: 15.1s\tremaining: 14s\n",
      "208:\tlearn: 0.0973581\ttotal: 15.3s\tremaining: 13.9s\n",
      "209:\tlearn: 0.0967280\ttotal: 15.4s\tremaining: 13.9s\n",
      "210:\tlearn: 0.0960314\ttotal: 15.5s\tremaining: 13.9s\n",
      "211:\tlearn: 0.0955276\ttotal: 15.6s\tremaining: 13.8s\n",
      "212:\tlearn: 0.0949589\ttotal: 15.7s\tremaining: 13.8s\n",
      "213:\tlearn: 0.0944487\ttotal: 15.9s\tremaining: 13.8s\n",
      "214:\tlearn: 0.0935659\ttotal: 16s\tremaining: 13.7s\n",
      "215:\tlearn: 0.0932151\ttotal: 16.1s\tremaining: 13.7s\n",
      "216:\tlearn: 0.0927038\ttotal: 16.2s\tremaining: 13.6s\n",
      "217:\tlearn: 0.0924157\ttotal: 16.3s\tremaining: 13.6s\n",
      "218:\tlearn: 0.0917251\ttotal: 16.4s\tremaining: 13.6s\n",
      "219:\tlearn: 0.0912380\ttotal: 16.5s\tremaining: 13.5s\n",
      "220:\tlearn: 0.0908213\ttotal: 16.6s\tremaining: 13.5s\n",
      "221:\tlearn: 0.0903737\ttotal: 16.7s\tremaining: 13.4s\n",
      "222:\tlearn: 0.0898388\ttotal: 16.8s\tremaining: 13.3s\n",
      "223:\tlearn: 0.0892973\ttotal: 16.9s\tremaining: 13.3s\n",
      "224:\tlearn: 0.0889386\ttotal: 17s\tremaining: 13.2s\n",
      "225:\tlearn: 0.0884129\ttotal: 17.1s\tremaining: 13.1s\n",
      "226:\tlearn: 0.0878945\ttotal: 17.2s\tremaining: 13.1s\n",
      "227:\tlearn: 0.0874877\ttotal: 17.3s\tremaining: 13s\n",
      "228:\tlearn: 0.0869626\ttotal: 17.3s\tremaining: 12.9s\n",
      "229:\tlearn: 0.0863382\ttotal: 17.5s\tremaining: 12.9s\n",
      "230:\tlearn: 0.0858116\ttotal: 17.5s\tremaining: 12.8s\n",
      "231:\tlearn: 0.0854296\ttotal: 17.6s\tremaining: 12.7s\n",
      "232:\tlearn: 0.0851157\ttotal: 17.6s\tremaining: 12.6s\n",
      "233:\tlearn: 0.0846808\ttotal: 17.6s\tremaining: 12.5s\n",
      "234:\tlearn: 0.0839484\ttotal: 17.7s\tremaining: 12.4s\n",
      "235:\tlearn: 0.0836656\ttotal: 17.7s\tremaining: 12.3s\n",
      "236:\tlearn: 0.0831918\ttotal: 17.8s\tremaining: 12.2s\n",
      "237:\tlearn: 0.0827938\ttotal: 17.8s\tremaining: 12.1s\n",
      "238:\tlearn: 0.0822860\ttotal: 17.9s\tremaining: 12s\n",
      "239:\tlearn: 0.0817359\ttotal: 17.9s\tremaining: 12s\n",
      "240:\tlearn: 0.0812238\ttotal: 18s\tremaining: 11.9s\n",
      "241:\tlearn: 0.0808529\ttotal: 18.1s\tremaining: 11.8s\n",
      "242:\tlearn: 0.0806521\ttotal: 18.1s\tremaining: 11.7s\n",
      "243:\tlearn: 0.0801884\ttotal: 18.2s\tremaining: 11.6s\n",
      "244:\tlearn: 0.0796449\ttotal: 18.3s\tremaining: 11.5s\n",
      "245:\tlearn: 0.0791684\ttotal: 18.3s\tremaining: 11.5s\n",
      "246:\tlearn: 0.0789615\ttotal: 18.4s\tremaining: 11.4s\n",
      "247:\tlearn: 0.0784362\ttotal: 18.4s\tremaining: 11.3s\n",
      "248:\tlearn: 0.0781620\ttotal: 18.6s\tremaining: 11.3s\n",
      "249:\tlearn: 0.0776819\ttotal: 18.6s\tremaining: 11.2s\n",
      "250:\tlearn: 0.0776072\ttotal: 18.7s\tremaining: 11.1s\n",
      "251:\tlearn: 0.0771645\ttotal: 18.7s\tremaining: 11s\n",
      "252:\tlearn: 0.0768627\ttotal: 18.8s\tremaining: 10.9s\n",
      "253:\tlearn: 0.0763820\ttotal: 18.8s\tremaining: 10.8s\n",
      "254:\tlearn: 0.0758115\ttotal: 18.9s\tremaining: 10.7s\n",
      "255:\tlearn: 0.0752381\ttotal: 19s\tremaining: 10.7s\n",
      "256:\tlearn: 0.0749039\ttotal: 19s\tremaining: 10.6s\n",
      "257:\tlearn: 0.0746804\ttotal: 19.1s\tremaining: 10.5s\n",
      "258:\tlearn: 0.0741775\ttotal: 19.1s\tremaining: 10.4s\n",
      "259:\tlearn: 0.0737767\ttotal: 19.1s\tremaining: 10.3s\n",
      "260:\tlearn: 0.0734514\ttotal: 19.2s\tremaining: 10.2s\n",
      "261:\tlearn: 0.0731728\ttotal: 19.2s\tremaining: 10.1s\n",
      "262:\tlearn: 0.0728954\ttotal: 19.3s\tremaining: 10s\n",
      "263:\tlearn: 0.0725818\ttotal: 19.3s\tremaining: 9.95s\n",
      "264:\tlearn: 0.0723870\ttotal: 19.3s\tremaining: 9.85s\n",
      "265:\tlearn: 0.0719199\ttotal: 19.4s\tremaining: 9.78s\n",
      "266:\tlearn: 0.0715448\ttotal: 19.4s\tremaining: 9.69s\n",
      "267:\tlearn: 0.0709859\ttotal: 19.5s\tremaining: 9.61s\n",
      "268:\tlearn: 0.0706750\ttotal: 19.5s\tremaining: 9.51s\n",
      "269:\tlearn: 0.0703396\ttotal: 19.6s\tremaining: 9.43s\n",
      "270:\tlearn: 0.0700730\ttotal: 19.6s\tremaining: 9.34s\n",
      "271:\tlearn: 0.0697280\ttotal: 19.7s\tremaining: 9.26s\n",
      "272:\tlearn: 0.0692302\ttotal: 19.7s\tremaining: 9.17s\n",
      "273:\tlearn: 0.0687550\ttotal: 19.8s\tremaining: 9.09s\n",
      "274:\tlearn: 0.0683690\ttotal: 19.8s\tremaining: 9s\n",
      "275:\tlearn: 0.0681257\ttotal: 19.8s\tremaining: 8.91s\n",
      "276:\tlearn: 0.0680065\ttotal: 19.9s\tremaining: 8.84s\n",
      "277:\tlearn: 0.0677789\ttotal: 20s\tremaining: 8.76s\n",
      "278:\tlearn: 0.0673464\ttotal: 20s\tremaining: 8.67s\n",
      "279:\tlearn: 0.0669453\ttotal: 20.1s\tremaining: 8.59s\n",
      "280:\tlearn: 0.0667674\ttotal: 20.2s\tremaining: 8.54s\n",
      "281:\tlearn: 0.0663162\ttotal: 20.2s\tremaining: 8.46s\n",
      "282:\tlearn: 0.0660370\ttotal: 20.3s\tremaining: 8.38s\n",
      "283:\tlearn: 0.0655951\ttotal: 20.4s\tremaining: 8.32s\n",
      "284:\tlearn: 0.0652361\ttotal: 20.4s\tremaining: 8.25s\n",
      "285:\tlearn: 0.0646182\ttotal: 20.5s\tremaining: 8.16s\n",
      "286:\tlearn: 0.0641871\ttotal: 20.5s\tremaining: 8.08s\n",
      "287:\tlearn: 0.0638132\ttotal: 20.6s\tremaining: 7.99s\n",
      "288:\tlearn: 0.0634972\ttotal: 20.6s\tremaining: 7.91s\n",
      "289:\tlearn: 0.0631929\ttotal: 20.6s\tremaining: 7.82s\n",
      "290:\tlearn: 0.0627589\ttotal: 20.7s\tremaining: 7.74s\n",
      "291:\tlearn: 0.0624602\ttotal: 20.7s\tremaining: 7.66s\n",
      "292:\tlearn: 0.0622599\ttotal: 20.8s\tremaining: 7.58s\n",
      "293:\tlearn: 0.0618990\ttotal: 20.8s\tremaining: 7.5s\n",
      "294:\tlearn: 0.0615674\ttotal: 20.8s\tremaining: 7.42s\n",
      "295:\tlearn: 0.0611750\ttotal: 20.9s\tremaining: 7.34s\n",
      "296:\tlearn: 0.0606783\ttotal: 20.9s\tremaining: 7.26s\n",
      "297:\tlearn: 0.0601381\ttotal: 21s\tremaining: 7.18s\n",
      "298:\tlearn: 0.0598025\ttotal: 21s\tremaining: 7.1s\n",
      "299:\tlearn: 0.0594192\ttotal: 21.1s\tremaining: 7.02s\n",
      "300:\tlearn: 0.0589572\ttotal: 21.1s\tremaining: 6.94s\n",
      "301:\tlearn: 0.0586924\ttotal: 21.1s\tremaining: 6.86s\n",
      "302:\tlearn: 0.0585780\ttotal: 21.2s\tremaining: 6.78s\n",
      "303:\tlearn: 0.0583277\ttotal: 21.2s\tremaining: 6.7s\n",
      "304:\tlearn: 0.0582739\ttotal: 21.3s\tremaining: 6.63s\n",
      "305:\tlearn: 0.0580844\ttotal: 21.3s\tremaining: 6.54s\n",
      "306:\tlearn: 0.0576647\ttotal: 21.4s\tremaining: 6.47s\n",
      "307:\tlearn: 0.0574288\ttotal: 21.4s\tremaining: 6.39s\n",
      "308:\tlearn: 0.0570825\ttotal: 21.4s\tremaining: 6.32s\n",
      "309:\tlearn: 0.0565917\ttotal: 21.5s\tremaining: 6.24s\n",
      "310:\tlearn: 0.0562511\ttotal: 21.5s\tremaining: 6.16s\n",
      "311:\tlearn: 0.0559921\ttotal: 21.6s\tremaining: 6.08s\n",
      "312:\tlearn: 0.0556515\ttotal: 21.6s\tremaining: 6.01s\n",
      "313:\tlearn: 0.0554305\ttotal: 21.6s\tremaining: 5.93s\n",
      "314:\tlearn: 0.0550311\ttotal: 21.7s\tremaining: 5.85s\n",
      "315:\tlearn: 0.0546482\ttotal: 21.7s\tremaining: 5.77s\n",
      "316:\tlearn: 0.0543483\ttotal: 21.8s\tremaining: 5.7s\n",
      "317:\tlearn: 0.0540813\ttotal: 21.8s\tremaining: 5.62s\n",
      "318:\tlearn: 0.0538471\ttotal: 21.9s\tremaining: 5.55s\n",
      "319:\tlearn: 0.0535367\ttotal: 21.9s\tremaining: 5.48s\n",
      "320:\tlearn: 0.0533335\ttotal: 21.9s\tremaining: 5.4s\n",
      "321:\tlearn: 0.0531242\ttotal: 22s\tremaining: 5.33s\n",
      "322:\tlearn: 0.0529971\ttotal: 22s\tremaining: 5.25s\n",
      "323:\tlearn: 0.0527304\ttotal: 22.1s\tremaining: 5.17s\n",
      "324:\tlearn: 0.0525306\ttotal: 22.1s\tremaining: 5.1s\n",
      "325:\tlearn: 0.0522701\ttotal: 22.2s\tremaining: 5.03s\n",
      "326:\tlearn: 0.0519572\ttotal: 22.2s\tremaining: 4.96s\n",
      "327:\tlearn: 0.0515642\ttotal: 22.2s\tremaining: 4.88s\n",
      "328:\tlearn: 0.0513603\ttotal: 22.3s\tremaining: 4.81s\n",
      "329:\tlearn: 0.0511481\ttotal: 22.3s\tremaining: 4.74s\n",
      "330:\tlearn: 0.0509001\ttotal: 22.4s\tremaining: 4.66s\n",
      "331:\tlearn: 0.0506158\ttotal: 22.4s\tremaining: 4.59s\n",
      "332:\tlearn: 0.0503221\ttotal: 22.5s\tremaining: 4.52s\n",
      "333:\tlearn: 0.0500760\ttotal: 22.5s\tremaining: 4.45s\n",
      "334:\tlearn: 0.0498406\ttotal: 22.6s\tremaining: 4.38s\n",
      "335:\tlearn: 0.0496295\ttotal: 22.6s\tremaining: 4.3s\n",
      "336:\tlearn: 0.0493190\ttotal: 22.6s\tremaining: 4.23s\n",
      "337:\tlearn: 0.0490402\ttotal: 22.7s\tremaining: 4.16s\n",
      "338:\tlearn: 0.0487285\ttotal: 22.7s\tremaining: 4.09s\n",
      "339:\tlearn: 0.0484004\ttotal: 22.8s\tremaining: 4.02s\n",
      "340:\tlearn: 0.0483058\ttotal: 22.8s\tremaining: 3.95s\n",
      "341:\tlearn: 0.0478662\ttotal: 22.9s\tremaining: 3.88s\n",
      "342:\tlearn: 0.0476637\ttotal: 23s\tremaining: 3.81s\n",
      "343:\tlearn: 0.0476155\ttotal: 23s\tremaining: 3.74s\n",
      "344:\tlearn: 0.0474258\ttotal: 23s\tremaining: 3.67s\n",
      "345:\tlearn: 0.0472344\ttotal: 23.1s\tremaining: 3.6s\n",
      "346:\tlearn: 0.0469956\ttotal: 23.2s\tremaining: 3.54s\n",
      "347:\tlearn: 0.0467824\ttotal: 23.2s\tremaining: 3.47s\n",
      "348:\tlearn: 0.0464636\ttotal: 23.3s\tremaining: 3.4s\n",
      "349:\tlearn: 0.0462797\ttotal: 23.3s\tremaining: 3.33s\n",
      "350:\tlearn: 0.0460845\ttotal: 23.4s\tremaining: 3.26s\n",
      "351:\tlearn: 0.0458458\ttotal: 23.4s\tremaining: 3.19s\n",
      "352:\tlearn: 0.0456340\ttotal: 23.5s\tremaining: 3.13s\n",
      "353:\tlearn: 0.0453361\ttotal: 23.5s\tremaining: 3.06s\n",
      "354:\tlearn: 0.0451216\ttotal: 23.6s\tremaining: 2.99s\n",
      "355:\tlearn: 0.0448483\ttotal: 23.6s\tremaining: 2.92s\n",
      "356:\tlearn: 0.0446585\ttotal: 23.7s\tremaining: 2.85s\n",
      "357:\tlearn: 0.0444458\ttotal: 23.8s\tremaining: 2.79s\n",
      "358:\tlearn: 0.0443247\ttotal: 23.8s\tremaining: 2.72s\n",
      "359:\tlearn: 0.0439615\ttotal: 23.8s\tremaining: 2.65s\n",
      "360:\tlearn: 0.0437322\ttotal: 23.9s\tremaining: 2.58s\n",
      "361:\tlearn: 0.0435907\ttotal: 23.9s\tremaining: 2.51s\n",
      "362:\tlearn: 0.0433545\ttotal: 24s\tremaining: 2.45s\n",
      "363:\tlearn: 0.0432295\ttotal: 24.1s\tremaining: 2.38s\n",
      "364:\tlearn: 0.0429500\ttotal: 24.1s\tremaining: 2.31s\n",
      "365:\tlearn: 0.0428008\ttotal: 24.1s\tremaining: 2.24s\n",
      "366:\tlearn: 0.0425845\ttotal: 24.2s\tremaining: 2.17s\n",
      "367:\tlearn: 0.0423788\ttotal: 24.2s\tremaining: 2.11s\n",
      "368:\tlearn: 0.0422540\ttotal: 24.3s\tremaining: 2.04s\n",
      "369:\tlearn: 0.0421365\ttotal: 24.3s\tremaining: 1.97s\n",
      "370:\tlearn: 0.0417869\ttotal: 24.3s\tremaining: 1.9s\n",
      "371:\tlearn: 0.0416585\ttotal: 24.4s\tremaining: 1.83s\n",
      "372:\tlearn: 0.0415038\ttotal: 24.4s\tremaining: 1.77s\n",
      "373:\tlearn: 0.0413104\ttotal: 24.4s\tremaining: 1.7s\n",
      "374:\tlearn: 0.0409733\ttotal: 24.5s\tremaining: 1.63s\n",
      "375:\tlearn: 0.0406793\ttotal: 24.5s\tremaining: 1.57s\n",
      "376:\tlearn: 0.0405107\ttotal: 24.6s\tremaining: 1.5s\n",
      "377:\tlearn: 0.0402303\ttotal: 24.6s\tremaining: 1.43s\n",
      "378:\tlearn: 0.0401888\ttotal: 24.7s\tremaining: 1.37s\n",
      "379:\tlearn: 0.0400015\ttotal: 24.7s\tremaining: 1.3s\n",
      "380:\tlearn: 0.0397121\ttotal: 24.8s\tremaining: 1.24s\n",
      "381:\tlearn: 0.0395140\ttotal: 24.8s\tremaining: 1.17s\n",
      "382:\tlearn: 0.0394560\ttotal: 24.9s\tremaining: 1.1s\n",
      "383:\tlearn: 0.0393073\ttotal: 24.9s\tremaining: 1.04s\n",
      "384:\tlearn: 0.0391687\ttotal: 25s\tremaining: 974ms\n",
      "385:\tlearn: 0.0389139\ttotal: 25s\tremaining: 908ms\n",
      "386:\tlearn: 0.0387637\ttotal: 25.1s\tremaining: 843ms\n",
      "387:\tlearn: 0.0385786\ttotal: 25.1s\tremaining: 777ms\n",
      "388:\tlearn: 0.0384432\ttotal: 25.2s\tremaining: 712ms\n",
      "389:\tlearn: 0.0382759\ttotal: 25.2s\tremaining: 647ms\n",
      "390:\tlearn: 0.0381088\ttotal: 25.3s\tremaining: 581ms\n",
      "391:\tlearn: 0.0378880\ttotal: 25.3s\tremaining: 516ms\n",
      "392:\tlearn: 0.0376333\ttotal: 25.4s\tremaining: 452ms\n",
      "393:\tlearn: 0.0374878\ttotal: 25.4s\tremaining: 387ms\n",
      "394:\tlearn: 0.0372682\ttotal: 25.4s\tremaining: 322ms\n",
      "395:\tlearn: 0.0371911\ttotal: 25.5s\tremaining: 257ms\n",
      "396:\tlearn: 0.0370339\ttotal: 25.5s\tremaining: 193ms\n",
      "397:\tlearn: 0.0369633\ttotal: 25.6s\tremaining: 129ms\n",
      "398:\tlearn: 0.0367928\ttotal: 25.6s\tremaining: 64.2ms\n",
      "399:\tlearn: 0.0366172\ttotal: 25.7s\tremaining: 0us\n",
      "0:\tlearn: 0.5762639\ttotal: 52ms\tremaining: 20.7s\n",
      "1:\tlearn: 0.5068267\ttotal: 91ms\tremaining: 18.1s\n",
      "2:\tlearn: 0.4646360\ttotal: 126ms\tremaining: 16.7s\n",
      "3:\tlearn: 0.4411543\ttotal: 169ms\tremaining: 16.7s\n",
      "4:\tlearn: 0.4186902\ttotal: 212ms\tremaining: 16.7s\n",
      "5:\tlearn: 0.4077594\ttotal: 256ms\tremaining: 16.8s\n",
      "6:\tlearn: 0.4008827\ttotal: 310ms\tremaining: 17.4s\n",
      "7:\tlearn: 0.3901645\ttotal: 355ms\tremaining: 17.4s\n",
      "8:\tlearn: 0.3820441\ttotal: 400ms\tremaining: 17.4s\n",
      "9:\tlearn: 0.3770252\ttotal: 453ms\tremaining: 17.7s\n",
      "10:\tlearn: 0.3703864\ttotal: 497ms\tremaining: 17.6s\n",
      "11:\tlearn: 0.3662362\ttotal: 536ms\tremaining: 17.3s\n",
      "12:\tlearn: 0.3626832\ttotal: 577ms\tremaining: 17.2s\n",
      "13:\tlearn: 0.3581183\ttotal: 649ms\tremaining: 17.9s\n",
      "14:\tlearn: 0.3536364\ttotal: 696ms\tremaining: 17.9s\n",
      "15:\tlearn: 0.3496035\ttotal: 739ms\tremaining: 17.7s\n",
      "16:\tlearn: 0.3455353\ttotal: 792ms\tremaining: 17.8s\n",
      "17:\tlearn: 0.3426470\ttotal: 863ms\tremaining: 18.3s\n",
      "18:\tlearn: 0.3392889\ttotal: 914ms\tremaining: 18.3s\n",
      "19:\tlearn: 0.3366054\ttotal: 952ms\tremaining: 18.1s\n",
      "20:\tlearn: 0.3339420\ttotal: 992ms\tremaining: 17.9s\n",
      "21:\tlearn: 0.3313401\ttotal: 1.06s\tremaining: 18.3s\n",
      "22:\tlearn: 0.3284182\ttotal: 1.1s\tremaining: 18.1s\n",
      "23:\tlearn: 0.3261915\ttotal: 1.14s\tremaining: 17.9s\n",
      "24:\tlearn: 0.3237253\ttotal: 1.2s\tremaining: 18s\n",
      "25:\tlearn: 0.3216304\ttotal: 1.26s\tremaining: 18.1s\n",
      "26:\tlearn: 0.3189817\ttotal: 1.29s\tremaining: 17.9s\n",
      "27:\tlearn: 0.3172376\ttotal: 1.34s\tremaining: 17.9s\n",
      "28:\tlearn: 0.3144505\ttotal: 1.4s\tremaining: 17.9s\n",
      "29:\tlearn: 0.3120965\ttotal: 1.46s\tremaining: 18s\n",
      "30:\tlearn: 0.3097313\ttotal: 1.51s\tremaining: 18s\n",
      "31:\tlearn: 0.3079313\ttotal: 1.59s\tremaining: 18.3s\n",
      "32:\tlearn: 0.3055007\ttotal: 1.64s\tremaining: 18.3s\n",
      "33:\tlearn: 0.3031019\ttotal: 1.72s\tremaining: 18.5s\n",
      "34:\tlearn: 0.3016986\ttotal: 1.78s\tremaining: 18.6s\n",
      "35:\tlearn: 0.2996323\ttotal: 1.83s\tremaining: 18.5s\n",
      "36:\tlearn: 0.2980037\ttotal: 1.88s\tremaining: 18.5s\n",
      "37:\tlearn: 0.2960357\ttotal: 2s\tremaining: 19.1s\n",
      "38:\tlearn: 0.2943228\ttotal: 2.05s\tremaining: 19s\n",
      "39:\tlearn: 0.2915464\ttotal: 2.11s\tremaining: 19s\n",
      "40:\tlearn: 0.2897558\ttotal: 2.15s\tremaining: 18.8s\n",
      "41:\tlearn: 0.2874053\ttotal: 2.2s\tremaining: 18.8s\n",
      "42:\tlearn: 0.2856023\ttotal: 2.26s\tremaining: 18.7s\n",
      "43:\tlearn: 0.2846785\ttotal: 2.33s\tremaining: 18.8s\n",
      "44:\tlearn: 0.2831476\ttotal: 2.4s\tremaining: 18.9s\n",
      "45:\tlearn: 0.2809176\ttotal: 2.48s\tremaining: 19.1s\n",
      "46:\tlearn: 0.2789549\ttotal: 2.56s\tremaining: 19.2s\n",
      "47:\tlearn: 0.2761294\ttotal: 2.64s\tremaining: 19.4s\n",
      "48:\tlearn: 0.2748405\ttotal: 2.7s\tremaining: 19.4s\n",
      "49:\tlearn: 0.2733799\ttotal: 2.77s\tremaining: 19.4s\n",
      "50:\tlearn: 0.2715144\ttotal: 2.84s\tremaining: 19.5s\n",
      "51:\tlearn: 0.2694978\ttotal: 2.91s\tremaining: 19.5s\n",
      "52:\tlearn: 0.2678249\ttotal: 2.99s\tremaining: 19.6s\n",
      "53:\tlearn: 0.2654969\ttotal: 3.06s\tremaining: 19.6s\n",
      "54:\tlearn: 0.2635721\ttotal: 3.13s\tremaining: 19.6s\n",
      "55:\tlearn: 0.2611060\ttotal: 3.21s\tremaining: 19.7s\n",
      "56:\tlearn: 0.2585293\ttotal: 3.27s\tremaining: 19.7s\n",
      "57:\tlearn: 0.2570747\ttotal: 3.35s\tremaining: 19.8s\n",
      "58:\tlearn: 0.2551850\ttotal: 3.39s\tremaining: 19.6s\n",
      "59:\tlearn: 0.2535678\ttotal: 3.44s\tremaining: 19.5s\n",
      "60:\tlearn: 0.2521886\ttotal: 3.48s\tremaining: 19.4s\n",
      "61:\tlearn: 0.2504632\ttotal: 3.53s\tremaining: 19.2s\n",
      "62:\tlearn: 0.2489706\ttotal: 3.57s\tremaining: 19.1s\n",
      "63:\tlearn: 0.2473862\ttotal: 3.61s\tremaining: 18.9s\n",
      "64:\tlearn: 0.2469956\ttotal: 3.66s\tremaining: 18.9s\n",
      "65:\tlearn: 0.2459016\ttotal: 3.75s\tremaining: 19s\n",
      "66:\tlearn: 0.2440317\ttotal: 3.81s\tremaining: 19s\n",
      "67:\tlearn: 0.2424921\ttotal: 3.9s\tremaining: 19s\n",
      "68:\tlearn: 0.2402506\ttotal: 3.98s\tremaining: 19.1s\n",
      "69:\tlearn: 0.2386535\ttotal: 4.01s\tremaining: 18.9s\n",
      "70:\tlearn: 0.2372588\ttotal: 4.06s\tremaining: 18.8s\n",
      "71:\tlearn: 0.2353402\ttotal: 4.1s\tremaining: 18.7s\n",
      "72:\tlearn: 0.2332592\ttotal: 4.16s\tremaining: 18.6s\n",
      "73:\tlearn: 0.2320440\ttotal: 4.2s\tremaining: 18.5s\n",
      "74:\tlearn: 0.2306878\ttotal: 4.26s\tremaining: 18.4s\n",
      "75:\tlearn: 0.2289049\ttotal: 4.29s\tremaining: 18.3s\n",
      "76:\tlearn: 0.2275725\ttotal: 4.34s\tremaining: 18.2s\n",
      "77:\tlearn: 0.2262431\ttotal: 4.42s\tremaining: 18.2s\n",
      "78:\tlearn: 0.2253938\ttotal: 4.5s\tremaining: 18.3s\n",
      "79:\tlearn: 0.2242986\ttotal: 4.57s\tremaining: 18.3s\n",
      "80:\tlearn: 0.2226776\ttotal: 4.64s\tremaining: 18.3s\n",
      "81:\tlearn: 0.2212379\ttotal: 4.72s\tremaining: 18.3s\n",
      "82:\tlearn: 0.2201249\ttotal: 4.78s\tremaining: 18.3s\n",
      "83:\tlearn: 0.2177947\ttotal: 4.86s\tremaining: 18.3s\n",
      "84:\tlearn: 0.2167618\ttotal: 4.93s\tremaining: 18.3s\n",
      "85:\tlearn: 0.2153550\ttotal: 5.02s\tremaining: 18.3s\n",
      "86:\tlearn: 0.2145379\ttotal: 5.13s\tremaining: 18.5s\n",
      "87:\tlearn: 0.2128393\ttotal: 5.23s\tremaining: 18.5s\n",
      "88:\tlearn: 0.2111734\ttotal: 5.3s\tremaining: 18.5s\n",
      "89:\tlearn: 0.2091955\ttotal: 5.39s\tremaining: 18.6s\n",
      "90:\tlearn: 0.2072423\ttotal: 5.46s\tremaining: 18.5s\n",
      "91:\tlearn: 0.2055913\ttotal: 5.52s\tremaining: 18.5s\n",
      "92:\tlearn: 0.2040110\ttotal: 5.58s\tremaining: 18.4s\n",
      "93:\tlearn: 0.2026719\ttotal: 5.65s\tremaining: 18.4s\n",
      "94:\tlearn: 0.2011875\ttotal: 5.73s\tremaining: 18.4s\n",
      "95:\tlearn: 0.2003789\ttotal: 5.8s\tremaining: 18.4s\n",
      "96:\tlearn: 0.1991318\ttotal: 5.87s\tremaining: 18.4s\n",
      "97:\tlearn: 0.1974337\ttotal: 5.97s\tremaining: 18.4s\n",
      "98:\tlearn: 0.1959202\ttotal: 6.04s\tremaining: 18.4s\n",
      "99:\tlearn: 0.1948822\ttotal: 6.14s\tremaining: 18.4s\n",
      "100:\tlearn: 0.1939625\ttotal: 6.21s\tremaining: 18.4s\n",
      "101:\tlearn: 0.1930628\ttotal: 6.25s\tremaining: 18.3s\n",
      "102:\tlearn: 0.1921878\ttotal: 6.29s\tremaining: 18.1s\n",
      "103:\tlearn: 0.1903165\ttotal: 6.35s\tremaining: 18.1s\n",
      "104:\tlearn: 0.1893396\ttotal: 6.4s\tremaining: 18s\n",
      "105:\tlearn: 0.1884161\ttotal: 6.45s\tremaining: 17.9s\n",
      "106:\tlearn: 0.1871214\ttotal: 6.5s\tremaining: 17.8s\n",
      "107:\tlearn: 0.1861079\ttotal: 6.54s\tremaining: 17.7s\n",
      "108:\tlearn: 0.1853823\ttotal: 6.59s\tremaining: 17.6s\n",
      "109:\tlearn: 0.1844473\ttotal: 6.65s\tremaining: 17.5s\n",
      "110:\tlearn: 0.1833771\ttotal: 6.7s\tremaining: 17.4s\n",
      "111:\tlearn: 0.1825796\ttotal: 6.75s\tremaining: 17.3s\n",
      "112:\tlearn: 0.1823025\ttotal: 6.78s\tremaining: 17.2s\n",
      "113:\tlearn: 0.1808447\ttotal: 6.83s\tremaining: 17.1s\n",
      "114:\tlearn: 0.1799561\ttotal: 6.88s\tremaining: 17s\n",
      "115:\tlearn: 0.1790825\ttotal: 6.92s\tremaining: 16.9s\n",
      "116:\tlearn: 0.1776915\ttotal: 6.96s\tremaining: 16.8s\n",
      "117:\tlearn: 0.1763626\ttotal: 7.01s\tremaining: 16.7s\n",
      "118:\tlearn: 0.1756938\ttotal: 7.07s\tremaining: 16.7s\n",
      "119:\tlearn: 0.1745008\ttotal: 7.1s\tremaining: 16.6s\n",
      "120:\tlearn: 0.1735191\ttotal: 7.15s\tremaining: 16.5s\n",
      "121:\tlearn: 0.1724825\ttotal: 7.18s\tremaining: 16.4s\n",
      "122:\tlearn: 0.1714011\ttotal: 7.22s\tremaining: 16.3s\n",
      "123:\tlearn: 0.1703620\ttotal: 7.26s\tremaining: 16.2s\n",
      "124:\tlearn: 0.1690331\ttotal: 7.29s\tremaining: 16.1s\n",
      "125:\tlearn: 0.1679699\ttotal: 7.34s\tremaining: 16s\n",
      "126:\tlearn: 0.1666402\ttotal: 7.38s\tremaining: 15.9s\n",
      "127:\tlearn: 0.1655203\ttotal: 7.45s\tremaining: 15.8s\n",
      "128:\tlearn: 0.1647206\ttotal: 7.49s\tremaining: 15.7s\n",
      "129:\tlearn: 0.1634960\ttotal: 7.52s\tremaining: 15.6s\n",
      "130:\tlearn: 0.1622430\ttotal: 7.59s\tremaining: 15.6s\n",
      "131:\tlearn: 0.1613106\ttotal: 7.63s\tremaining: 15.5s\n",
      "132:\tlearn: 0.1607527\ttotal: 7.67s\tremaining: 15.4s\n",
      "133:\tlearn: 0.1595101\ttotal: 7.72s\tremaining: 15.3s\n",
      "134:\tlearn: 0.1578642\ttotal: 7.78s\tremaining: 15.3s\n",
      "135:\tlearn: 0.1569398\ttotal: 7.83s\tremaining: 15.2s\n",
      "136:\tlearn: 0.1560200\ttotal: 7.87s\tremaining: 15.1s\n",
      "137:\tlearn: 0.1550213\ttotal: 7.91s\tremaining: 15s\n",
      "138:\tlearn: 0.1542238\ttotal: 7.95s\tremaining: 14.9s\n",
      "139:\tlearn: 0.1537876\ttotal: 7.98s\tremaining: 14.8s\n",
      "140:\tlearn: 0.1529680\ttotal: 8.02s\tremaining: 14.7s\n",
      "141:\tlearn: 0.1517478\ttotal: 8.06s\tremaining: 14.7s\n",
      "142:\tlearn: 0.1507375\ttotal: 8.1s\tremaining: 14.6s\n",
      "143:\tlearn: 0.1498986\ttotal: 8.15s\tremaining: 14.5s\n",
      "144:\tlearn: 0.1491901\ttotal: 8.2s\tremaining: 14.4s\n",
      "145:\tlearn: 0.1480984\ttotal: 8.25s\tremaining: 14.3s\n",
      "146:\tlearn: 0.1470541\ttotal: 8.29s\tremaining: 14.3s\n",
      "147:\tlearn: 0.1459103\ttotal: 8.33s\tremaining: 14.2s\n",
      "148:\tlearn: 0.1451016\ttotal: 8.38s\tremaining: 14.1s\n",
      "149:\tlearn: 0.1440580\ttotal: 8.46s\tremaining: 14.1s\n",
      "150:\tlearn: 0.1432909\ttotal: 8.54s\tremaining: 14.1s\n",
      "151:\tlearn: 0.1427488\ttotal: 8.58s\tremaining: 14s\n",
      "152:\tlearn: 0.1423297\ttotal: 8.62s\tremaining: 13.9s\n",
      "153:\tlearn: 0.1413903\ttotal: 8.67s\tremaining: 13.8s\n",
      "154:\tlearn: 0.1405042\ttotal: 8.75s\tremaining: 13.8s\n",
      "155:\tlearn: 0.1394665\ttotal: 8.8s\tremaining: 13.8s\n",
      "156:\tlearn: 0.1388608\ttotal: 8.84s\tremaining: 13.7s\n",
      "157:\tlearn: 0.1379512\ttotal: 8.9s\tremaining: 13.6s\n",
      "158:\tlearn: 0.1369709\ttotal: 9s\tremaining: 13.6s\n",
      "159:\tlearn: 0.1358640\ttotal: 9.08s\tremaining: 13.6s\n",
      "160:\tlearn: 0.1347928\ttotal: 9.15s\tremaining: 13.6s\n",
      "161:\tlearn: 0.1342257\ttotal: 9.22s\tremaining: 13.5s\n",
      "162:\tlearn: 0.1332860\ttotal: 9.31s\tremaining: 13.5s\n",
      "163:\tlearn: 0.1325052\ttotal: 9.38s\tremaining: 13.5s\n",
      "164:\tlearn: 0.1321330\ttotal: 9.46s\tremaining: 13.5s\n",
      "165:\tlearn: 0.1314908\ttotal: 9.53s\tremaining: 13.4s\n",
      "166:\tlearn: 0.1308370\ttotal: 9.61s\tremaining: 13.4s\n",
      "167:\tlearn: 0.1299445\ttotal: 9.7s\tremaining: 13.4s\n",
      "168:\tlearn: 0.1293897\ttotal: 9.77s\tremaining: 13.4s\n",
      "169:\tlearn: 0.1288405\ttotal: 9.87s\tremaining: 13.4s\n",
      "170:\tlearn: 0.1279771\ttotal: 9.96s\tremaining: 13.3s\n",
      "171:\tlearn: 0.1273346\ttotal: 10s\tremaining: 13.3s\n",
      "172:\tlearn: 0.1263826\ttotal: 10.1s\tremaining: 13.3s\n",
      "173:\tlearn: 0.1253611\ttotal: 10.2s\tremaining: 13.2s\n",
      "174:\tlearn: 0.1243160\ttotal: 10.3s\tremaining: 13.2s\n",
      "175:\tlearn: 0.1235096\ttotal: 10.3s\tremaining: 13.2s\n",
      "176:\tlearn: 0.1229300\ttotal: 10.4s\tremaining: 13.1s\n",
      "177:\tlearn: 0.1223333\ttotal: 10.5s\tremaining: 13.1s\n",
      "178:\tlearn: 0.1213930\ttotal: 10.6s\tremaining: 13.1s\n",
      "179:\tlearn: 0.1207388\ttotal: 10.8s\tremaining: 13.2s\n",
      "180:\tlearn: 0.1203663\ttotal: 10.8s\tremaining: 13.1s\n",
      "181:\tlearn: 0.1197925\ttotal: 10.9s\tremaining: 13.1s\n",
      "182:\tlearn: 0.1192222\ttotal: 11s\tremaining: 13s\n",
      "183:\tlearn: 0.1182521\ttotal: 11.1s\tremaining: 13s\n",
      "184:\tlearn: 0.1173974\ttotal: 11.2s\tremaining: 13s\n",
      "185:\tlearn: 0.1165715\ttotal: 11.3s\tremaining: 13s\n",
      "186:\tlearn: 0.1156128\ttotal: 11.3s\tremaining: 12.9s\n",
      "187:\tlearn: 0.1148875\ttotal: 11.4s\tremaining: 12.8s\n",
      "188:\tlearn: 0.1141899\ttotal: 11.4s\tremaining: 12.8s\n",
      "189:\tlearn: 0.1137205\ttotal: 11.5s\tremaining: 12.7s\n",
      "190:\tlearn: 0.1129761\ttotal: 11.6s\tremaining: 12.7s\n",
      "191:\tlearn: 0.1123173\ttotal: 11.8s\tremaining: 12.7s\n",
      "192:\tlearn: 0.1118580\ttotal: 11.8s\tremaining: 12.7s\n",
      "193:\tlearn: 0.1114318\ttotal: 11.9s\tremaining: 12.6s\n",
      "194:\tlearn: 0.1111207\ttotal: 11.9s\tremaining: 12.5s\n",
      "195:\tlearn: 0.1103940\ttotal: 12s\tremaining: 12.5s\n",
      "196:\tlearn: 0.1096305\ttotal: 12.1s\tremaining: 12.4s\n",
      "197:\tlearn: 0.1086590\ttotal: 12.1s\tremaining: 12.4s\n",
      "198:\tlearn: 0.1078877\ttotal: 12.2s\tremaining: 12.3s\n",
      "199:\tlearn: 0.1072468\ttotal: 12.3s\tremaining: 12.3s\n",
      "200:\tlearn: 0.1063480\ttotal: 12.4s\tremaining: 12.3s\n",
      "201:\tlearn: 0.1060407\ttotal: 12.5s\tremaining: 12.2s\n",
      "202:\tlearn: 0.1056655\ttotal: 12.6s\tremaining: 12.2s\n",
      "203:\tlearn: 0.1050630\ttotal: 12.7s\tremaining: 12.2s\n",
      "204:\tlearn: 0.1042366\ttotal: 12.9s\tremaining: 12.2s\n",
      "205:\tlearn: 0.1035436\ttotal: 13s\tremaining: 12.2s\n",
      "206:\tlearn: 0.1029997\ttotal: 13.1s\tremaining: 12.3s\n",
      "207:\tlearn: 0.1025873\ttotal: 13.3s\tremaining: 12.3s\n",
      "208:\tlearn: 0.1019876\ttotal: 13.5s\tremaining: 12.3s\n",
      "209:\tlearn: 0.1015830\ttotal: 13.6s\tremaining: 12.3s\n",
      "210:\tlearn: 0.1011117\ttotal: 13.7s\tremaining: 12.3s\n",
      "211:\tlearn: 0.1007690\ttotal: 13.9s\tremaining: 12.3s\n",
      "212:\tlearn: 0.1001158\ttotal: 14s\tremaining: 12.3s\n",
      "213:\tlearn: 0.0995397\ttotal: 14.2s\tremaining: 12.3s\n",
      "214:\tlearn: 0.0994198\ttotal: 14.3s\tremaining: 12.3s\n",
      "215:\tlearn: 0.0989860\ttotal: 14.4s\tremaining: 12.3s\n",
      "216:\tlearn: 0.0982537\ttotal: 14.6s\tremaining: 12.3s\n",
      "217:\tlearn: 0.0977589\ttotal: 14.7s\tremaining: 12.3s\n",
      "218:\tlearn: 0.0971115\ttotal: 14.8s\tremaining: 12.3s\n",
      "219:\tlearn: 0.0967017\ttotal: 15s\tremaining: 12.2s\n",
      "220:\tlearn: 0.0960432\ttotal: 15.1s\tremaining: 12.2s\n",
      "221:\tlearn: 0.0955999\ttotal: 15.2s\tremaining: 12.2s\n",
      "222:\tlearn: 0.0949196\ttotal: 15.3s\tremaining: 12.1s\n",
      "223:\tlearn: 0.0944212\ttotal: 15.5s\tremaining: 12.1s\n",
      "224:\tlearn: 0.0938621\ttotal: 15.6s\tremaining: 12.1s\n",
      "225:\tlearn: 0.0932697\ttotal: 15.7s\tremaining: 12.1s\n",
      "226:\tlearn: 0.0929294\ttotal: 15.9s\tremaining: 12.1s\n",
      "227:\tlearn: 0.0925031\ttotal: 16.1s\tremaining: 12.1s\n",
      "228:\tlearn: 0.0918970\ttotal: 16.2s\tremaining: 12.1s\n",
      "229:\tlearn: 0.0912919\ttotal: 16.3s\tremaining: 12.1s\n",
      "230:\tlearn: 0.0909620\ttotal: 16.5s\tremaining: 12.1s\n",
      "231:\tlearn: 0.0901789\ttotal: 16.6s\tremaining: 12s\n",
      "232:\tlearn: 0.0896663\ttotal: 16.8s\tremaining: 12s\n",
      "233:\tlearn: 0.0893477\ttotal: 16.9s\tremaining: 12s\n",
      "234:\tlearn: 0.0889837\ttotal: 17.1s\tremaining: 12s\n",
      "235:\tlearn: 0.0883656\ttotal: 17.2s\tremaining: 11.9s\n",
      "236:\tlearn: 0.0878413\ttotal: 17.2s\tremaining: 11.8s\n",
      "237:\tlearn: 0.0873012\ttotal: 17.3s\tremaining: 11.7s\n",
      "238:\tlearn: 0.0869223\ttotal: 17.3s\tremaining: 11.7s\n",
      "239:\tlearn: 0.0866831\ttotal: 17.3s\tremaining: 11.6s\n",
      "240:\tlearn: 0.0864798\ttotal: 17.4s\tremaining: 11.5s\n",
      "241:\tlearn: 0.0859565\ttotal: 17.4s\tremaining: 11.4s\n",
      "242:\tlearn: 0.0853733\ttotal: 17.5s\tremaining: 11.3s\n",
      "243:\tlearn: 0.0848555\ttotal: 17.5s\tremaining: 11.2s\n",
      "244:\tlearn: 0.0840589\ttotal: 17.5s\tremaining: 11.1s\n",
      "245:\tlearn: 0.0837104\ttotal: 17.6s\tremaining: 11s\n",
      "246:\tlearn: 0.0831245\ttotal: 17.6s\tremaining: 10.9s\n",
      "247:\tlearn: 0.0825473\ttotal: 17.7s\tremaining: 10.8s\n",
      "248:\tlearn: 0.0818213\ttotal: 17.7s\tremaining: 10.8s\n",
      "249:\tlearn: 0.0811510\ttotal: 17.8s\tremaining: 10.7s\n",
      "250:\tlearn: 0.0806590\ttotal: 17.8s\tremaining: 10.6s\n",
      "251:\tlearn: 0.0800310\ttotal: 17.9s\tremaining: 10.5s\n",
      "252:\tlearn: 0.0798091\ttotal: 17.9s\tremaining: 10.4s\n",
      "253:\tlearn: 0.0792601\ttotal: 18s\tremaining: 10.3s\n",
      "254:\tlearn: 0.0787508\ttotal: 18.1s\tremaining: 10.3s\n",
      "255:\tlearn: 0.0784704\ttotal: 18.1s\tremaining: 10.2s\n",
      "256:\tlearn: 0.0781619\ttotal: 18.2s\tremaining: 10.1s\n",
      "257:\tlearn: 0.0778971\ttotal: 18.2s\tremaining: 10s\n",
      "258:\tlearn: 0.0772350\ttotal: 18.3s\tremaining: 9.97s\n",
      "259:\tlearn: 0.0769415\ttotal: 18.4s\tremaining: 9.9s\n",
      "260:\tlearn: 0.0765189\ttotal: 18.5s\tremaining: 9.83s\n",
      "261:\tlearn: 0.0760459\ttotal: 18.6s\tremaining: 9.78s\n",
      "262:\tlearn: 0.0752665\ttotal: 18.6s\tremaining: 9.71s\n",
      "263:\tlearn: 0.0747309\ttotal: 18.8s\tremaining: 9.7s\n",
      "264:\tlearn: 0.0742197\ttotal: 19s\tremaining: 9.66s\n",
      "265:\tlearn: 0.0738882\ttotal: 19.2s\tremaining: 9.66s\n",
      "266:\tlearn: 0.0735254\ttotal: 19.2s\tremaining: 9.57s\n",
      "267:\tlearn: 0.0729071\ttotal: 19.2s\tremaining: 9.48s\n",
      "268:\tlearn: 0.0723607\ttotal: 19.3s\tremaining: 9.4s\n",
      "269:\tlearn: 0.0720953\ttotal: 19.4s\tremaining: 9.34s\n",
      "270:\tlearn: 0.0715487\ttotal: 19.4s\tremaining: 9.26s\n",
      "271:\tlearn: 0.0710941\ttotal: 19.5s\tremaining: 9.18s\n",
      "272:\tlearn: 0.0706558\ttotal: 19.5s\tremaining: 9.09s\n",
      "273:\tlearn: 0.0705715\ttotal: 19.6s\tremaining: 9.01s\n",
      "274:\tlearn: 0.0700688\ttotal: 19.7s\tremaining: 8.93s\n",
      "275:\tlearn: 0.0697212\ttotal: 19.7s\tremaining: 8.85s\n",
      "276:\tlearn: 0.0694523\ttotal: 19.7s\tremaining: 8.77s\n",
      "277:\tlearn: 0.0693191\ttotal: 19.8s\tremaining: 8.68s\n",
      "278:\tlearn: 0.0691165\ttotal: 19.8s\tremaining: 8.6s\n",
      "279:\tlearn: 0.0685428\ttotal: 19.9s\tremaining: 8.52s\n",
      "280:\tlearn: 0.0683690\ttotal: 19.9s\tremaining: 8.44s\n",
      "281:\tlearn: 0.0680374\ttotal: 20s\tremaining: 8.36s\n",
      "282:\tlearn: 0.0675613\ttotal: 20s\tremaining: 8.29s\n",
      "283:\tlearn: 0.0672174\ttotal: 20.1s\tremaining: 8.2s\n",
      "284:\tlearn: 0.0669051\ttotal: 20.1s\tremaining: 8.12s\n",
      "285:\tlearn: 0.0665040\ttotal: 20.2s\tremaining: 8.04s\n",
      "286:\tlearn: 0.0662804\ttotal: 20.2s\tremaining: 7.96s\n",
      "287:\tlearn: 0.0659325\ttotal: 20.3s\tremaining: 7.88s\n",
      "288:\tlearn: 0.0655675\ttotal: 20.3s\tremaining: 7.8s\n",
      "289:\tlearn: 0.0651618\ttotal: 20.3s\tremaining: 7.72s\n",
      "290:\tlearn: 0.0649815\ttotal: 20.4s\tremaining: 7.64s\n",
      "291:\tlearn: 0.0646761\ttotal: 20.4s\tremaining: 7.56s\n",
      "292:\tlearn: 0.0644557\ttotal: 20.5s\tremaining: 7.48s\n",
      "293:\tlearn: 0.0641708\ttotal: 20.5s\tremaining: 7.41s\n",
      "294:\tlearn: 0.0637883\ttotal: 20.6s\tremaining: 7.33s\n",
      "295:\tlearn: 0.0633760\ttotal: 20.6s\tremaining: 7.25s\n",
      "296:\tlearn: 0.0629675\ttotal: 20.7s\tremaining: 7.18s\n",
      "297:\tlearn: 0.0625305\ttotal: 20.7s\tremaining: 7.1s\n",
      "298:\tlearn: 0.0622632\ttotal: 20.8s\tremaining: 7.02s\n",
      "299:\tlearn: 0.0618559\ttotal: 20.8s\tremaining: 6.95s\n",
      "300:\tlearn: 0.0616269\ttotal: 20.9s\tremaining: 6.88s\n",
      "301:\tlearn: 0.0614004\ttotal: 21s\tremaining: 6.8s\n",
      "302:\tlearn: 0.0609763\ttotal: 21s\tremaining: 6.72s\n",
      "303:\tlearn: 0.0607518\ttotal: 21s\tremaining: 6.64s\n",
      "304:\tlearn: 0.0605115\ttotal: 21.1s\tremaining: 6.57s\n",
      "305:\tlearn: 0.0603030\ttotal: 21.1s\tremaining: 6.49s\n",
      "306:\tlearn: 0.0599026\ttotal: 21.2s\tremaining: 6.41s\n",
      "307:\tlearn: 0.0597546\ttotal: 21.2s\tremaining: 6.33s\n",
      "308:\tlearn: 0.0593515\ttotal: 21.2s\tremaining: 6.25s\n",
      "309:\tlearn: 0.0590531\ttotal: 21.3s\tremaining: 6.18s\n",
      "310:\tlearn: 0.0587964\ttotal: 21.3s\tremaining: 6.1s\n",
      "311:\tlearn: 0.0584532\ttotal: 21.4s\tremaining: 6.03s\n",
      "312:\tlearn: 0.0582595\ttotal: 21.4s\tremaining: 5.95s\n",
      "313:\tlearn: 0.0580130\ttotal: 21.5s\tremaining: 5.88s\n",
      "314:\tlearn: 0.0576427\ttotal: 21.5s\tremaining: 5.81s\n",
      "315:\tlearn: 0.0572986\ttotal: 21.6s\tremaining: 5.73s\n",
      "316:\tlearn: 0.0571395\ttotal: 21.6s\tremaining: 5.66s\n",
      "317:\tlearn: 0.0567930\ttotal: 21.7s\tremaining: 5.59s\n",
      "318:\tlearn: 0.0566470\ttotal: 21.8s\tremaining: 5.52s\n",
      "319:\tlearn: 0.0563887\ttotal: 21.8s\tremaining: 5.46s\n",
      "320:\tlearn: 0.0559584\ttotal: 21.9s\tremaining: 5.38s\n",
      "321:\tlearn: 0.0557770\ttotal: 21.9s\tremaining: 5.31s\n",
      "322:\tlearn: 0.0556161\ttotal: 22s\tremaining: 5.24s\n",
      "323:\tlearn: 0.0552745\ttotal: 22.1s\tremaining: 5.17s\n",
      "324:\tlearn: 0.0548787\ttotal: 22.1s\tremaining: 5.1s\n",
      "325:\tlearn: 0.0545922\ttotal: 22.1s\tremaining: 5.02s\n",
      "326:\tlearn: 0.0544202\ttotal: 22.2s\tremaining: 4.95s\n",
      "327:\tlearn: 0.0540871\ttotal: 22.2s\tremaining: 4.88s\n",
      "328:\tlearn: 0.0537563\ttotal: 22.3s\tremaining: 4.81s\n",
      "329:\tlearn: 0.0534890\ttotal: 22.3s\tremaining: 4.74s\n",
      "330:\tlearn: 0.0531674\ttotal: 22.4s\tremaining: 4.67s\n",
      "331:\tlearn: 0.0527276\ttotal: 22.4s\tremaining: 4.6s\n",
      "332:\tlearn: 0.0525064\ttotal: 22.5s\tremaining: 4.52s\n",
      "333:\tlearn: 0.0520982\ttotal: 22.5s\tremaining: 4.45s\n",
      "334:\tlearn: 0.0517172\ttotal: 22.6s\tremaining: 4.38s\n",
      "335:\tlearn: 0.0514697\ttotal: 22.6s\tremaining: 4.31s\n",
      "336:\tlearn: 0.0512435\ttotal: 22.7s\tremaining: 4.23s\n",
      "337:\tlearn: 0.0509087\ttotal: 22.7s\tremaining: 4.16s\n",
      "338:\tlearn: 0.0505210\ttotal: 22.7s\tremaining: 4.09s\n",
      "339:\tlearn: 0.0503700\ttotal: 22.8s\tremaining: 4.02s\n",
      "340:\tlearn: 0.0501186\ttotal: 22.8s\tremaining: 3.95s\n",
      "341:\tlearn: 0.0498461\ttotal: 22.9s\tremaining: 3.88s\n",
      "342:\tlearn: 0.0497130\ttotal: 22.9s\tremaining: 3.81s\n",
      "343:\tlearn: 0.0495118\ttotal: 22.9s\tremaining: 3.73s\n",
      "344:\tlearn: 0.0493700\ttotal: 23s\tremaining: 3.67s\n",
      "345:\tlearn: 0.0493088\ttotal: 23s\tremaining: 3.59s\n",
      "346:\tlearn: 0.0491201\ttotal: 23.1s\tremaining: 3.52s\n",
      "347:\tlearn: 0.0489501\ttotal: 23.1s\tremaining: 3.45s\n",
      "348:\tlearn: 0.0485724\ttotal: 23.2s\tremaining: 3.39s\n",
      "349:\tlearn: 0.0482915\ttotal: 23.2s\tremaining: 3.32s\n",
      "350:\tlearn: 0.0480968\ttotal: 23.3s\tremaining: 3.25s\n",
      "351:\tlearn: 0.0476818\ttotal: 23.3s\tremaining: 3.18s\n",
      "352:\tlearn: 0.0473932\ttotal: 23.4s\tremaining: 3.11s\n",
      "353:\tlearn: 0.0471720\ttotal: 23.4s\tremaining: 3.05s\n",
      "354:\tlearn: 0.0469152\ttotal: 23.5s\tremaining: 2.98s\n",
      "355:\tlearn: 0.0467184\ttotal: 23.6s\tremaining: 2.91s\n",
      "356:\tlearn: 0.0462889\ttotal: 23.6s\tremaining: 2.85s\n",
      "357:\tlearn: 0.0460337\ttotal: 23.7s\tremaining: 2.78s\n",
      "358:\tlearn: 0.0457434\ttotal: 23.7s\tremaining: 2.71s\n",
      "359:\tlearn: 0.0453520\ttotal: 23.8s\tremaining: 2.64s\n",
      "360:\tlearn: 0.0452288\ttotal: 23.8s\tremaining: 2.58s\n",
      "361:\tlearn: 0.0449362\ttotal: 23.9s\tremaining: 2.51s\n",
      "362:\tlearn: 0.0448002\ttotal: 24s\tremaining: 2.44s\n",
      "363:\tlearn: 0.0445068\ttotal: 24.1s\tremaining: 2.38s\n",
      "364:\tlearn: 0.0441587\ttotal: 24.2s\tremaining: 2.32s\n",
      "365:\tlearn: 0.0439118\ttotal: 24.2s\tremaining: 2.25s\n",
      "366:\tlearn: 0.0436810\ttotal: 24.3s\tremaining: 2.18s\n",
      "367:\tlearn: 0.0434342\ttotal: 24.3s\tremaining: 2.11s\n",
      "368:\tlearn: 0.0431906\ttotal: 24.4s\tremaining: 2.05s\n",
      "369:\tlearn: 0.0430329\ttotal: 24.4s\tremaining: 1.98s\n",
      "370:\tlearn: 0.0428489\ttotal: 24.5s\tremaining: 1.91s\n",
      "371:\tlearn: 0.0426627\ttotal: 24.5s\tremaining: 1.84s\n",
      "372:\tlearn: 0.0423945\ttotal: 24.5s\tremaining: 1.78s\n",
      "373:\tlearn: 0.0421641\ttotal: 24.6s\tremaining: 1.71s\n",
      "374:\tlearn: 0.0418936\ttotal: 24.6s\tremaining: 1.64s\n",
      "375:\tlearn: 0.0417578\ttotal: 24.7s\tremaining: 1.57s\n",
      "376:\tlearn: 0.0415515\ttotal: 24.7s\tremaining: 1.51s\n",
      "377:\tlearn: 0.0414066\ttotal: 24.8s\tremaining: 1.44s\n",
      "378:\tlearn: 0.0411130\ttotal: 24.8s\tremaining: 1.37s\n",
      "379:\tlearn: 0.0409235\ttotal: 24.8s\tremaining: 1.31s\n",
      "380:\tlearn: 0.0407078\ttotal: 24.9s\tremaining: 1.24s\n",
      "381:\tlearn: 0.0405373\ttotal: 24.9s\tremaining: 1.17s\n",
      "382:\tlearn: 0.0404760\ttotal: 25s\tremaining: 1.11s\n",
      "383:\tlearn: 0.0402276\ttotal: 25s\tremaining: 1.04s\n",
      "384:\tlearn: 0.0400102\ttotal: 25.1s\tremaining: 976ms\n",
      "385:\tlearn: 0.0398652\ttotal: 25.1s\tremaining: 910ms\n",
      "386:\tlearn: 0.0396516\ttotal: 25.2s\tremaining: 845ms\n",
      "387:\tlearn: 0.0393259\ttotal: 25.2s\tremaining: 779ms\n",
      "388:\tlearn: 0.0391325\ttotal: 25.2s\tremaining: 714ms\n",
      "389:\tlearn: 0.0388866\ttotal: 25.3s\tremaining: 648ms\n",
      "390:\tlearn: 0.0386940\ttotal: 25.3s\tremaining: 583ms\n",
      "391:\tlearn: 0.0385834\ttotal: 25.4s\tremaining: 518ms\n",
      "392:\tlearn: 0.0384127\ttotal: 25.4s\tremaining: 453ms\n",
      "393:\tlearn: 0.0383952\ttotal: 25.5s\tremaining: 388ms\n",
      "394:\tlearn: 0.0382054\ttotal: 25.5s\tremaining: 323ms\n",
      "395:\tlearn: 0.0380329\ttotal: 25.6s\tremaining: 258ms\n",
      "396:\tlearn: 0.0378341\ttotal: 25.6s\tremaining: 194ms\n",
      "397:\tlearn: 0.0377249\ttotal: 25.7s\tremaining: 129ms\n",
      "398:\tlearn: 0.0376231\ttotal: 25.7s\tremaining: 64.4ms\n",
      "399:\tlearn: 0.0374530\ttotal: 25.7s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6794704428866957"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostClassifier(iterations=400, learning_rate=0.2, depth=6)\n",
    "test_feats(cb, feat_selector.transform(feats), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[this] = fn(special_normalize(get_group_mean(X, col, group)))\n",
      "/tmp/ipykernel_21397/3501114163.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grid_groups[cat] = X[cat].map({\n",
      "/tmp/ipykernel_21397/2295090295.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_gg['id'] = test_gg.index\n"
     ]
    }
   ],
   "source": [
    "X_test = baseline.origtestX()\n",
    "test_gg = preprocess(X_test)\n",
    "es = ft.EntitySet(id = 'gridgroups')\n",
    "test_gg['id'] = test_gg.index\n",
    "es = ft.EntitySet(id = 'gridgroups')\n",
    "es = es.add_dataframe(dataframe_name='gg', dataframe =test_gg, index='id')\n",
    "es.normalize_dataframe(base_dataframe_name='gg', new_dataframe_name='2nd', index='geology')\n",
    "feature_matrix, feature_names = ft.dfs(\n",
    "    entityset=es, \n",
    "    target_dataframe_name = 'gg',\n",
    "    max_depth=2\n",
    ")\n",
    "feats = StandardScaler().fit_transform(feature_matrix.drop([\"geology\"], axis=1, inplace=False))\n",
    "short_feats = feat_selector.transform(feats)\n",
    "y_pred = cb.predict(short_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_ID  Label\n",
       "0      10865      1\n",
       "1      10866      0\n",
       "2      10867      0\n",
       "3      10868      0\n",
       "4      10869      1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/Test.csv\")\n",
    "sub_file = pd.DataFrame({'Sample_ID': test.Sample_ID, 'Label': y_pred})\n",
    "sub_file.to_csv('finn/cat_fs.csv', index = False)\n",
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "hailmary = StackingClassifier([cv=\n",
    "    \n",
    "])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13e18283c4a862c74c262255fd7943db7848134b8f26507a85728d4a3e70d9da"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('starthack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
