{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = baseline.baselineXy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import QuantileTransformer, KBinsDiscretizer, Normalizer, PowerTransformer, RobustScaler, SplineTransformer, StandardScaler, MinMaxScaler\n",
    "td = {\n",
    " 'sdoif_mean_id': QuantileTransformer,\n",
    " 'sdoif_mean_sq': RobustScaler,\n",
    " 'elevation_mean_sqrt': QuantileTransformer,\n",
    " 'procurv_mean_id': StandardScaler,\n",
    " 'placurv_mean_id': Normalizer,\n",
    " 'lsfactor_mean_id': Normalizer,\n",
    " 'slope_mean_id': RobustScaler,\n",
    " 'twi_mean_id': Normalizer,\n",
    " 'twi_mean_sqrt': QuantileTransformer,\n",
    " 'aspect_mean_id': QuantileTransformer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, t in td.items():\n",
    "    X[key] = t().fit_transform(X[[key]])\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\n",
    "    [1, 2, 6, 7],\n",
    "    [3, 8],\n",
    "    [4, 5, 9, 10],\n",
    "    [11, 12],\n",
    "    [13],\n",
    "    [14, 15],\n",
    "    [16, 17, 21, 22],\n",
    "    [18, 23],\n",
    "    [19, 20, 24, 25],\n",
    "    list(range(1, 26))\n",
    "]\n",
    "\n",
    "def get_group_mean(df, col, group):\n",
    "    cols = [f\"{i}_{col}\" for i in group]\n",
    "    return df[cols].to_numpy().mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37.73571  , 31.7261425, 49.1132025, ..., 39.9281625, 35.24104  ,\n",
       "       20.02481  ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import baseline\n",
    "X, y = baseline.originalXy()\n",
    "get_group_mean(X, \"slope\", groups[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(X):\n",
    "    def normalize(x):\n",
    "        return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "    def special_normalize(x):\n",
    "        return ((x - x.min()) / (x.max() - x.min()) + 0.01) / 1.01\n",
    "\n",
    "    fns = [(np.array, 'id'), (np.sqrt, 'sqrt'), (np.square, 'sq'), (np.log, 'log')]\n",
    "    print(len(baseline.continuous) * len(groups) * len(fns))\n",
    "    cols = []\n",
    "    col_names = []\n",
    "    for col in baseline.continuous:\n",
    "        for i, group in enumerate(groups):\n",
    "            for fn, name in fns:\n",
    "                this = f\"{col}_g{i}_{name}\"\n",
    "                if name == 'log':\n",
    "                    cols.append(pd.Series(fn(special_normalize(get_group_mean(X, col, group))), name=this, dtype=float))\n",
    "                else:\n",
    "                    cols.append(pd.Series(fn(normalize(get_group_mean(X, col, group))), name=this, dtype=float))\n",
    "                col_names.append(this)\n",
    "    \n",
    "    for col in X.columns:\n",
    "        cols.append(X[col])\n",
    "\n",
    "    df = pd.concat(cols, axis=1)\n",
    "\n",
    "    import dfcols\n",
    "    def most_freq(df, col):\n",
    "        matrix = df[dfcols.all_square_cols(col)].to_numpy()\n",
    "        return np.array(list(map(np.argmax, map(np.bincount, matrix))))\n",
    "\n",
    "    cat = \"geology\"\n",
    "    # get most freq category\n",
    "    df[cat] = most_freq(X, cat)\n",
    "\n",
    "    for cat_val in df[cat].unique():\n",
    "        df[f\"{cat}_{cat_val}\"] = np.array(df[cat] == cat_val, dtype=int)\n",
    "\n",
    "    return df\n",
    "grid_groups = preprocess(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.feat_trans import test_feats\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_test(x, y, **kwargs):\n",
    "    kf = KFold(n_splits=3)\n",
    "    f1m = 0\n",
    "    for train_ind, test_ind in kf.split(x):\n",
    "        X_train, X_test = x[train_ind], x[test_ind]\n",
    "        y_train, y_test = y[train_ind], y[test_ind]\n",
    "        X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "        X_train, X_test = StandardScaler().fit_transform(X_train), StandardScaler().fit_transform(X_test)\n",
    "        ds = lgb.Dataset(X_train, label=y_train)\n",
    "        bst = lgb.train(kwargs, ds)\n",
    "        y_pred = bst.predict(X_test)\n",
    "        y_pred = np.array(y_pred > 0.5, dtype=int)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1m += f1 / 3\n",
    "    return f1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5537/13491132.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X['id'] = X.index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Entityset: gridgroups\n",
       "  DataFrames:\n",
       "    gg [Rows: 16296, Columns: 554]\n",
       "    2nd [Rows: 7, Columns: 1]\n",
       "  Relationships:\n",
       "    gg.geology -> 2nd.geology"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = baseline.originalXy()\n",
    "X = preprocess(X)\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "X['geology'] = X['geology'].map({\n",
    "        1: \"Weathered Cretaceous granitic rocks\",\n",
    "        2: \"Weathered Jurassic granite rocks\",\n",
    "        3: \"Weathered Jurassic tuff and lava\",\n",
    "        4: \"Weathered Cretaceous tuff and lava\",\n",
    "        5: \"Quaternary deposits\",\n",
    "        6: \"Fill\",\n",
    "        7: \"Weathered Jurassic sandstone, siltstone and mudstone\"\n",
    "    })\n",
    "X['id'] = X.index\n",
    "es = ft.EntitySet(id = 'gridgroups')\n",
    "es = es.add_dataframe(dataframe_name='gg', dataframe = X, index='id')\n",
    "es.normalize_dataframe(base_dataframe_name='gg', new_dataframe_name='2nd', index='geology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sdoif_g0_id</th>\n",
       "      <th>sdoif_g0_sqrt</th>\n",
       "      <th>sdoif_g0_sq</th>\n",
       "      <th>sdoif_g0_log</th>\n",
       "      <th>sdoif_g1_id</th>\n",
       "      <th>sdoif_g1_sqrt</th>\n",
       "      <th>sdoif_g1_sq</th>\n",
       "      <th>sdoif_g1_log</th>\n",
       "      <th>sdoif_g2_id</th>\n",
       "      <th>sdoif_g2_sqrt</th>\n",
       "      <th>...</th>\n",
       "      <th>25_sdoif</th>\n",
       "      <th>geology</th>\n",
       "      <th>geology_3</th>\n",
       "      <th>geology_2</th>\n",
       "      <th>geology_5</th>\n",
       "      <th>geology_1</th>\n",
       "      <th>geology_7</th>\n",
       "      <th>geology_4</th>\n",
       "      <th>geology_6</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680410</td>\n",
       "      <td>0.824870</td>\n",
       "      <td>0.462958</td>\n",
       "      <td>-0.380419</td>\n",
       "      <td>0.680235</td>\n",
       "      <td>0.824763</td>\n",
       "      <td>0.462719</td>\n",
       "      <td>-0.380674</td>\n",
       "      <td>0.680087</td>\n",
       "      <td>0.824674</td>\n",
       "      <td>...</td>\n",
       "      <td>1.281693</td>\n",
       "      <td>Weathered Jurassic tuff and lava</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960227</td>\n",
       "      <td>0.979912</td>\n",
       "      <td>0.922036</td>\n",
       "      <td>-0.040175</td>\n",
       "      <td>0.960051</td>\n",
       "      <td>0.979822</td>\n",
       "      <td>0.921698</td>\n",
       "      <td>-0.040357</td>\n",
       "      <td>0.959901</td>\n",
       "      <td>0.979745</td>\n",
       "      <td>...</td>\n",
       "      <td>1.359579</td>\n",
       "      <td>Weathered Jurassic tuff and lava</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979967</td>\n",
       "      <td>0.989933</td>\n",
       "      <td>0.960336</td>\n",
       "      <td>-0.020034</td>\n",
       "      <td>0.980065</td>\n",
       "      <td>0.989982</td>\n",
       "      <td>0.960528</td>\n",
       "      <td>-0.019935</td>\n",
       "      <td>0.980189</td>\n",
       "      <td>0.990045</td>\n",
       "      <td>...</td>\n",
       "      <td>1.365038</td>\n",
       "      <td>Weathered Jurassic granite rocks</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.173158</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>-3.229237</td>\n",
       "      <td>0.030168</td>\n",
       "      <td>0.173691</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>-3.224625</td>\n",
       "      <td>0.030344</td>\n",
       "      <td>0.174196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100731</td>\n",
       "      <td>Weathered Jurassic granite rocks</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.690175</td>\n",
       "      <td>0.830768</td>\n",
       "      <td>0.476342</td>\n",
       "      <td>-0.366375</td>\n",
       "      <td>0.689855</td>\n",
       "      <td>0.830575</td>\n",
       "      <td>0.475900</td>\n",
       "      <td>-0.366832</td>\n",
       "      <td>0.689496</td>\n",
       "      <td>0.830359</td>\n",
       "      <td>...</td>\n",
       "      <td>1.283876</td>\n",
       "      <td>Quaternary deposits</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16291</th>\n",
       "      <td>0.731971</td>\n",
       "      <td>0.855529</td>\n",
       "      <td>0.535904</td>\n",
       "      <td>-0.308505</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>0.855478</td>\n",
       "      <td>0.535777</td>\n",
       "      <td>-0.308622</td>\n",
       "      <td>0.731806</td>\n",
       "      <td>0.855432</td>\n",
       "      <td>...</td>\n",
       "      <td>1.296128</td>\n",
       "      <td>Weathered Jurassic tuff and lava</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16292</th>\n",
       "      <td>0.734917</td>\n",
       "      <td>0.857246</td>\n",
       "      <td>0.540241</td>\n",
       "      <td>-0.304555</td>\n",
       "      <td>0.734831</td>\n",
       "      <td>0.857196</td>\n",
       "      <td>0.540113</td>\n",
       "      <td>-0.304670</td>\n",
       "      <td>0.734747</td>\n",
       "      <td>0.857147</td>\n",
       "      <td>...</td>\n",
       "      <td>1.296958</td>\n",
       "      <td>Weathered Jurassic tuff and lava</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16293</th>\n",
       "      <td>0.794210</td>\n",
       "      <td>0.891185</td>\n",
       "      <td>0.630770</td>\n",
       "      <td>-0.227845</td>\n",
       "      <td>0.794008</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.630449</td>\n",
       "      <td>-0.228096</td>\n",
       "      <td>0.793834</td>\n",
       "      <td>0.890974</td>\n",
       "      <td>...</td>\n",
       "      <td>1.313354</td>\n",
       "      <td>Weathered Jurassic tuff and lava</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16294</th>\n",
       "      <td>0.770762</td>\n",
       "      <td>0.876427</td>\n",
       "      <td>0.602098</td>\n",
       "      <td>-0.264147</td>\n",
       "      <td>0.770575</td>\n",
       "      <td>0.876323</td>\n",
       "      <td>0.601797</td>\n",
       "      <td>-0.264379</td>\n",
       "      <td>0.770386</td>\n",
       "      <td>0.876218</td>\n",
       "      <td>...</td>\n",
       "      <td>1.306828</td>\n",
       "      <td>Weathered Jurassic tuff and lava</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16295</th>\n",
       "      <td>0.706954</td>\n",
       "      <td>0.840734</td>\n",
       "      <td>0.500127</td>\n",
       "      <td>-0.343025</td>\n",
       "      <td>0.706780</td>\n",
       "      <td>0.840630</td>\n",
       "      <td>0.499882</td>\n",
       "      <td>-0.343268</td>\n",
       "      <td>0.706620</td>\n",
       "      <td>0.840535</td>\n",
       "      <td>...</td>\n",
       "      <td>1.289076</td>\n",
       "      <td>Weathered Jurassic tuff and lava</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16296 rows × 554 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sdoif_g0_id  sdoif_g0_sqrt  sdoif_g0_sq  sdoif_g0_log  sdoif_g1_id  \\\n",
       "0         0.680410       0.824870     0.462958     -0.380419     0.680235   \n",
       "1         0.960227       0.979912     0.922036     -0.040175     0.960051   \n",
       "2         0.979967       0.989933     0.960336     -0.020034     0.980065   \n",
       "3         0.029984       0.173158     0.000899     -3.229237     0.030168   \n",
       "4         0.690175       0.830768     0.476342     -0.366375     0.689855   \n",
       "...            ...            ...          ...           ...          ...   \n",
       "16291     0.731971       0.855529     0.535904     -0.308505     0.731884   \n",
       "16292     0.734917       0.857246     0.540241     -0.304555     0.734831   \n",
       "16293     0.794210       0.891185     0.630770     -0.227845     0.794008   \n",
       "16294     0.770762       0.876427     0.602098     -0.264147     0.770575   \n",
       "16295     0.706954       0.840734     0.500127     -0.343025     0.706780   \n",
       "\n",
       "       sdoif_g1_sqrt  sdoif_g1_sq  sdoif_g1_log  sdoif_g2_id  sdoif_g2_sqrt  \\\n",
       "0           0.824763     0.462719     -0.380674     0.680087       0.824674   \n",
       "1           0.979822     0.921698     -0.040357     0.959901       0.979745   \n",
       "2           0.989982     0.960528     -0.019935     0.980189       0.990045   \n",
       "3           0.173691     0.000910     -3.224625     0.030344       0.174196   \n",
       "4           0.830575     0.475900     -0.366832     0.689496       0.830359   \n",
       "...              ...          ...           ...          ...            ...   \n",
       "16291       0.855478     0.535777     -0.308622     0.731806       0.855432   \n",
       "16292       0.857196     0.540113     -0.304670     0.734747       0.857147   \n",
       "16293       0.891071     0.630449     -0.228096     0.793834       0.890974   \n",
       "16294       0.876323     0.601797     -0.264379     0.770386       0.876218   \n",
       "16295       0.840630     0.499882     -0.343268     0.706620       0.840535   \n",
       "\n",
       "       ...  25_sdoif                           geology  geology_3  geology_2  \\\n",
       "0      ...  1.281693  Weathered Jurassic tuff and lava          1          0   \n",
       "1      ...  1.359579  Weathered Jurassic tuff and lava          1          0   \n",
       "2      ...  1.365038  Weathered Jurassic granite rocks          0          1   \n",
       "3      ...  1.100731  Weathered Jurassic granite rocks          0          1   \n",
       "4      ...  1.283876               Quaternary deposits          0          0   \n",
       "...    ...       ...                               ...        ...        ...   \n",
       "16291  ...  1.296128  Weathered Jurassic tuff and lava          1          0   \n",
       "16292  ...  1.296958  Weathered Jurassic tuff and lava          1          0   \n",
       "16293  ...  1.313354  Weathered Jurassic tuff and lava          1          0   \n",
       "16294  ...  1.306828  Weathered Jurassic tuff and lava          1          0   \n",
       "16295  ...  1.289076  Weathered Jurassic tuff and lava          1          0   \n",
       "\n",
       "       geology_5  geology_1  geology_7  geology_4  geology_6     id  \n",
       "0              0          0          0          0          0      0  \n",
       "1              0          0          0          0          0      1  \n",
       "2              0          0          0          0          0      2  \n",
       "3              0          0          0          0          0      3  \n",
       "4              1          0          0          0          0      4  \n",
       "...          ...        ...        ...        ...        ...    ...  \n",
       "16291          0          0          0          0          0  16291  \n",
       "16292          0          0          0          0          0  16292  \n",
       "16293          0          0          0          0          0  16293  \n",
       "16294          0          0          0          0          0  16294  \n",
       "16295          0          0          0          0          0  16295  \n",
       "\n",
       "[16296 rows x 554 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3866"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix, feature_names = ft.dfs(\n",
    "    entityset=es, \n",
    "    target_dataframe_name = 'gg',\n",
    "    max_depth=10\n",
    ")\n",
    "\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16296, 3865)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = StandardScaler().fit_transform(feature_matrix.drop([\"geology\"], axis=1, inplace=False))\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 8\n",
      "Confirmed: \t0\n",
      "Tentative: \t3865\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 8\n",
      "Confirmed: \t0\n",
      "Tentative: \t3865\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 8\n",
      "Confirmed: \t0\n",
      "Tentative: \t3865\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 8\n",
      "Confirmed: \t0\n",
      "Tentative: \t3865\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 8\n",
      "Confirmed: \t0\n",
      "Tentative: \t3865\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 8\n",
      "Confirmed: \t0\n",
      "Tentative: \t3865\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 8\n",
      "Confirmed: \t0\n",
      "Tentative: \t3865\n",
      "Rejected: \t0\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t8 / 8\n",
      "Confirmed: \t0\n",
      "Tentative: \t786\n",
      "Rejected: \t0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=ExtraTreesClassifier(n_estimators=879,\n",
       "                                        random_state=RandomState(MT19937) at 0x2B70CD7D0B40),\n",
       "         max_iter=8, n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x2B70CD7D0B40, verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "feat_selector = BorutaPy(\n",
    "    verbose=2,\n",
    "    estimator=ExtraTreesClassifier(),\n",
    "    n_estimators='auto',\n",
    "    max_iter=8,  # number of iterations to perform\n",
    ")\n",
    "feat_selector.fit(feats, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [16296, 10864]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/cluster/home/fharbeke/startHack/finniboy.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000038vscode-remote?line=0'>1</a>\u001b[0m feat_selector\u001b[39m.\u001b[39;49mfit_transform(feats, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py:246\u001b[0m, in \u001b[0;36mBorutaPy.fit_transform\u001b[0;34m(self, X, y, weak)\u001b[0m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=223'>224</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y, weak\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=224'>225</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=225'>226</a>\u001b[0m \u001b[39m    Fits Boruta, then reduces the input X to the selected features.\u001b[39;00m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=226'>227</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=242'>243</a>\u001b[0m \u001b[39m        selected by Boruta.\u001b[39;00m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=243'>244</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=245'>246</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=246'>247</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform(X, weak)\n",
      "File \u001b[0;32m~/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py:251\u001b[0m, in \u001b[0;36mBorutaPy._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=248'>249</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=249'>250</a>\u001b[0m     \u001b[39m# check input params\u001b[39;00m\n\u001b[0;32m--> <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=250'>251</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params(X, y)\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=251'>252</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=252'>253</a>\u001b[0m     \u001b[39m# setup variables for Boruta\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py:517\u001b[0m, in \u001b[0;36mBorutaPy._check_params\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=512'>513</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=513'>514</a>\u001b[0m \u001b[39mCheck hyperparameters as well as X and y before proceeding with fit.\u001b[39;00m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=514'>515</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=515'>516</a>\u001b[0m \u001b[39m# check X and y are consistent len, X is Array and y is column\u001b[39;00m\n\u001b[0;32m--> <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=516'>517</a>\u001b[0m X, y \u001b[39m=\u001b[39m check_X_y(X, y)\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=517'>518</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperc \u001b[39m>\u001b[39m \u001b[39m100\u001b[39m:\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/boruta/boruta_py.py?line=518'>519</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThe percentile should be between 0 and 100.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py:981\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=963'>964</a>\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=964'>965</a>\u001b[0m     X,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=965'>966</a>\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=975'>976</a>\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=976'>977</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=978'>979</a>\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[0;32m--> <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=980'>981</a>\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=982'>983</a>\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=329'>330</a>\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=330'>331</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=331'>332</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=332'>333</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=333'>334</a>\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=334'>335</a>\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [16296, 10864]"
     ]
    }
   ],
   "source": [
    "feat_selector.fit_transform(feats, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(X):\n",
    "    gg = preprocess(X)\n",
    "    gg['id'] = gg.index\n",
    "    es = ft.EntitySet(id = 'gridgroups')\n",
    "    es = es.add_dataframe(dataframe_name='gg', dataframe =gg, index='id')\n",
    "    es.normalize_dataframe(base_dataframe_name='gg', new_dataframe_name='2nd', index='geology')\n",
    "    feature_matrix, feature_names = ft.dfs(\n",
    "        entityset=es, \n",
    "        target_dataframe_name = 'gg',\n",
    "        max_depth=10\n",
    "    )\n",
    "    feats = StandardScaler().fit_transform(feature_matrix.drop([\"geology\"], axis=1, inplace=False))\n",
    "    short_feats = feat_selector.transform(feats)\n",
    "    return short_feats\n",
    "#y_pred = cb.predict(short_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n",
      "(10864, 252)\n",
      "0:\tlearn: 0.5943333\ttotal: 95.1ms\tremaining: 37.9s\n",
      "1:\tlearn: 0.5343578\ttotal: 130ms\tremaining: 25.9s\n",
      "2:\tlearn: 0.4949056\ttotal: 165ms\tremaining: 21.8s\n",
      "3:\tlearn: 0.4708808\ttotal: 199ms\tremaining: 19.7s\n",
      "4:\tlearn: 0.4509781\ttotal: 235ms\tremaining: 18.6s\n",
      "5:\tlearn: 0.4381107\ttotal: 270ms\tremaining: 17.7s\n",
      "6:\tlearn: 0.4291794\ttotal: 306ms\tremaining: 17.2s\n",
      "7:\tlearn: 0.4202852\ttotal: 341ms\tremaining: 16.7s\n",
      "8:\tlearn: 0.4096361\ttotal: 404ms\tremaining: 17.5s\n",
      "9:\tlearn: 0.3996324\ttotal: 438ms\tremaining: 17.1s\n",
      "10:\tlearn: 0.3941120\ttotal: 472ms\tremaining: 16.7s\n",
      "11:\tlearn: 0.3886123\ttotal: 507ms\tremaining: 16.4s\n",
      "12:\tlearn: 0.3849474\ttotal: 542ms\tremaining: 16.1s\n",
      "13:\tlearn: 0.3807273\ttotal: 577ms\tremaining: 15.9s\n",
      "14:\tlearn: 0.3763270\ttotal: 612ms\tremaining: 15.7s\n",
      "15:\tlearn: 0.3723740\ttotal: 647ms\tremaining: 15.5s\n",
      "16:\tlearn: 0.3694734\ttotal: 680ms\tremaining: 15.3s\n",
      "17:\tlearn: 0.3662116\ttotal: 715ms\tremaining: 15.2s\n",
      "18:\tlearn: 0.3631344\ttotal: 753ms\tremaining: 15.1s\n",
      "19:\tlearn: 0.3589783\ttotal: 790ms\tremaining: 15s\n",
      "20:\tlearn: 0.3558655\ttotal: 824ms\tremaining: 14.9s\n",
      "21:\tlearn: 0.3507915\ttotal: 864ms\tremaining: 14.8s\n",
      "22:\tlearn: 0.3486503\ttotal: 900ms\tremaining: 14.7s\n",
      "23:\tlearn: 0.3461971\ttotal: 936ms\tremaining: 14.7s\n",
      "24:\tlearn: 0.3437329\ttotal: 973ms\tremaining: 14.6s\n",
      "25:\tlearn: 0.3410734\ttotal: 1.01s\tremaining: 14.5s\n",
      "26:\tlearn: 0.3374913\ttotal: 1.04s\tremaining: 14.4s\n",
      "27:\tlearn: 0.3352279\ttotal: 1.08s\tremaining: 14.3s\n",
      "28:\tlearn: 0.3332427\ttotal: 1.12s\tremaining: 14.3s\n",
      "29:\tlearn: 0.3305801\ttotal: 1.15s\tremaining: 14.2s\n",
      "30:\tlearn: 0.3283598\ttotal: 1.19s\tremaining: 14.1s\n",
      "31:\tlearn: 0.3264071\ttotal: 1.22s\tremaining: 14.1s\n",
      "32:\tlearn: 0.3250522\ttotal: 1.26s\tremaining: 14s\n",
      "33:\tlearn: 0.3222662\ttotal: 1.29s\tremaining: 13.9s\n",
      "34:\tlearn: 0.3197379\ttotal: 1.33s\tremaining: 13.9s\n",
      "35:\tlearn: 0.3182972\ttotal: 1.36s\tremaining: 13.8s\n",
      "36:\tlearn: 0.3163785\ttotal: 1.4s\tremaining: 13.7s\n",
      "37:\tlearn: 0.3146905\ttotal: 1.43s\tremaining: 13.7s\n",
      "38:\tlearn: 0.3119275\ttotal: 1.47s\tremaining: 13.6s\n",
      "39:\tlearn: 0.3106500\ttotal: 1.5s\tremaining: 13.5s\n",
      "40:\tlearn: 0.3090843\ttotal: 1.54s\tremaining: 13.5s\n",
      "41:\tlearn: 0.3073051\ttotal: 1.57s\tremaining: 13.4s\n",
      "42:\tlearn: 0.3055046\ttotal: 1.61s\tremaining: 13.4s\n",
      "43:\tlearn: 0.3035604\ttotal: 1.65s\tremaining: 13.3s\n",
      "44:\tlearn: 0.3012548\ttotal: 1.68s\tremaining: 13.3s\n",
      "45:\tlearn: 0.2991813\ttotal: 1.72s\tremaining: 13.2s\n",
      "46:\tlearn: 0.2977990\ttotal: 1.75s\tremaining: 13.2s\n",
      "47:\tlearn: 0.2960182\ttotal: 1.79s\tremaining: 13.1s\n",
      "48:\tlearn: 0.2945300\ttotal: 1.83s\tremaining: 13.1s\n",
      "49:\tlearn: 0.2930642\ttotal: 1.86s\tremaining: 13s\n",
      "50:\tlearn: 0.2914643\ttotal: 1.9s\tremaining: 13s\n",
      "51:\tlearn: 0.2900065\ttotal: 1.94s\tremaining: 13s\n",
      "52:\tlearn: 0.2887340\ttotal: 1.97s\tremaining: 12.9s\n",
      "53:\tlearn: 0.2864449\ttotal: 2s\tremaining: 12.8s\n",
      "54:\tlearn: 0.2853280\ttotal: 2.04s\tremaining: 12.8s\n",
      "55:\tlearn: 0.2836226\ttotal: 2.08s\tremaining: 12.8s\n",
      "56:\tlearn: 0.2807301\ttotal: 2.11s\tremaining: 12.7s\n",
      "57:\tlearn: 0.2779447\ttotal: 2.15s\tremaining: 12.7s\n",
      "58:\tlearn: 0.2757239\ttotal: 2.19s\tremaining: 12.7s\n",
      "59:\tlearn: 0.2736896\ttotal: 2.22s\tremaining: 12.6s\n",
      "60:\tlearn: 0.2687430\ttotal: 2.26s\tremaining: 12.6s\n",
      "61:\tlearn: 0.2674469\ttotal: 2.3s\tremaining: 12.5s\n",
      "62:\tlearn: 0.2656852\ttotal: 2.34s\tremaining: 12.5s\n",
      "63:\tlearn: 0.2645523\ttotal: 2.37s\tremaining: 12.5s\n",
      "64:\tlearn: 0.2621722\ttotal: 2.41s\tremaining: 12.4s\n",
      "65:\tlearn: 0.2611686\ttotal: 2.44s\tremaining: 12.4s\n",
      "66:\tlearn: 0.2598768\ttotal: 2.48s\tremaining: 12.3s\n",
      "67:\tlearn: 0.2586958\ttotal: 2.51s\tremaining: 12.3s\n",
      "68:\tlearn: 0.2547886\ttotal: 2.55s\tremaining: 12.2s\n",
      "69:\tlearn: 0.2511318\ttotal: 2.58s\tremaining: 12.2s\n",
      "70:\tlearn: 0.2499624\ttotal: 2.62s\tremaining: 12.1s\n",
      "71:\tlearn: 0.2484348\ttotal: 2.65s\tremaining: 12.1s\n",
      "72:\tlearn: 0.2472659\ttotal: 2.69s\tremaining: 12.1s\n",
      "73:\tlearn: 0.2456531\ttotal: 2.73s\tremaining: 12s\n",
      "74:\tlearn: 0.2442852\ttotal: 2.76s\tremaining: 12s\n",
      "75:\tlearn: 0.2431058\ttotal: 2.79s\tremaining: 11.9s\n",
      "76:\tlearn: 0.2420409\ttotal: 2.83s\tremaining: 11.9s\n",
      "77:\tlearn: 0.2410341\ttotal: 2.86s\tremaining: 11.8s\n",
      "78:\tlearn: 0.2395680\ttotal: 2.9s\tremaining: 11.8s\n",
      "79:\tlearn: 0.2386058\ttotal: 2.94s\tremaining: 11.8s\n",
      "80:\tlearn: 0.2374101\ttotal: 2.97s\tremaining: 11.7s\n",
      "81:\tlearn: 0.2359070\ttotal: 3.01s\tremaining: 11.7s\n",
      "82:\tlearn: 0.2348421\ttotal: 3.05s\tremaining: 11.6s\n",
      "83:\tlearn: 0.2318502\ttotal: 3.08s\tremaining: 11.6s\n",
      "84:\tlearn: 0.2304108\ttotal: 3.12s\tremaining: 11.6s\n",
      "85:\tlearn: 0.2292701\ttotal: 3.15s\tremaining: 11.5s\n",
      "86:\tlearn: 0.2284251\ttotal: 3.19s\tremaining: 11.5s\n",
      "87:\tlearn: 0.2278439\ttotal: 3.23s\tremaining: 11.4s\n",
      "88:\tlearn: 0.2267161\ttotal: 3.26s\tremaining: 11.4s\n",
      "89:\tlearn: 0.2254849\ttotal: 3.29s\tremaining: 11.3s\n",
      "90:\tlearn: 0.2246456\ttotal: 3.33s\tremaining: 11.3s\n",
      "91:\tlearn: 0.2232312\ttotal: 3.37s\tremaining: 11.3s\n",
      "92:\tlearn: 0.2221458\ttotal: 3.4s\tremaining: 11.2s\n",
      "93:\tlearn: 0.2213513\ttotal: 3.44s\tremaining: 11.2s\n",
      "94:\tlearn: 0.2197990\ttotal: 3.48s\tremaining: 11.2s\n",
      "95:\tlearn: 0.2188738\ttotal: 3.51s\tremaining: 11.1s\n",
      "96:\tlearn: 0.2174344\ttotal: 3.55s\tremaining: 11.1s\n",
      "97:\tlearn: 0.2166330\ttotal: 3.58s\tremaining: 11s\n",
      "98:\tlearn: 0.2153156\ttotal: 3.62s\tremaining: 11s\n",
      "99:\tlearn: 0.2147333\ttotal: 3.65s\tremaining: 11s\n",
      "100:\tlearn: 0.2137044\ttotal: 3.69s\tremaining: 10.9s\n",
      "101:\tlearn: 0.2123347\ttotal: 3.73s\tremaining: 10.9s\n",
      "102:\tlearn: 0.2115153\ttotal: 3.76s\tremaining: 10.8s\n",
      "103:\tlearn: 0.2102850\ttotal: 3.8s\tremaining: 10.8s\n",
      "104:\tlearn: 0.2081520\ttotal: 3.83s\tremaining: 10.8s\n",
      "105:\tlearn: 0.2073796\ttotal: 3.87s\tremaining: 10.7s\n",
      "106:\tlearn: 0.2060343\ttotal: 3.9s\tremaining: 10.7s\n",
      "107:\tlearn: 0.2050398\ttotal: 3.94s\tremaining: 10.6s\n",
      "108:\tlearn: 0.2042472\ttotal: 3.98s\tremaining: 10.6s\n",
      "109:\tlearn: 0.2033601\ttotal: 4.01s\tremaining: 10.6s\n",
      "110:\tlearn: 0.2026373\ttotal: 4.05s\tremaining: 10.5s\n",
      "111:\tlearn: 0.2012914\ttotal: 4.08s\tremaining: 10.5s\n",
      "112:\tlearn: 0.2000769\ttotal: 4.12s\tremaining: 10.5s\n",
      "113:\tlearn: 0.1982936\ttotal: 4.16s\tremaining: 10.4s\n",
      "114:\tlearn: 0.1972522\ttotal: 4.19s\tremaining: 10.4s\n",
      "115:\tlearn: 0.1964470\ttotal: 4.23s\tremaining: 10.4s\n",
      "116:\tlearn: 0.1956504\ttotal: 4.27s\tremaining: 10.3s\n",
      "117:\tlearn: 0.1950920\ttotal: 4.3s\tremaining: 10.3s\n",
      "118:\tlearn: 0.1942219\ttotal: 4.33s\tremaining: 10.2s\n",
      "119:\tlearn: 0.1935360\ttotal: 4.37s\tremaining: 10.2s\n",
      "120:\tlearn: 0.1928553\ttotal: 4.4s\tremaining: 10.2s\n",
      "121:\tlearn: 0.1919385\ttotal: 4.44s\tremaining: 10.1s\n",
      "122:\tlearn: 0.1911808\ttotal: 4.47s\tremaining: 10.1s\n",
      "123:\tlearn: 0.1903862\ttotal: 4.51s\tremaining: 10s\n",
      "124:\tlearn: 0.1894631\ttotal: 4.55s\tremaining: 10s\n",
      "125:\tlearn: 0.1884758\ttotal: 4.58s\tremaining: 9.97s\n",
      "126:\tlearn: 0.1878124\ttotal: 4.62s\tremaining: 9.93s\n",
      "127:\tlearn: 0.1872661\ttotal: 4.66s\tremaining: 9.91s\n",
      "128:\tlearn: 0.1867547\ttotal: 4.7s\tremaining: 9.87s\n",
      "129:\tlearn: 0.1858746\ttotal: 4.74s\tremaining: 9.84s\n",
      "130:\tlearn: 0.1848997\ttotal: 4.79s\tremaining: 9.83s\n",
      "131:\tlearn: 0.1841966\ttotal: 4.83s\tremaining: 9.8s\n",
      "132:\tlearn: 0.1832356\ttotal: 4.87s\tremaining: 9.77s\n",
      "133:\tlearn: 0.1825306\ttotal: 4.91s\tremaining: 9.75s\n",
      "134:\tlearn: 0.1816479\ttotal: 4.95s\tremaining: 9.71s\n",
      "135:\tlearn: 0.1807723\ttotal: 4.99s\tremaining: 9.69s\n",
      "136:\tlearn: 0.1801262\ttotal: 5.03s\tremaining: 9.65s\n",
      "137:\tlearn: 0.1791921\ttotal: 5.06s\tremaining: 9.61s\n",
      "138:\tlearn: 0.1785537\ttotal: 5.1s\tremaining: 9.58s\n",
      "139:\tlearn: 0.1779756\ttotal: 5.13s\tremaining: 9.53s\n",
      "140:\tlearn: 0.1772287\ttotal: 5.17s\tremaining: 9.49s\n",
      "141:\tlearn: 0.1763667\ttotal: 5.21s\tremaining: 9.46s\n",
      "142:\tlearn: 0.1758302\ttotal: 5.24s\tremaining: 9.42s\n",
      "143:\tlearn: 0.1748533\ttotal: 5.28s\tremaining: 9.38s\n",
      "144:\tlearn: 0.1741094\ttotal: 5.32s\tremaining: 9.35s\n",
      "145:\tlearn: 0.1732483\ttotal: 5.35s\tremaining: 9.31s\n",
      "146:\tlearn: 0.1723514\ttotal: 5.39s\tremaining: 9.27s\n",
      "147:\tlearn: 0.1717226\ttotal: 5.42s\tremaining: 9.23s\n",
      "148:\tlearn: 0.1708523\ttotal: 5.46s\tremaining: 9.2s\n",
      "149:\tlearn: 0.1704829\ttotal: 5.49s\tremaining: 9.16s\n",
      "150:\tlearn: 0.1700822\ttotal: 5.53s\tremaining: 9.12s\n",
      "151:\tlearn: 0.1692389\ttotal: 5.56s\tremaining: 9.08s\n",
      "152:\tlearn: 0.1687964\ttotal: 5.6s\tremaining: 9.04s\n",
      "153:\tlearn: 0.1676480\ttotal: 5.64s\tremaining: 9s\n",
      "154:\tlearn: 0.1669520\ttotal: 5.67s\tremaining: 8.96s\n",
      "155:\tlearn: 0.1663075\ttotal: 5.7s\tremaining: 8.92s\n",
      "156:\tlearn: 0.1654616\ttotal: 5.74s\tremaining: 8.89s\n",
      "157:\tlearn: 0.1648569\ttotal: 5.78s\tremaining: 8.85s\n",
      "158:\tlearn: 0.1640624\ttotal: 5.82s\tremaining: 8.82s\n",
      "159:\tlearn: 0.1633819\ttotal: 5.85s\tremaining: 8.78s\n",
      "160:\tlearn: 0.1625844\ttotal: 5.89s\tremaining: 8.74s\n",
      "161:\tlearn: 0.1616122\ttotal: 5.92s\tremaining: 8.7s\n",
      "162:\tlearn: 0.1604377\ttotal: 5.96s\tremaining: 8.66s\n",
      "163:\tlearn: 0.1595810\ttotal: 5.99s\tremaining: 8.63s\n",
      "164:\tlearn: 0.1589083\ttotal: 6.03s\tremaining: 8.59s\n",
      "165:\tlearn: 0.1581944\ttotal: 6.06s\tremaining: 8.54s\n",
      "166:\tlearn: 0.1571029\ttotal: 6.1s\tremaining: 8.51s\n",
      "167:\tlearn: 0.1561969\ttotal: 6.13s\tremaining: 8.47s\n",
      "168:\tlearn: 0.1554828\ttotal: 6.17s\tremaining: 8.44s\n",
      "169:\tlearn: 0.1543211\ttotal: 6.22s\tremaining: 8.41s\n",
      "170:\tlearn: 0.1539339\ttotal: 6.25s\tremaining: 8.37s\n",
      "171:\tlearn: 0.1532202\ttotal: 6.29s\tremaining: 8.34s\n",
      "172:\tlearn: 0.1526933\ttotal: 6.32s\tremaining: 8.3s\n",
      "173:\tlearn: 0.1518340\ttotal: 6.36s\tremaining: 8.26s\n",
      "174:\tlearn: 0.1511743\ttotal: 6.4s\tremaining: 8.22s\n",
      "175:\tlearn: 0.1501780\ttotal: 6.43s\tremaining: 8.19s\n",
      "176:\tlearn: 0.1496802\ttotal: 6.47s\tremaining: 8.15s\n",
      "177:\tlearn: 0.1488370\ttotal: 6.51s\tremaining: 8.12s\n",
      "178:\tlearn: 0.1485884\ttotal: 6.54s\tremaining: 8.08s\n",
      "179:\tlearn: 0.1480931\ttotal: 6.58s\tremaining: 8.04s\n",
      "180:\tlearn: 0.1472113\ttotal: 6.61s\tremaining: 8s\n",
      "181:\tlearn: 0.1463274\ttotal: 6.65s\tremaining: 7.96s\n",
      "182:\tlearn: 0.1459734\ttotal: 6.68s\tremaining: 7.92s\n",
      "183:\tlearn: 0.1453684\ttotal: 6.72s\tremaining: 7.89s\n",
      "184:\tlearn: 0.1449338\ttotal: 6.75s\tremaining: 7.85s\n",
      "185:\tlearn: 0.1445505\ttotal: 6.79s\tremaining: 7.81s\n",
      "186:\tlearn: 0.1438523\ttotal: 6.83s\tremaining: 7.78s\n",
      "187:\tlearn: 0.1432707\ttotal: 6.87s\tremaining: 7.74s\n",
      "188:\tlearn: 0.1430001\ttotal: 6.9s\tremaining: 7.7s\n",
      "189:\tlearn: 0.1424785\ttotal: 6.93s\tremaining: 7.66s\n",
      "190:\tlearn: 0.1419387\ttotal: 6.97s\tremaining: 7.62s\n",
      "191:\tlearn: 0.1415319\ttotal: 7s\tremaining: 7.58s\n",
      "192:\tlearn: 0.1409155\ttotal: 7.04s\tremaining: 7.55s\n",
      "193:\tlearn: 0.1402991\ttotal: 7.07s\tremaining: 7.51s\n",
      "194:\tlearn: 0.1397889\ttotal: 7.11s\tremaining: 7.47s\n",
      "195:\tlearn: 0.1390653\ttotal: 7.14s\tremaining: 7.44s\n",
      "196:\tlearn: 0.1384640\ttotal: 7.18s\tremaining: 7.4s\n",
      "197:\tlearn: 0.1381358\ttotal: 7.22s\tremaining: 7.36s\n",
      "198:\tlearn: 0.1377672\ttotal: 7.25s\tremaining: 7.32s\n",
      "199:\tlearn: 0.1371266\ttotal: 7.29s\tremaining: 7.29s\n",
      "200:\tlearn: 0.1364673\ttotal: 7.33s\tremaining: 7.26s\n",
      "201:\tlearn: 0.1358095\ttotal: 7.36s\tremaining: 7.22s\n",
      "202:\tlearn: 0.1351541\ttotal: 7.4s\tremaining: 7.18s\n",
      "203:\tlearn: 0.1348901\ttotal: 7.43s\tremaining: 7.14s\n",
      "204:\tlearn: 0.1344888\ttotal: 7.47s\tremaining: 7.1s\n",
      "205:\tlearn: 0.1339446\ttotal: 7.5s\tremaining: 7.07s\n",
      "206:\tlearn: 0.1334106\ttotal: 7.54s\tremaining: 7.03s\n",
      "207:\tlearn: 0.1326906\ttotal: 7.58s\tremaining: 7s\n",
      "208:\tlearn: 0.1320357\ttotal: 7.61s\tremaining: 6.96s\n",
      "209:\tlearn: 0.1311474\ttotal: 7.65s\tremaining: 6.92s\n",
      "210:\tlearn: 0.1307696\ttotal: 7.68s\tremaining: 6.88s\n",
      "211:\tlearn: 0.1301086\ttotal: 7.72s\tremaining: 6.85s\n",
      "212:\tlearn: 0.1297019\ttotal: 7.76s\tremaining: 6.82s\n",
      "213:\tlearn: 0.1292310\ttotal: 7.8s\tremaining: 6.78s\n",
      "214:\tlearn: 0.1288764\ttotal: 7.83s\tremaining: 6.74s\n",
      "215:\tlearn: 0.1283189\ttotal: 7.87s\tremaining: 6.7s\n",
      "216:\tlearn: 0.1278525\ttotal: 7.91s\tremaining: 6.67s\n",
      "217:\tlearn: 0.1275066\ttotal: 7.94s\tremaining: 6.63s\n",
      "218:\tlearn: 0.1268276\ttotal: 7.98s\tremaining: 6.59s\n",
      "219:\tlearn: 0.1264222\ttotal: 8.01s\tremaining: 6.55s\n",
      "220:\tlearn: 0.1259299\ttotal: 8.05s\tremaining: 6.52s\n",
      "221:\tlearn: 0.1254650\ttotal: 8.08s\tremaining: 6.48s\n",
      "222:\tlearn: 0.1249602\ttotal: 8.12s\tremaining: 6.44s\n",
      "223:\tlearn: 0.1244093\ttotal: 8.15s\tremaining: 6.4s\n",
      "224:\tlearn: 0.1239482\ttotal: 8.19s\tremaining: 6.37s\n",
      "225:\tlearn: 0.1236197\ttotal: 8.22s\tremaining: 6.33s\n",
      "226:\tlearn: 0.1228585\ttotal: 8.26s\tremaining: 6.29s\n",
      "227:\tlearn: 0.1222296\ttotal: 8.3s\tremaining: 6.26s\n",
      "228:\tlearn: 0.1218066\ttotal: 8.33s\tremaining: 6.22s\n",
      "229:\tlearn: 0.1210491\ttotal: 8.37s\tremaining: 6.18s\n",
      "230:\tlearn: 0.1204851\ttotal: 8.4s\tremaining: 6.15s\n",
      "231:\tlearn: 0.1200308\ttotal: 8.44s\tremaining: 6.11s\n",
      "232:\tlearn: 0.1194985\ttotal: 8.47s\tremaining: 6.07s\n",
      "233:\tlearn: 0.1194497\ttotal: 8.51s\tremaining: 6.04s\n",
      "234:\tlearn: 0.1191019\ttotal: 8.54s\tremaining: 6s\n",
      "235:\tlearn: 0.1186052\ttotal: 8.58s\tremaining: 5.96s\n",
      "236:\tlearn: 0.1181283\ttotal: 8.62s\tremaining: 5.92s\n",
      "237:\tlearn: 0.1167342\ttotal: 8.65s\tremaining: 5.89s\n",
      "238:\tlearn: 0.1162776\ttotal: 8.69s\tremaining: 5.85s\n",
      "239:\tlearn: 0.1158166\ttotal: 8.72s\tremaining: 5.82s\n",
      "240:\tlearn: 0.1154613\ttotal: 8.76s\tremaining: 5.78s\n",
      "241:\tlearn: 0.1150646\ttotal: 8.79s\tremaining: 5.74s\n",
      "242:\tlearn: 0.1146187\ttotal: 8.83s\tremaining: 5.71s\n",
      "243:\tlearn: 0.1141897\ttotal: 8.87s\tremaining: 5.67s\n",
      "244:\tlearn: 0.1137937\ttotal: 8.9s\tremaining: 5.63s\n",
      "245:\tlearn: 0.1134641\ttotal: 8.94s\tremaining: 5.59s\n",
      "246:\tlearn: 0.1131411\ttotal: 8.97s\tremaining: 5.56s\n",
      "247:\tlearn: 0.1127135\ttotal: 9.01s\tremaining: 5.52s\n",
      "248:\tlearn: 0.1123806\ttotal: 9.04s\tremaining: 5.48s\n",
      "249:\tlearn: 0.1119142\ttotal: 9.07s\tremaining: 5.44s\n",
      "250:\tlearn: 0.1115737\ttotal: 9.11s\tremaining: 5.41s\n",
      "251:\tlearn: 0.1111662\ttotal: 9.14s\tremaining: 5.37s\n",
      "252:\tlearn: 0.1107384\ttotal: 9.18s\tremaining: 5.33s\n",
      "253:\tlearn: 0.1103143\ttotal: 9.22s\tremaining: 5.3s\n",
      "254:\tlearn: 0.1101313\ttotal: 9.29s\tremaining: 5.28s\n",
      "255:\tlearn: 0.1098570\ttotal: 9.34s\tremaining: 5.25s\n",
      "256:\tlearn: 0.1093921\ttotal: 9.38s\tremaining: 5.22s\n",
      "257:\tlearn: 0.1090547\ttotal: 9.42s\tremaining: 5.18s\n",
      "258:\tlearn: 0.1085218\ttotal: 9.46s\tremaining: 5.15s\n",
      "259:\tlearn: 0.1080923\ttotal: 9.49s\tremaining: 5.11s\n",
      "260:\tlearn: 0.1077755\ttotal: 9.53s\tremaining: 5.08s\n",
      "261:\tlearn: 0.1073981\ttotal: 9.56s\tremaining: 5.04s\n",
      "262:\tlearn: 0.1070140\ttotal: 9.6s\tremaining: 5s\n",
      "263:\tlearn: 0.1068199\ttotal: 9.64s\tremaining: 4.96s\n",
      "264:\tlearn: 0.1064746\ttotal: 9.68s\tremaining: 4.93s\n",
      "265:\tlearn: 0.1061774\ttotal: 9.71s\tremaining: 4.89s\n",
      "266:\tlearn: 0.1057432\ttotal: 9.75s\tremaining: 4.86s\n",
      "267:\tlearn: 0.1052802\ttotal: 9.78s\tremaining: 4.82s\n",
      "268:\tlearn: 0.1049777\ttotal: 9.82s\tremaining: 4.78s\n",
      "269:\tlearn: 0.1046509\ttotal: 9.85s\tremaining: 4.74s\n",
      "270:\tlearn: 0.1041667\ttotal: 9.89s\tremaining: 4.71s\n",
      "271:\tlearn: 0.1037804\ttotal: 9.93s\tremaining: 4.67s\n",
      "272:\tlearn: 0.1031983\ttotal: 9.96s\tremaining: 4.63s\n",
      "273:\tlearn: 0.1028870\ttotal: 10s\tremaining: 4.6s\n",
      "274:\tlearn: 0.1023498\ttotal: 10s\tremaining: 4.56s\n",
      "275:\tlearn: 0.1018441\ttotal: 10.1s\tremaining: 4.53s\n",
      "276:\tlearn: 0.1014215\ttotal: 10.1s\tremaining: 4.49s\n",
      "277:\tlearn: 0.1010552\ttotal: 10.2s\tremaining: 4.46s\n",
      "278:\tlearn: 0.1004534\ttotal: 10.2s\tremaining: 4.42s\n",
      "279:\tlearn: 0.0999898\ttotal: 10.2s\tremaining: 4.39s\n",
      "280:\tlearn: 0.0996988\ttotal: 10.3s\tremaining: 4.35s\n",
      "281:\tlearn: 0.0994219\ttotal: 10.3s\tremaining: 4.32s\n",
      "282:\tlearn: 0.0990119\ttotal: 10.4s\tremaining: 4.28s\n",
      "283:\tlearn: 0.0987034\ttotal: 10.4s\tremaining: 4.25s\n",
      "284:\tlearn: 0.0982670\ttotal: 10.4s\tremaining: 4.21s\n",
      "285:\tlearn: 0.0979502\ttotal: 10.5s\tremaining: 4.17s\n",
      "286:\tlearn: 0.0976981\ttotal: 10.5s\tremaining: 4.13s\n",
      "287:\tlearn: 0.0973620\ttotal: 10.5s\tremaining: 4.1s\n",
      "288:\tlearn: 0.0970411\ttotal: 10.6s\tremaining: 4.06s\n",
      "289:\tlearn: 0.0965982\ttotal: 10.6s\tremaining: 4.02s\n",
      "290:\tlearn: 0.0960286\ttotal: 10.6s\tremaining: 3.99s\n",
      "291:\tlearn: 0.0957400\ttotal: 10.7s\tremaining: 3.95s\n",
      "292:\tlearn: 0.0952863\ttotal: 10.7s\tremaining: 3.91s\n",
      "293:\tlearn: 0.0948936\ttotal: 10.8s\tremaining: 3.88s\n",
      "294:\tlearn: 0.0946916\ttotal: 10.8s\tremaining: 3.84s\n",
      "295:\tlearn: 0.0942461\ttotal: 10.8s\tremaining: 3.81s\n",
      "296:\tlearn: 0.0939552\ttotal: 10.9s\tremaining: 3.77s\n",
      "297:\tlearn: 0.0934520\ttotal: 10.9s\tremaining: 3.73s\n",
      "298:\tlearn: 0.0932145\ttotal: 10.9s\tremaining: 3.69s\n",
      "299:\tlearn: 0.0929594\ttotal: 11s\tremaining: 3.66s\n",
      "300:\tlearn: 0.0925013\ttotal: 11s\tremaining: 3.62s\n",
      "301:\tlearn: 0.0922821\ttotal: 11s\tremaining: 3.58s\n",
      "302:\tlearn: 0.0919401\ttotal: 11.1s\tremaining: 3.55s\n",
      "303:\tlearn: 0.0915601\ttotal: 11.1s\tremaining: 3.51s\n",
      "304:\tlearn: 0.0911430\ttotal: 11.1s\tremaining: 3.47s\n",
      "305:\tlearn: 0.0907989\ttotal: 11.2s\tremaining: 3.44s\n",
      "306:\tlearn: 0.0902426\ttotal: 11.2s\tremaining: 3.4s\n",
      "307:\tlearn: 0.0898156\ttotal: 11.3s\tremaining: 3.36s\n",
      "308:\tlearn: 0.0895049\ttotal: 11.3s\tremaining: 3.33s\n",
      "309:\tlearn: 0.0890499\ttotal: 11.3s\tremaining: 3.29s\n",
      "310:\tlearn: 0.0887442\ttotal: 11.4s\tremaining: 3.25s\n",
      "311:\tlearn: 0.0884784\ttotal: 11.4s\tremaining: 3.22s\n",
      "312:\tlearn: 0.0882720\ttotal: 11.4s\tremaining: 3.18s\n",
      "313:\tlearn: 0.0879769\ttotal: 11.5s\tremaining: 3.14s\n",
      "314:\tlearn: 0.0876636\ttotal: 11.5s\tremaining: 3.1s\n",
      "315:\tlearn: 0.0873543\ttotal: 11.5s\tremaining: 3.07s\n",
      "316:\tlearn: 0.0871241\ttotal: 11.6s\tremaining: 3.03s\n",
      "317:\tlearn: 0.0866818\ttotal: 11.6s\tremaining: 3s\n",
      "318:\tlearn: 0.0863924\ttotal: 11.7s\tremaining: 2.96s\n",
      "319:\tlearn: 0.0860323\ttotal: 11.7s\tremaining: 2.92s\n",
      "320:\tlearn: 0.0857608\ttotal: 11.7s\tremaining: 2.88s\n",
      "321:\tlearn: 0.0852830\ttotal: 11.8s\tremaining: 2.85s\n",
      "322:\tlearn: 0.0849336\ttotal: 11.8s\tremaining: 2.81s\n",
      "323:\tlearn: 0.0844090\ttotal: 11.8s\tremaining: 2.77s\n",
      "324:\tlearn: 0.0841885\ttotal: 11.9s\tremaining: 2.74s\n",
      "325:\tlearn: 0.0837999\ttotal: 11.9s\tremaining: 2.7s\n",
      "326:\tlearn: 0.0835285\ttotal: 11.9s\tremaining: 2.66s\n",
      "327:\tlearn: 0.0832803\ttotal: 12s\tremaining: 2.63s\n",
      "328:\tlearn: 0.0829847\ttotal: 12s\tremaining: 2.59s\n",
      "329:\tlearn: 0.0826201\ttotal: 12s\tremaining: 2.55s\n",
      "330:\tlearn: 0.0822460\ttotal: 12.1s\tremaining: 2.52s\n",
      "331:\tlearn: 0.0819354\ttotal: 12.1s\tremaining: 2.48s\n",
      "332:\tlearn: 0.0817379\ttotal: 12.1s\tremaining: 2.44s\n",
      "333:\tlearn: 0.0814769\ttotal: 12.2s\tremaining: 2.41s\n",
      "334:\tlearn: 0.0810897\ttotal: 12.2s\tremaining: 2.37s\n",
      "335:\tlearn: 0.0807631\ttotal: 12.3s\tremaining: 2.33s\n",
      "336:\tlearn: 0.0806686\ttotal: 12.3s\tremaining: 2.3s\n",
      "337:\tlearn: 0.0804240\ttotal: 12.3s\tremaining: 2.26s\n",
      "338:\tlearn: 0.0802056\ttotal: 12.4s\tremaining: 2.22s\n",
      "339:\tlearn: 0.0798327\ttotal: 12.4s\tremaining: 2.19s\n",
      "340:\tlearn: 0.0795846\ttotal: 12.4s\tremaining: 2.15s\n",
      "341:\tlearn: 0.0794010\ttotal: 12.5s\tremaining: 2.11s\n",
      "342:\tlearn: 0.0792278\ttotal: 12.5s\tremaining: 2.08s\n",
      "343:\tlearn: 0.0788376\ttotal: 12.5s\tremaining: 2.04s\n",
      "344:\tlearn: 0.0786944\ttotal: 12.6s\tremaining: 2s\n",
      "345:\tlearn: 0.0784066\ttotal: 12.6s\tremaining: 1.97s\n",
      "346:\tlearn: 0.0779470\ttotal: 12.6s\tremaining: 1.93s\n",
      "347:\tlearn: 0.0777520\ttotal: 12.7s\tremaining: 1.9s\n",
      "348:\tlearn: 0.0775915\ttotal: 12.7s\tremaining: 1.86s\n",
      "349:\tlearn: 0.0771524\ttotal: 12.8s\tremaining: 1.82s\n",
      "350:\tlearn: 0.0769202\ttotal: 12.8s\tremaining: 1.78s\n",
      "351:\tlearn: 0.0767400\ttotal: 12.8s\tremaining: 1.75s\n",
      "352:\tlearn: 0.0764289\ttotal: 12.9s\tremaining: 1.71s\n",
      "353:\tlearn: 0.0763193\ttotal: 12.9s\tremaining: 1.68s\n",
      "354:\tlearn: 0.0760575\ttotal: 12.9s\tremaining: 1.64s\n",
      "355:\tlearn: 0.0757667\ttotal: 13s\tremaining: 1.6s\n",
      "356:\tlearn: 0.0755498\ttotal: 13s\tremaining: 1.57s\n",
      "357:\tlearn: 0.0754140\ttotal: 13s\tremaining: 1.53s\n",
      "358:\tlearn: 0.0750944\ttotal: 13.1s\tremaining: 1.49s\n",
      "359:\tlearn: 0.0748556\ttotal: 13.1s\tremaining: 1.46s\n",
      "360:\tlearn: 0.0744866\ttotal: 13.2s\tremaining: 1.42s\n",
      "361:\tlearn: 0.0742117\ttotal: 13.2s\tremaining: 1.39s\n",
      "362:\tlearn: 0.0739748\ttotal: 13.2s\tremaining: 1.35s\n",
      "363:\tlearn: 0.0736408\ttotal: 13.3s\tremaining: 1.31s\n",
      "364:\tlearn: 0.0733111\ttotal: 13.3s\tremaining: 1.27s\n",
      "365:\tlearn: 0.0730442\ttotal: 13.3s\tremaining: 1.24s\n",
      "366:\tlearn: 0.0727178\ttotal: 13.4s\tremaining: 1.2s\n",
      "367:\tlearn: 0.0726136\ttotal: 13.4s\tremaining: 1.17s\n",
      "368:\tlearn: 0.0723381\ttotal: 13.4s\tremaining: 1.13s\n",
      "369:\tlearn: 0.0721038\ttotal: 13.5s\tremaining: 1.09s\n",
      "370:\tlearn: 0.0717695\ttotal: 13.5s\tremaining: 1.06s\n",
      "371:\tlearn: 0.0716269\ttotal: 13.6s\tremaining: 1.02s\n",
      "372:\tlearn: 0.0714250\ttotal: 13.6s\tremaining: 984ms\n",
      "373:\tlearn: 0.0712523\ttotal: 13.6s\tremaining: 947ms\n",
      "374:\tlearn: 0.0710796\ttotal: 13.7s\tremaining: 911ms\n",
      "375:\tlearn: 0.0708702\ttotal: 13.7s\tremaining: 874ms\n",
      "376:\tlearn: 0.0705011\ttotal: 13.7s\tremaining: 838ms\n",
      "377:\tlearn: 0.0703849\ttotal: 13.8s\tremaining: 801ms\n",
      "378:\tlearn: 0.0701752\ttotal: 13.8s\tremaining: 765ms\n",
      "379:\tlearn: 0.0699100\ttotal: 13.8s\tremaining: 728ms\n",
      "380:\tlearn: 0.0697554\ttotal: 13.9s\tremaining: 692ms\n",
      "381:\tlearn: 0.0694969\ttotal: 13.9s\tremaining: 656ms\n",
      "382:\tlearn: 0.0693171\ttotal: 13.9s\tremaining: 619ms\n",
      "383:\tlearn: 0.0690317\ttotal: 14s\tremaining: 583ms\n",
      "384:\tlearn: 0.0688269\ttotal: 14s\tremaining: 546ms\n",
      "385:\tlearn: 0.0684766\ttotal: 14.1s\tremaining: 510ms\n",
      "386:\tlearn: 0.0681527\ttotal: 14.1s\tremaining: 473ms\n",
      "387:\tlearn: 0.0679600\ttotal: 14.1s\tremaining: 437ms\n",
      "388:\tlearn: 0.0677637\ttotal: 14.2s\tremaining: 401ms\n",
      "389:\tlearn: 0.0673805\ttotal: 14.2s\tremaining: 364ms\n",
      "390:\tlearn: 0.0671209\ttotal: 14.2s\tremaining: 328ms\n",
      "391:\tlearn: 0.0669110\ttotal: 14.3s\tremaining: 291ms\n",
      "392:\tlearn: 0.0667788\ttotal: 14.3s\tremaining: 255ms\n",
      "393:\tlearn: 0.0665220\ttotal: 14.3s\tremaining: 218ms\n",
      "394:\tlearn: 0.0662075\ttotal: 14.4s\tremaining: 182ms\n",
      "395:\tlearn: 0.0660104\ttotal: 14.4s\tremaining: 146ms\n",
      "396:\tlearn: 0.0657297\ttotal: 14.5s\tremaining: 109ms\n",
      "397:\tlearn: 0.0654905\ttotal: 14.5s\tremaining: 72.9ms\n",
      "398:\tlearn: 0.0652839\ttotal: 14.5s\tremaining: 36.4ms\n",
      "399:\tlearn: 0.0650121\ttotal: 14.6s\tremaining: 0us\n",
      "0.9947278077488966\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "cb = CatBoostClassifier(iterations=400, learning_rate=0.2, depth=6)\n",
    "X, y = baseline.originalXy()\n",
    "feats = complete(X)\n",
    "print(feats.shape)\n",
    "feats, y = SMOTE().fit_resample(feats, y)\n",
    "cb.fit(feats, y)\n",
    "print(f1_score(y, cb.predict(feats)))\n",
    "y_pred = cb.predict(complete(baseline.origtestX()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_ID  Label\n",
       "0      10865      0\n",
       "1      10866      0\n",
       "2      10867      0\n",
       "3      10868      1\n",
       "4      10869      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/Test.csv\")\n",
    "sub_file = pd.DataFrame({'Sample_ID': test.Sample_ID, 'Label': y_pred})\n",
    "sub_file.to_csv('finn/cat_fs.csv', index = False)\n",
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Info] Number of positive: 6531, number of negative: 6531\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 69101\n",
      "[LightGBM] [Info] Number of data points in the train set: 13062, number of used features: 271\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "X#0,  gbdt 0.10 31 100, t=0.4: 0.702746\n",
      "X#0,  gbdt 0.10 31 100, t=0.4: 0.704433\n",
      "X#0,  gbdt 0.10 31 100, t=0.5: 0.708054\n",
      "X#0,  gbdt 0.10 31 100, t=0.5: 0.706701\n",
      "X#0,  gbdt 0.10 31 100, t=0.6: 0.694319\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Info] Number of positive: 6531, number of negative: 6531\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 69101\n",
      "[LightGBM] [Info] Number of data points in the train set: 13062, number of used features: 271\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "X#0,  gbdt 0.10 47 100, t=0.4: 0.709196\n",
      "X#0,  gbdt 0.10 47 100, t=0.4: 0.709137\n",
      "X#0,  gbdt 0.10 47 100, t=0.5: 0.708191\n",
      "X#0,  gbdt 0.10 47 100, t=0.5: 0.700444\n",
      "X#0,  gbdt 0.10 47 100, t=0.6: 0.705448\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Info] Number of positive: 6531, number of negative: 6531\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 69101\n",
      "[LightGBM] [Info] Number of data points in the train set: 13062, number of used features: 271\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "X#0,  gbdt 0.10 63 100, t=0.4: 0.712375\n",
      "X#0,  gbdt 0.10 63 100, t=0.4: 0.718166\n",
      "X#0,  gbdt 0.10 63 100, t=0.5: 0.715899\n",
      "X#0,  gbdt 0.10 63 100, t=0.5: 0.713649\n",
      "X#0,  gbdt 0.10 63 100, t=0.6: 0.712835\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Info] Number of positive: 6531, number of negative: 6531\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 69101\n",
      "[LightGBM] [Info] Number of data points in the train set: 13062, number of used features: 271\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "X#0,  goss 0.10 31 100, t=0.4: 0.695230\n",
      "X#0,  goss 0.10 31 100, t=0.4: 0.699752\n",
      "X#0,  goss 0.10 31 100, t=0.5: 0.701101\n",
      "X#0,  goss 0.10 31 100, t=0.5: 0.693591\n",
      "X#0,  goss 0.10 31 100, t=0.6: 0.693141\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Info] Number of positive: 6531, number of negative: 6531\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 69101\n",
      "[LightGBM] [Info] Number of data points in the train set: 13062, number of used features: 271\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "X#0,  goss 0.10 47 100, t=0.4: 0.699093\n",
      "X#0,  goss 0.10 47 100, t=0.4: 0.697908\n",
      "X#0,  goss 0.10 47 100, t=0.5: 0.699743\n",
      "X#0,  goss 0.10 47 100, t=0.5: 0.690941\n",
      "X#0,  goss 0.10 47 100, t=0.6: 0.688584\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Warning] Unknown parameter: num_iterationsn\n",
      "[LightGBM] [Info] Number of positive: 6531, number of negative: 6531\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 69101\n",
      "[LightGBM] [Info] Number of data points in the train set: 13062, number of used features: 271\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "X#0,  goss 0.10 63 100, t=0.4: 0.703112\n",
      "X#0,  goss 0.10 63 100, t=0.4: 0.703986\n",
      "X#0,  goss 0.10 63 100, t=0.5: 0.702330\n",
      "X#0,  goss 0.10 63 100, t=0.5: 0.690391\n",
      "X#0,  goss 0.10 63 100, t=0.6: 0.686869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "X, y = baseline.originalXy()\n",
    "feats = complete(X)\n",
    "\n",
    "for i, x in enumerate([feats]):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "    params = {'objective': 'binary'}\n",
    "    ds = lgb.Dataset(X_train, label=y_train)\n",
    "    boosts = ['gbdt', 'goss']\n",
    "    lrs = [0.1]\n",
    "    ns = [31, 47, 63]\n",
    "    iterations = [100]\n",
    "    for b, lr, n, it in product(boosts, lrs, ns, iterations):\n",
    "        params['boosting'] = b\n",
    "        params['learning_rate'] = lr\n",
    "        params['num_leaves'] = n\n",
    "        params['num_iterationsn'] = it\n",
    "        bst = lgb.train(params, ds)\n",
    "        y_prob = bst.predict(X_test)\n",
    "        for thresh in [0.4, 0.42, 0.45, 0.5, 0.55]:\n",
    "            y_pred = np.array(y_prob > thresh, dtype=int)\n",
    "\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            print(f\"X#{i}, {b: >5} {lr:.2f} {n} {it}, t={thresh:.3f}: {f1:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear 0.25, 0.671698\n",
      "linear 0.5, 0.671698\n",
      "linear 0.75, 0.671698\n",
      "poly 0.25, 0.571429\n",
      "poly 0.5, 0.571429\n",
      "poly 0.75, 0.571429\n",
      "rbf 0.25, 0.076125\n",
      "rbf 0.5, 0.055944\n",
      "rbf 0.75, 0.055944\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feats, y, test_size=0.2, random_state=42)\n",
    "X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "gamma = [0.25, 0.5, 0.75]\n",
    "for k, g in product(kernels, gamma):\n",
    "    svc = SVC(kernel=k, gamma=g).fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{k} {g}, {f1:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticnet, 0.672218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1, 0.670704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2, 0.672218\n",
      "none, 0.672714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "penalties = ['elasticnet', 'l1', 'l2', 'none']\n",
    "for pen in penalties:\n",
    "    lr = LogisticRegression(penalty=pen, solver='saga', l1_ratio=0.5).fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{pen}, {f1:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True gini: 0.694097\n",
      "True entropy: 0.700348\n",
      "False gini: 0.679210\n",
      "False entropy: 0.695574\n"
     ]
    }
   ],
   "source": [
    "bs = [True, False]\n",
    "crits = ['gini', 'entropy']\n",
    "for b, c in product(bs, crits):\n",
    "    rf = RandomForestClassifier(criterion=c, bootstrap=b)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"{b} {c}: {f1:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True gini: 0.708949\n",
      "True entropy: 0.703259\n",
      "False gini: 0.709502\n",
      "False entropy: 0.701880\n"
     ]
    }
   ],
   "source": [
    "for b, c in product(bs, crits):\n",
    "    et = ExtraTreesClassifier(criterion=c, bootstrap=b)\n",
    "    et.fit(X_train, y_train)\n",
    "    y_pred = et.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"{b} {c}: {f1:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity, (320, 150, 75): 0.659409\n",
      "identity, (150, 150, 25): 0.663324\n",
      "identity, (320, 50, 100, 50): 0.654275\n",
      "identity, (100, 200, 75, 50): 0.658247\n",
      "relu, (320, 150, 75): 0.648250\n",
      "relu, (150, 150, 25): 0.648250\n",
      "relu, (320, 50, 100, 50): 0.631678\n",
      "relu, (100, 200, 75, 50): 0.644222\n",
      "logistic, (320, 150, 75): 0.607434\n",
      "logistic, (150, 150, 25): 0.598738\n",
      "logistic, (320, 50, 100, 50): 0.630837\n",
      "logistic, (100, 200, 75, 50): 0.605455\n",
      "tanh, (320, 150, 75): 0.650866\n",
      "tanh, (150, 150, 25): 0.626244\n",
      "tanh, (320, 50, 100, 50): 0.638079\n",
      "tanh, (100, 200, 75, 50): 0.619437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "acts = ['identity', 'relu', 'logistic', 'tanh']\n",
    "sizes = [(320, 150, 75), (150, 150, 25), (320, 50, 100, 50), (100, 200, 75, 50)]\n",
    "for act, s in product(acts, sizes):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=s, random_state=1, activation=act)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"{act}, {s}: {f1:.6f}\")\n",
    "# (150,100,75,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity, (150, 100, 75, 50, 10): 0.661107\n",
      "relu, (150, 100, 75, 50, 10): 0.661710\n",
      "logistic, (150, 100, 75, 50, 10): 0.650435\n",
      "tanh, (150, 100, 75, 50, 10): 0.641003\n"
     ]
    }
   ],
   "source": [
    "acts = ['identity', 'relu', 'logistic', 'tanh']\n",
    "sizes = [(150, 100, 75, 50, 10)]\n",
    "for act, s in product(acts, sizes):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=s, random_state=1, activation=act)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"{act}, {s}: {f1:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = lgb.Dataset(X_train, label=y_train)\n",
    "bst = lgb.train({'learning_rate': 0.1, 'boosting': 'goss', 'num_leaves': 63, 'num_iterations': 100}, ds)\n",
    "\n",
    "cb = CatBoostClassifier(iterations=400, learning_rate=0.2, depth=6).fit(X_train, y_train)\n",
    "\n",
    "svc = SVC(kernel='linear').fit(X_train, y_train)\n",
    "\n",
    "lr = LogisticRegression(penalty='none', solver='newton-cg').fit(X_train, y_train)\n",
    "\n",
    "rf = RandomForestClassifier(criterion='entropy', bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "et = ExtraTreesClassifier(criterion='gini', bootstrap=False).fit(X_train, y_train)\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(150, 100, 75, 50, 10)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.42411367e-01, 1.06707716e-02, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 9.99999799e-01, 2.00930038e-07],\n",
       "       [6.95488322e-01, 9.31561895e-01, 1.00000000e+00, ...,\n",
       "        1.00000000e+00, 4.00316036e-06, 9.99995997e-01],\n",
       "       [5.20182152e-01, 3.38847266e-01, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 9.67939055e-01, 3.20609446e-02],\n",
       "       ...,\n",
       "       [9.79092660e-01, 9.69322922e-01, 1.00000000e+00, ...,\n",
       "        1.00000000e+00, 2.11617825e-06, 9.99997884e-01],\n",
       "       [9.89017515e-01, 9.98216615e-01, 1.00000000e+00, ...,\n",
       "        1.00000000e+00, 3.88452357e-08, 9.99999961e-01],\n",
       "       [1.03691389e+00, 9.96556033e-01, 1.00000000e+00, ...,\n",
       "        1.00000000e+00, 6.89674967e-07, 9.99999310e-01]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_pred = bst.predict(X_train)\n",
    "cb_pred = cb.predict_proba(X_train)[:, 1]\n",
    "svc_pred = svc.predict(X_train)\n",
    "lr_pred = lr.predict_proba(X_train)\n",
    "rf_pred = rf.predict_proba(X_train)\n",
    "et_pred = et.predict_proba(X_train)\n",
    "nn_pred = nn.predict_proba(X_train)\n",
    "\n",
    "all_preds = np.c_[bst_pred, cb_pred, svc_pred, lr_pred, rf_pred, et_pred, nn_pred]\n",
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr = LogisticRegression().fit(all_preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7002700270027004"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_pred = bst.predict(X_test)\n",
    "cb_pred = cb.predict_proba(X_test)[:, 1]\n",
    "svc_pred = svc.predict(X_test)\n",
    "lr_pred = lr.predict_proba(X_test)\n",
    "rf_pred = rf.predict_proba(X_test)\n",
    "et_pred = et.predict_proba(X_test)\n",
    "nn_pred = nn.predict_proba(X_test)\n",
    "\n",
    "all_preds = np.c_[bst_pred, cb_pred, svc_pred, lr_pred, rf_pred, et_pred, nn_pred]\n",
    "\n",
    "y_pred = final_lr.predict(all_preds)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(10864, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/cluster/home/fharbeke/startHack/finniboy.ipynb Cell 32'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000037vscode-remote?line=0'>1</a>\u001b[0m X, y \u001b[39m=\u001b[39m baseline\u001b[39m.\u001b[39moriginalXy()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000037vscode-remote?line=1'>2</a>\u001b[0m X \u001b[39m=\u001b[39m complete(X)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000037vscode-remote?line=2'>3</a>\u001b[0m X, y \u001b[39m=\u001b[39m SMOTE()\u001b[39m.\u001b[39;49mfit_resample(X, y)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000037vscode-remote?line=3'>4</a>\u001b[0m X\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py:77\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py?line=74'>75</a>\u001b[0m check_classification_targets(y)\n\u001b[1;32m     <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py?line=75'>76</a>\u001b[0m arrays_transformer \u001b[39m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m---> <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py?line=76'>77</a>\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X_y(X, y)\n\u001b[1;32m     <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py?line=78'>79</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m     <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py?line=79'>80</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_type\n\u001b[1;32m     <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py?line=80'>81</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py?line=82'>83</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py:132\u001b[0m, in \u001b[0;36mBaseSampler._check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py?line=129'>130</a>\u001b[0m     accept_sparse \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py?line=130'>131</a>\u001b[0m y, binarize_y \u001b[39m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py?line=131'>132</a>\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, reset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse)\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/imblearn/base.py?line=132'>133</a>\u001b[0m \u001b[39mreturn\u001b[39;00m X, y, binarize_y\n",
      "File \u001b[0;32m~/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/base.py?line=578'>579</a>\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/base.py?line=579'>580</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/base.py?line=580'>581</a>\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/base.py?line=581'>582</a>\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/base.py?line=583'>584</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=960'>961</a>\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=961'>962</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=963'>964</a>\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=964'>965</a>\u001b[0m     X,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=965'>966</a>\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=966'>967</a>\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=967'>968</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=968'>969</a>\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=969'>970</a>\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=970'>971</a>\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=971'>972</a>\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=972'>973</a>\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=973'>974</a>\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=974'>975</a>\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=975'>976</a>\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=976'>977</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=978'>979</a>\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=980'>981</a>\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py:814\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=811'>812</a>\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=812'>813</a>\u001b[0m     \u001b[39mif\u001b[39;00m n_features \u001b[39m<\u001b[39m ensure_min_features:\n\u001b[0;32m--> <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=813'>814</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=814'>815</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m feature(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=815'>816</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m a minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=816'>817</a>\u001b[0m             \u001b[39m%\u001b[39m (n_features, array\u001b[39m.\u001b[39mshape, ensure_min_features, context)\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=817'>818</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=819'>820</a>\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[1;32m    <a href='file:///cluster/home/fharbeke/miniconda3/envs/starthack/lib/python3.9/site-packages/sklearn/utils/validation.py?line=820'>821</a>\u001b[0m     array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(array, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(10864, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "X, y = baseline.originalXy()\n",
    "X = complete(X)\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'feat_selector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/cluster/home/fharbeke/startHack/finniboy.ipynb Cell 32'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000031vscode-remote?line=0'>1</a>\u001b[0m X, y \u001b[39m=\u001b[39m baseline\u001b[39m.\u001b[39moriginalXy()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000031vscode-remote?line=1'>2</a>\u001b[0m X \u001b[39m=\u001b[39m complete(X)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000031vscode-remote?line=2'>3</a>\u001b[0m X, y \u001b[39m=\u001b[39m SMOTE()\u001b[39m.\u001b[39mfit_resample(X, y)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000031vscode-remote?line=4'>5</a>\u001b[0m ds \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(X, label\u001b[39m=\u001b[39my)\n",
      "\u001b[1;32m/cluster/home/fharbeke/startHack/finniboy.ipynb Cell 17'\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000016vscode-remote?line=8'>9</a>\u001b[0m feature_matrix, feature_names \u001b[39m=\u001b[39m ft\u001b[39m.\u001b[39mdfs(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000016vscode-remote?line=9'>10</a>\u001b[0m     entityset\u001b[39m=\u001b[39mes, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000016vscode-remote?line=10'>11</a>\u001b[0m     target_dataframe_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000016vscode-remote?line=11'>12</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000016vscode-remote?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000016vscode-remote?line=13'>14</a>\u001b[0m feats \u001b[39m=\u001b[39m StandardScaler()\u001b[39m.\u001b[39mfit_transform(feature_matrix\u001b[39m.\u001b[39mdrop([\u001b[39m\"\u001b[39m\u001b[39mgeology\u001b[39m\u001b[39m\"\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000016vscode-remote?line=14'>15</a>\u001b[0m short_feats \u001b[39m=\u001b[39m feat_selector\u001b[39m.\u001b[39mtransform(feats)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beuler.ethz.ch/cluster/home/fharbeke/startHack/finniboy.ipynb#ch0000016vscode-remote?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m short_feats\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feat_selector' is not defined"
     ]
    }
   ],
   "source": [
    "ds = lgb.Dataset(X, label=y)\n",
    "bst = lgb.train({'learning_rate': 0.1, 'boosting': 'goss', 'num_leaves': 63, 'num_iterations': 100}, ds)\n",
    "\n",
    "cb = CatBoostClassifier(iterations=400, learning_rate=0.2, depth=6).fit(X, y)\n",
    "\n",
    "svc = SVC(kernel='linear').fit(X, y)\n",
    "\n",
    "lr = LogisticRegression(penalty='none', solver='newton-cg').fit(X, y)\n",
    "\n",
    "rf = RandomForestClassifier(criterion='entropy', bootstrap=True).fit(X, y)\n",
    "\n",
    "et = ExtraTreesClassifier(criterion='gini', bootstrap=False).fit(X, y)\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(150, 100, 75, 50, 10)).fit(X, y)\n",
    "\n",
    "bst_pred = bst.predict(X)\n",
    "cb_pred = cb.predict_proba(X)[:, 1]\n",
    "svc_pred = svc.predict(X)\n",
    "lr_pred = lr.predict_proba(X)\n",
    "rf_pred = rf.predict_proba(X)\n",
    "et_pred = et.predict_proba(X)\n",
    "nn_pred = nn.predict_proba(X)\n",
    "\n",
    "all_preds = np.c_[bst_pred, cb_pred, svc_pred, lr_pred, rf_pred, et_pred, nn_pred]\n",
    "#all_preds = np.c_[bst_pred, cb_pred, lr_pred, rf_pred, et_pred, nn_pred]\n",
    "final_lr = LogisticRegression().fit(all_preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_lr = LogisticRegression().fit(all_preds, y)\n",
    "\n",
    "X_test = complete(baseline.origtestX())\n",
    "#X_test = baseline.origtestX()\n",
    "\n",
    "bst_pred = bst.predict(X_test)\n",
    "cb_pred = cb.predict_proba(X_test)[:, 1]\n",
    "svc_pred = svc.predict(X_test)\n",
    "lr_pred = lr.predict_proba(X_test)\n",
    "rf_pred = rf.predict_proba(X_test)\n",
    "et_pred = et.predict_proba(X_test)\n",
    "nn_pred = nn.predict_proba(X_test)\n",
    "\n",
    "all_preds = np.c_[bst_pred, cb_pred, svc_pred, lr_pred, rf_pred, et_pred, nn_pred]\n",
    "#all_preds = np.c_[bst_pred, cb_pred, lr_pred, rf_pred, et_pred, nn_pred]\n",
    "\n",
    "y_pred = final_lr.predict(all_preds)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_ID  Label\n",
       "0      10865      1\n",
       "1      10866      0\n",
       "2      10867      0\n",
       "3      10868      1\n",
       "4      10869      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/Test.csv\")\n",
    "sub_file = pd.DataFrame({'Sample_ID': test.Sample_ID, 'Label': y_pred})\n",
    "sub_file.to_csv('finn/finalLR.csv', index = False)\n",
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13e18283c4a862c74c262255fd7943db7848134b8f26507a85728d4a3e70d9da"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('starthack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
